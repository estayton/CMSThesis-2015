\chapter{Sources and Ideologies}

%% 2. Where is that coming from?
%% -Sci-fi and historical dreama
%% -a cultural vision of automation of work
%% -AI history
%% -NHTSA/SAE policy/standards (instantiated in)
%% -researchers in the field!

%%Consider including both sides in automation of work, AI history, and
%%NHTSA/SAE! That way everything is consistent & in one place


The popular narratives about self-driving vehicles cannot have come from
the ether. But what are their roots? What are the sources from which
these stories come, the founts of technological ideology from which
they spring? Journalistic accounts of technological change are of
course impacted by a wide variety of practices and perspectives, from
the market and readership needs of news organizations to the pervasive
culture of commodity scientism.\cite{???-smithCommodityScientism} The
reasons for why these stories are the way they are may be innumerable
and difficult to pin down. Specifically regarding the ways that
driverless cars are figured in the press as autonomous machines, there
are a number of identifiable sources for these modes of writing and
ideological connections: science fiction, factory automation,
artificial intelligence, and engineering and policy documents. Some of
these sources themselves have more direct impacts, such as
policy documents that stand to shape the way state legislation proceeds. Each,
in its turn, impacts the popular narrative in specific and important
ways, which must be understood if we are to come to grips with the
question of why we are receiving a particular story, why vehicle
automation appears on the surface the way that it does.

\subsection{Science Fictions, Historical Dreams}

Science fiction is a perennial source of popular metaphors and ideas
about technological change, in part perhaps because the visions are so
compelling, but also because they are so easily available. While they
too do not issue forth from a vacuum, coming from a potent combination
of actual engineering and scientific developments mixed with fervent imagination,
science-fiction images represent easily-digestible cultural reference
points for technological stories. From Asimov to \emph{Terminator},
these sorts of pictures are endemic to discussions of Artificial
Intelligence in the press. Visions of robotic drivers are cut from the
same cloth. Stories and ideas about what autonomous cars will be are
influenced by \emph{Minority Report}, \emph{KITT}, and \emph{Total
  Recall}.\cite{???} Countless articles begin by describing
self-driving vehicles as a Hollywood or science-fiction
staple.\cite{???-http://seekingalpha.com/article/2798325-a-window-into-a-driverless-future-from-science-fiction-to-reality} 

Many, indeed most, articles seem ignorant of the actual research
history. Some bring up the pioneering work done by Mercedes and Ernst
Dickmanns in Germany in the 1990s.\cite{???} But few connect
autonomous vehicles today as part of a long research history going
back to the 1960s, and an even longer set of engineering dreams going
back at least to the 1920s. Such narratives would be at least as
valid, in their own way, as connections to science fiction, but I
suggest that some of the shock value of the technology would be lost
by linking it to a deep history of research and effort. Connecting it
instead to the dreams and aspirations of Hollywood cinema makes it
more novel, exciting, even magical. And that hype fits the business
goals of many news outlets interested only in pageviews.

But despite this paucity of historical grounding, certain historically-specific
dreams do filter through into the narratives of autonomous technology
through the media of popular culture and fiction. The Jetsons, though
the show did not actually foreground driverless vehicles, get
remembered due to the role of flying cars, which trigger similar visions of wild
futures made possible through technology.\cite{???} GM's Firebird III, from a
similar era, is remembered due to its publicity campaign and
subsequent cultural presence,\cite{???-http://www.fool.com/investing/general/2013/12/22/google-vs-tesla-vs-ford-who-has-the-best-self-driv.aspx} despite that the vehicle actually
contained no autonomous technology of any kind.\cite[p. ???]{wetmore} It was
itself an engineering fiction. 

<CAN I FIND A THIRD EXAMPLE???>

These fictions are powerful because they do not answer to logic and
sense. They draw upon emotions, hopes, and aspirations. Driverless cars
are in part works of theater, objects of technological spectacle which
are not yet truly real, despite their existence as physical objects
which can be photographed and experienced. Such real-world contact is
yet limited to a lucky few. Special press events are hosted to allow journalists
to ride in these vehicles.\cite{???} Their capabilities are touted,
advertised, but their media picture is still tightly controlled. Not subsumed
to the mundane, the quotidian, they still possess that magic that
makes science fiction connections obvious and compelling. But this
does not mean such connections are unproblematic. Far from it. By
their alignment of these vehicles to science fiction, popular
narratives curry forward those pictures of the technology already
envisioned, and obscure the multitude of potential implementations
that can emerge from engineering practice in the moment. Self-driving
cars threaten to become natural and obvious, in a particular form,
through their associations with existing, known and culturally
assimilated media portrayals.

But there are other historical images that are part and parcel of
popular autonomous vehicle narratives, ones that are not connected
with vehicles at all. And among these is the assimilated cultural
understanding of the history of factory labor and the automation of work.

\subsection{Accepted Stories of the Automation of Work}
%% 1.1) deep history is the mechanization/automation of work (4 p)
%% --going back to factories/IRev: replacing human competencies with
%% machine competencies and moving the people into new roles
%% --which engages old debates about the role of the human

Human technological progress since antiquity has
involved continual re-negotiations of human labor and the roles of
animals and mechanisms in the labor process. Due to a confluence
of factors---the continuing miniaturization of computing technology, new
advances in machine learning and artificial intelligence algorithms, a
gradual increase in battery capacities, faster wireless networks---the
horizons for everyday automation are broader now than ever before. 

The popular visions of this technology focus on the future: the
idea that in just two decades the majority of cars on the road will be
fully autonomous. Even respected business information and consulting
bodies have bought into this dream.\footnote{For example, the IHS
  predicts 54 million such vehicles by 2035, which is not as extreme,
  but still a sizable fraction of road vehicles \cite{IHSstudy}} In these vehicles, the users would
step in, select a destination, and would then be free to read, sleep,
watch a movie, answer emails, or otherwise occupy themselves without
needing to pay any attention to the operation of the vehicle. While this
vision has its benefits, it makes many people nervous about
ceding their driving agency to a computer system.\cite{clytton} News articles fret
about what will happen when no one knows how to drive manually any
more,\cite{pross} a classic fear of ``de-skilling'' that is implicated in so many
other implementations of computers. Furthermore, coexistence with
autonomous or automated systems is sometimes presented as a fundamentally new
situation, as if human beings had never before had to work and live
with and next to automated systems, presenting new benefits and
dangers, and requiring new roles for their human tenders.

However, automation already has a deep
history in the industrial sector. Current debates and fears about de-skilling, human jobs,
and the role and value of human labor return us to questions that have
plagued factories, and labor's relationship to machinery, since the
early Industrial Revolution. But as we have already seen with the common
elision of the actual research history of self-driving vehicles, the
stories that get told about driverless cars and factory automation are
primarily those rooted in the cultural consciousness, rather than in
nuanced, factual histories.

<INCLUDE MORE ACTUAL HISTORY>
<Wiener's automated factory from the 1950s>

The early areas of automation which get picked-up by popular attention
include the textile mills of the early 1800s, in which a large
proportion of hand-labor was replaced by steam-powered (in the UK) and
water-powered industrial machinery.\cite{???-fromMRSmithClass} The
story here is a familiar one: skilled artisans made obsolete by the
lower cost and higher productive capacity of mechanical labor. By
analogy, new types of skilled labor (taxi and limousine drivers, or
even bus drivers) are now under threat, and their fate should be no
different than that of the workers who came before.

Robotic cars are sometimes situated as
the next step for robots after the factory, their final emergence into
the real world having conquered the factory floor.\footnote{See for
  example ``Robot Vehicles'' in RobotWorx \cite{robotworx}, which describes automated cars as having the sensors
  industrial robots have had for many years.} The history of
automation that gets mobilized is one of a teleological progression
toward complete automation of all sectors of work. This tendency seems
to be deeply aligned with the struggle of certain groups of
middle-class laborers to keep their jobs in the face of changing
factory conditions. Among the most public and most topical of these
are the Detroit autoworkers, once a bastion of middle-class
respectability, many of whom faced unemployment with the rise of
Japanese (popularly read as: ``highly automated'') automotive
might.\cite{???} There is some truth to this, though the actual story
is far more complicated and has less to do with automation and more to
do with product priorities and other labor
relations.\cite{???-nyeAmericas} actual historical circumstances are
not the point. What matters is the general perception that automated
systems, such as the robotic arms used for painting and assembly, are
reducing the overall pool of available jobs.

This narrative of automation progress was once the province of
blue-collar labor only, but is now moving into white-collar work as
well. Bill Gates, speaking at the American Enterprise Institute,
suggested that a large portion of the workforce will find itself
displaced by robots in the next 20 years, including accountants and
other white-collar
jobs.\cite{???-http://bgr.com/2014/03/14/bill-gates-interview-robots/}
Gate's suggested remedies (low to no taxes and decreasing minimum
wages) are painfully self-serving, but his comments play directly into
contemporary fears about automation, and only support the usual
narrative that job-loss due to automation is inevitable, and workers
should just get out of the way. To this view, the last two hundred
years of innovation in automation is unidirectional and largely
undifferentiated. From steam power to the assembly line, from
Taylorism to roboticization, each was yet another nail in the coffin
of the human worker. But while it is undeniable that automation had changed the
character of human labor, this perceived uniformity in automation
processes is a figment of the collective imagination. For example,
Taylorism, while it attempted to more deeply control and rationalize
the work processes of the individual, in a way mechanizing them, also
created new classes of worker and expanded the role of human managers
in the labor process. An in-depth critique of the traditional
narrative, through a more nuanced discussion of automation
history, is the subject of another chapter. But 
articles that posit factory work as a precursor to the automated
car, without going deeper into that history, implicitly accept a
vision of teleological progress that comes to color the conclusions
and possible futures presented.

%% This approach
%% presents serious risks. It may be some time before the human inside
%% the car can be entirely disengaged with the driving task,2 if that is
%% even something we want as a culture, which means an interim period of
%% operation potentially characterized by “hours of boredom punctuated by
%% moments of terror.”3 The danger of human inattention,4 which has shown
%% up in aircraft automation with sometimes disastrous results, is
%% actually pushing aircraft manufacturers to more fully involve the
%% human in the process of flying, even as cockpits become more and more
%% computerized.5 And by focusing on ever more automation, rather than
%% appropriate automation, we may also be removing some of the parts of
%% driving that are most enjoyable: by replacing the skilled craftsman
%% with the automaton and the machine tender, we risk making driving
%% sterile and dull. 

\subsection{Artificial Intelligence and Its Cultural Resonance}
%% 1.2) place to introduce the brief overview of AI history, of what goes
%% into the different approaches
%% --starting from historical visions of automata (1 p)
%% --classical symbolic approaches / physical symbol system (3 p)
%% ----which in a way we have returned to today w/ explicit mapping
%% --Rodney Brooks subsumption architecture and ``world is its own best
%% model'' (3 p)
%% --Leaning heavily on H. R. Ekiba and his approach to illuminating the
%% unstated assumptions of AI research areas (2 p)
Artificial intelligence has its own history, distinct from that of the
automation of work, that feeds into driverless car narratives. Many popular
portrayals of AI care little about the actual history of the field,
and generally pull from major moments that garnered enough popular
attention to enter the cultural knowledge-base: ELIZA, Deep Blue,
Watson, and Siri. But coverage of advances in other artificial
intelligence tasks often cross-pollinates with self-driving car
coverage, either through direct reference or indirect association.
Some appreciation for the history of the field
of AI is important for understanding these moments as they are being
used, as models of progress and evidence of the technological inevitability of
self-driving vehicles. And the technologies of the moment, employed in
cars as well as other AI applications, are critical here. The history
of AI as conveyed through news coverage about self-driving vehicles is
not a complete one, but it is one side of the truth. And even
engineers ignorant of this history may make similar mistakes of understanding.

Intelligent machines are not a new idea. Just as automation has long
been a part of human history, dreams of artificial life suffuse our
legends. The myths about Hephaestus and
his creations, notably Talos, a golden female automaton, come to us
from antiquity,\cite{mccorduck}  but continue to be cited as historical antecedents in
literature on autonomous robots and their ethical issues.\cite[p. 3]{patricklin} Automata,
or rather semblances of automata, appear in Hellenic Egypt, with
priests as puppeteers pulling their strings.\cite[Ch. 1]{mccorduck} The history of
artificial life is intertwined with that of autonomous machines: the
creation of Pygmalion's Galatea echoes the same practices and
concerns, as does the story of Mary Shelley's “modern Prometheus” (of
particular note for the purposes of this argument, Shelley's vision of
artificial life is inspired and physically mobilized by static
electricity, the infusing of a ``spark of being'' into the creature; and
electrostatics were a highly public research topic and indeed public
spectacle, complete with live demonstrations, in the 1700s and early
1800s).\cite[p. 44]{shelley} Judah Loew ben Bezalel, a Talmudic scholar, is in legend the
creator of the golem, a being animated from clay who functioned as a
spy against the Gentiles.\cite[Ch. 1]{mccorduck} Though Loew's was not the only golem
recorded in myth, the rabbi occupies a special position among the most
prominent AI researchers of the 20th century: Pamela McCorduck records
that Marvin Minsky and Joel Moses grew up with a ``family tradition
that they are descendants of Rabbi Loew,'' and Moses claims a number of
other American scientists, including John von Neumann and Norbert
Wiener, also consider themselves among the descendants.\cite[Ch. 1]{mccorduck} This is all
to say that while the technological drivers of conceptual visions are
more contemporary, ancient myth and legend continue to subtly underpin
research in autonomy and artificial intelligence.

%% Drosz and Vaucanson
As Jessica Riskin chronicles in her studies of eighteenth and
nineteenth century automata, clever inventors, interested in going
beyond mere representation, created a variety of impressive
simulations of life---that is simulation in its modern sense, meaning
experimental models that can elucidate the natural, rather than its
contemporary sense which would have meant artifice.\cite[p. ??]{riskinDuck}
Makers of automata strove to imitate the very materials of life,
hoping to ``make the parts of their machine work as much as possible
like the parts of living things and thereby to test the limits of
resemblance between synthetic and natural life.''\cite[p. ??]{riskinDuck}
Automata of this era ``bled,'' ``defecated,'' and ``breathed,'' though some
of these functions were themselves faked, such as in the case of
Vaucanson's Duck. Nevertheless, imitation was central to the project,
and in this way these early automata prefigured at least some of the
developments in AI and Alife. These attempts, though little known and
rarely referenced today, provide critical background for the attempts
that followed. 

%% Steam governors
Many of these automata, despite being surprisingly accurate
mimeses of life, did little in terms of interaction with the
environment. Meaningful interaction requires closing the loop between
sensing and acting in the manner of a
 ``teleological,'' self-governing mechanism with corrective feedback.
 Indicative of Norbert Wiener's later research into cybernetics, such
 corrective feedback mechanisms had been studied since at least the
 late 18th century, when James Watt incorporated a governor into his
 steam engine. Watt himself had pulled from earlier applications of
 governors in windmills, which had been used since at least the 17th
 century.\cite{richardhills} James Clerk Maxwell, most famous for his equations of
 electricity and magnetism published in the 1865 paper ``A Dynamical
 Theory of the Electromagnetic Field'' (among the most important
 equations in physics), published a paper in 1868 on centrifugal
 governors in steam engines in the Proceedings of Royal Society. This
 paper, ``On governors,'' became one of the central papers in early
 control theory.\cite{ottomayr} Bringing together a number of existing
 areas including control theory,
 cybernetics---from the Greek \emph{cybernetes} meaning
 ``steersman''\cite[p. 6]{wienerMainIdeas}---extended their reach to more complex
 systems: ``control and communication in the animal and machine''. As
 Norbert Wiener puts it, control, or the
 feedback mechanism, is necessary for the extension of information
 theory into communication theory. Cybernetics envisions the world in
 terms of feedback mechanisms, which can be used to explain a variety
 of phenomena in living organisms: homeostasis, balance, and motion
 disorders like locomotor ataxia and Parkinsons all fall within the
 cybernetic sphere\cite[p. 10-15]{wienerMainIdeas}. And all are envisioned
 as outcomes of systems that pass messages internally. In this way
 cybernetics is a forerunner of the discipline of
 artificial intelligence, which is interested in re-creating many of the same
 self-regulating systems within computer systems. This replacement of
 competencies tends toward the obsolescence of the human being, and
 again is interpreted in many stories as a teleological process, a
 perpetual advancement of technological competencies.



%% Deep learning
A number of conceptually different approaches to AI have been tried
over the past 50 years, often with deep-seated
ambivalences.\footnote{Ekbia's book does an excellent job
  exploring and cataloging many of these, more than I have space for.
  But logical and neorobotic approaches appear most relevant as
  broad-strokes historical precursors for inclusion here.} Ideas fade
and resurface as fashions change, and greater computational power
allows ``failed'' techniques to be tried anew. But much of this
history is presently unappreciated outside of the discipline. Ours is the age of
statistical AI, and that is what receives attention in the
self-driving car narrative. The buzzword of the day seems to be ``deep
learning,'' which
appears to yield radical new possibilities everywhere it is
applied---it really just means a return of neural
networks,\footnote{These systems still have little or nothing to do
  with actual neurons; they are brain-like in only the barest
  toy-model sort of way, despite how they are often represented in the
  press} which, armed with some improvements in weight generation, more layers of
nodes, and more data to train with, have been able to eclipse many of
the previous techniques\cite{???}.

FIND A NEURAL NETWORK PRIMER I CAN REFER TO\footnote{
(perhaps Jordan, Michael I.; Bishop, Christopher M. (2004). ``Neural
Networks''. In Allen B. Tucker. Computer Science Handbook, Second
Edition (Section VII: Intelligent Systems). Boca Raton, FL: Chapman \&
Hall/CRC Press LLC)}

Neural networks are essentially just a web of nodes with
interconnections between them. They may consist of multiple layers
(hence ``deep'' in deep learning) or may be shallow. Also known as
``multilayer perceptrons,'' such networks have an input layer and
output layer, with one or more intervening hidden layers. Each node
corresponds to a particular feature or combination of features in the
input, and therefore works to classify inputs into different
categories. Each node is also connected to all the nodes in the
following layer with some tunable weight. The process of training the
neural network involves adjusting those connection weights so as to
be more sensitive in distinguishing different types of
inputs.\footnote{THIS ALL NEEDS SOME CLARITY} This tuning,
traditionally, has been done using supervised method and
backpropagation of errors: the output result is compared to an
expected classification result, and the error used to tune the weights
more appropriately. Deep learning extends this technique, decreasing
the amount of ``feature-engineering'' (a human task, identifying the
features the network should use to distinguish inputs) required to
train the system. The ``ideal'' training situation is entirely
unsupervised: the network independently ``learns'' the features of
unlabeled and unclassified input, without any human input. This ideal
prospers both due to convenience in terms of human effort (less
programmer effort required to build labeled sets of training data) and
due to the deep-seated ideology that machine independence is
paramount. Unsupervised learning is often seen as more impressive and
therefore more valuable research.\cite{???}



%%   $$$$$$$$      NOTE      $$$$$$$$$
%%
%%
%%
%%      More HISTORY, Less CRITIQUE
%%                (here)
%%
%%




%% ``self-aware'' mario, image recognition and other
%% claptrap (1) (incl. John von Neumann & ALife (See CMS790 paper)??)
But as has happened before, the AI hype-machine is doing its
work. And popular claims about the utopic promise of deep learning, to
learn about the world ``on its own,''
abound. Google's and Stanford's recent
improvements in image recognition\cite{markoffImage} triggered a wave
of popular speculation about computer vision meeting or surpassing
that of humans. Since vision is the primary sense involved in human driving
and one of the main research areas for automated vehicles, such
advances would seem to translate automatically into the self-driving
car space. Popular articles, though some note that current
state-of-the-art image recognition is still considerably less capable
than people are, still present the uncritical idea that we have solved
the image-recognition problem---or rather, that increases in computing
power mean it will necessarily soon be solved. By this narrative seemingly limitless
possibilities are open before us. As one should expect, the real
history is far more nuanced. But this is the environment that autonomous cars, as a
research area of artificial intelligence, find themselves in today:
part of a new surge (bubble?) of interest in the field, driven by new
or newly extended techniques.


\subsection{Engineering Standards and Policy Documents}

But while some of the conventional driverless car narrative comes from
poor understanding of the technology and history, some also comes
straight from the engineering standards and policy documents set up to
guide the industry's development. A number of levels-of-autonomy or
levels-of-automation taxonomies have been developed to guide
researchers and public agencies toward an appropriate understanding of
how automation research will progress. While they vary in terms of how
prescriptive or descriptive they are, these documents are easily taken
as evidence for how automated systems must or will develop in
practice.

The primary formulations of levels of autonomy for self-driving cars
have been published by the National Highway Traffic Safety
Administration (NHTSA) and the Society of Automotive Engineers
(SAE).\footnote{The German Federal Highway Research Institute, BASt,
 has also produced a taxonomy that predates the SAE's work, and
 influenced it in key ways.}
These reports exhibit some resonances and contradictions in how these
organizations represent autonomous vehicles and their human drivers.
Viewed in the larger context of the discourse on levels of automation
in general, these speak to different ideas of who the “driver” will be
in automated systems. However, both make particular assumptions about
the way autonomy is or will be implemented that may not ultimately be
valid and certainly seem to foreclose on certain alternative ways in
which systems could be designed. These documents represent an important
vector for the traditional autonomous vehicle narrative, and are
therefore worthy of deeper scrutiny.

The NHTSA's levels of automation focus largely on the human driver and
human costs, and are unable to think beyond human-machine opposition.
The agency identifies three ``distinct but related streams of
technological change'': 

\begin{quote}
``(1) in vehicle crash avoidance systems that provide warnings and/or
limited automated control of safety functions; (2) V2V communications
that support various crash avoidance applications; and (3)
self-driving vehicles''\cite{???}
\end{quote}

Though the agency positions these technologies ``as part of a
continuum,''\cite{???} aligning themselves with Thomas Sheridan, whose
work forms a fundamental part of \ref{chap3}, this belies
their three-part dissection of the technological landscape and their
following 5-level taxonomy. They correctly recognize that today's
``crash avoidance and mitigation technologies'' are the ``building blocks
for what may one day lead to a driverless vehicle,'' but incorrectly
assume that an easy line can be drawn between driven and
driverless.\cite{???} According to their definition, Automated
vehicles are those in which ``aspects of a safety-critical control
function (e.g., steering, throttle, or braking) occur without direct
driver input.''\cite{???} Therefore, the NHTSA definition excludes warning
systems that nevertheless still use ``automation'' in varying degrees,
drawing a suspect line between monitoring and action. Though there is
a difference between systems that only provide information and systems
that directly affect the mechanical state of the vehicle, making that
distinction part of the definition of “automation” perpetuates an
inaccurate view that automation is only meaningful or important to
consider when it affects a physical mechanism. Information automation
is written out of the NHTSA's definition.

Their definition also excludes non safety-critical ``control
functions.'' The agency is likely attempting to make this distinction
so that cars with currently banal automatic technologies like
automatic transmissions do 
not count as ``automated vehicles,'' but this is the wrong footing on
which to rest a definition of automation. Automated wipers and hazard
lights may well be ``safety critical.'' The state of the transmission
and drivetrain is fundamentally important to throttle control. The
terms of the agency's definition of ``automation'' itself are incoherent
and self-contradictory. By writing out current systems from the field
of ``automated vehicles,'' the NHTSA has hobbled their terminology.

The agency does not view the human-machine system as a whole, focusing
on, by labeling as ``automation,'' only those processes that are
mechanical in result and are arbitrarily considered to be
``safety-critical'' as opposed to ``secondary.'' Even if one does not
wish to include 
the driver as part of the ``vehicle,'' real-world vehicle tasks, or
control functions, are more complicated than simply turning the
steering wheel. The NHTSA's levels of autonomy only compound the
issues already exposed. Level 0, or “no-automation” represents
precisely the issues inherent in their definition of automation. Level
1 is the only automation level beyond zero that does not have the
ability to apply all types of mechanical input to the system: it is
limited to ``one or more specific control functions'' that operate
``independently,'' and only for certain periods of time.\cite{???} The
necessity of independence between automated ``control functions'' is
especially hard to fathom: in a modern automobile, few if any systems
are truly independent, instead coordinated via electronic management
systems.\footnote{For example, see systems like Bosch's comprehensive
  electronic energy management, EEM.} 

The report is even confused on the number of control functions, though
it ultimately means that both steering and brakes/throttle cannot be
automated at the same time in a level 1 system: 

\begin{quote}
``there is no combination of vehicle control systems working in unison
that enables the driver to be disengaged from physically operating the
vehicle by having his or her hands off the steering wheel AND feet off
the pedals at the same time''\cite{???}
\end{quote}

This continues the agency's curious focus on the physical state of the
driver's body, repeated in level 2 automation to make the distinction
that now the operator can be ``disengaged from physically operating the
vehicle by having his or her hands off the steering wheel AND foot off
pedal at the same time'' [sic].\cite{???} This description of bodily state is
the most coherent part of the levels definitions, but makes little
practical sense for defining automation. One can drive hands-and-feet
free in a non-automated vehicle, for short periods of time, in the
right conditions. Does the car become a level 2 during this time?

While this question seems fatuous, it becomes important if the
physical state of the driver's body will define system-level
automation. (It is also worth noting that this clarification is
unnecessarily normative, and does not transfer to other types of
bodily input—like GM's abandoned ``Unicontrol''\cite{???}—or controls designed
for amputees.) Though this stipulation attempts to address what the
human driver is actually doing, it is insufficiently granular to
account for the various types of mental and physical effort exerted:
from using control stalks to monitoring for vehicles to consulting a
GPS or mentally planning a route to monitoring and adjusting an
automation system via steering-wheel based controls. But the
preoccupation with the body results from the NHTSA's charter: the
human is a safety liability, something to be protected. The operations
of hands and feet represent readily visible and na\"{\i}ve distinctions
between human and automated, even if the distinctions do not turn out
to be particularly useful when faced with further technical scrutiny.
For their stated audience, primarily state lawmakers who are not
likely to be human factors engineers or well-versed in human-machine
interaction, these markers of human action are persuasive, but likely
to contribute to bad policies.

Further levels extend the functions which are automated. Levels 2-4
have automated systems capable of making all the electromechanical
inputs necessary to drive; they differ only in the extent to which
human stewardship is necessary.\cite{???} This exposes naïve assumptions about
how vehicles will be automated: one whole system at a time. How much
control is handed back when the human has to take over more vehicle
operation tasks is not clear: One primary control function? All
primary control functions? The NHTSA is trying to define an overall
automation level for a vehicle, but their definition masks system
specificities. The report is not clear on the level of automation for
a vehicle in which some control systems require continuous monitoring
and others can transition to manual control on an appropriate
timescale. And the NHTSA's taxonomy rests on the assumption that the
work of driving a vehicle will remain basically the same, some tasks
simply shuffled to the computer—system control first, monitoring of
control second—with no new cognitive loads placed on the human as a
result. This too is a na\"{\i}ve position that is not supported by current
examples of automation technology, which often result in the
generation of new types of human work (such as monitoring the
automation system itself).

Contrasting the NHTSA's model with the SAE's provides a deep look into
the priorities of the organizations. The SAE document provides a full
taxonomy of levels of automation for ``on-road motor vehicles,'' and the
presumed audience consists of engineers not policymakers.\cite{???} The report
focuses on the three ``highest'' automation levels (``conditional, high
and full automation''), implicitly because these are the newest areas
of research and therefore the most important. The report is careful to
distance itself from the terms ``autonomous'' or ``self-driving'' as used
in the media, preferring instead its own carefully-defined
terminology.\cite{???} 

The SAE report does try to square itself with NHTSA recommendations,
however approximately, and represents the hidden difference between
NHTSA's levels 2 and 3 as the monitoring of the environment by the
vehicle (in level 2 the vehicle does not monitor, and in level 3 it
does). In contrast, the NHTSA report does not make this plain, and
indeed a level 2 system can be said to ``relinquish control with no
advance warning'' which is impossible without either knowledge of the
environment or the occurrence of a bug—the system needs something on
which to base its decision to “relinquish control” if such a decision
can be said to be made.\cite{???} Rather than overloading the word ``control,''
the SAE considers the ``dynamic driving task'' to have a number of
components, including the detection and classification of objects and
events, the response to such events, planning of maneuvers, steering
and turning (including lane-holding and changing), acceleration and
deceleration, and ``enhancing conspicuity'' (referring to lighting,
signaling, gesturing, etc.).\cite{???} Like the NHTSA's taxonomy, the SAE's
document focuses primarily on four major aspects of this task:
steering, acceleration/deceleration, monitoring of the environment,
and fallback performance, but is somewhat clearer about how tasks are
defined—in particular, it is clearer about the separation of the
driving task into longitudinal and lateral components. Also like the
NHTSA, the SAE's definitions show all systems above level 1 having the
full electromechanical capability to drive the vehicle (to execute
both longitudinal and lateral driving tasks) which makes it difficult
to account for complex hybrid systems in which some tasks may be
highly automated and others not.

The primary distinction is whether the ``human driver'' or ``automated
driving system'' monitors the driving environment.\cite{???} The report deals
appropriately with human psychology, stating specifically that higher
levels of automation are based on the expectation that the human need
not ``and therefore will not''\footnote{Attention and task hand-over are
  known issues in aircraft automation, as prolonged inattention leaves
  pilots ill-positioned to regain control of systems when necessary
  (see for example the events leading up to the Air France 447
  crash). This will be a particular focus in \ref{chap3}} continuously
monitor the environment.\cite{???} But their 
picture is still binary, rather than considering the moment-to-moment
distribution of human 
cognitive effort. This is implicitly connected to their inclusion of
the lower levels of automation only ``as points of reference to help
bound the full range of vehicle automation''\cite{???}: they are not within
the document's focus, which favors an implicit---to the NHTSA's
explicit\footnote{The NHTSA explains this by deferring to existing
  laws: ``Generally, these laws seem to contemplate vehicle 
automation at Levels 3 and 4, as discussed above, i.e., some form of
self-driving operation. 
Accordingly, these recommendations are tailored to Levels 3 and 4
automation.''\cite[p. 10]{???}}---rhetoric of progress toward the
higher levels of autonomy. 
Not only are hybrid task monitoring systems classified as level 2
regardless of their complexity or capabilities, the SAE's taxonomy by
definition leaves out whole classes of systems where the default
execution of the dynamic driving task is up to the human but
monitoring/fallback performance are computerized, or where the dynamic
driving task is shared in a complex way, as is monitoring and fallback
performance. It considers only systems in which longitudinal and
lateral control is handed over to the system earlier in the hierarchy
than monitoring or fallback performance. The SAE is better about
identifying new types of human work, such as the monitoring of the
automated system, generated by partial automation
strategies.\footnote{For instance, the human driver ``constantly
  supervises dynamic driving task executed by driver assistance
  system.''\cite[p. 3]{???}} They
are also more conscious of issues of the handover of control, and
specifically discuss delayed-release of particular tasks ``when
immediate human takeover could compromise safety,'' slowly
transitioning control of a system from fully autonomous to fully
manual though never lingering in between.\cite{???} 

The SAE mentions the true complexities of driving at the report's end,
describing how the dynamic driving task is distinct from driving:
``Driving entails a variety of decisions and actions, which may or may
not involve the vehicle being in motion or even being in an active
lane of traffic.''\cite{???} Driving is split into Strategical, Tactical, and
Operational components, where strategical includes trip planning and
route selection, tactical includes maneuvering, while operational
involves ``split-second reactions that can be considered pre-cognitive
or innate.''\cite{???} The SAE is explicit about their exclusion of Strategical
effort, presumably the human's task, from the definition of the
dynamic driving task. However, this admission does expose an
inconsistency within the SAE's taxonomy: level 5 automation (and some
types of level 4 automation) definitionally require Strategical effort
(route selection is implicit within GPS navigation), which is not
separately mentioned as a system capacity in the document.

Both taxonomies ignore the external labor involved in automation:
human action displaced in space and time. Where do remotely monitored
systems fit? What about human preparatory work that allows for
automation? These are questions to which we will return in \ref{chap3}.

\subsection{Researchers in the Field}

<use interview material, and material from talks>


%% 3) (or worked in to each of the previous) current research
%%--not historical, but actual last-20-years papers about this
%%--examples of where ideologies bleed through!!!!
