\chapter{Narratives and Counternarratives}
\label{chap:2}

%% was sources \& ideologies
%% 2. Where is that coming from?
%% -Sci-fi and historical dreama
%% -a cultural vision of automation of work
%% -AI history
%% -NHTSA/SAE policy/standards (instantiated in)
%% -researchers in the field!

%Reconsider numbers in subsection headings


%%1) science fiction; feels disconnected from the meat of the chapter
%%could be introductory to whole thesis
%%or may need more depth

%%2) designed dreams needs more work; 
%%signal connection: designers thinking about science fiction
%%possibly remove designed dreams from title

%%3) stronger punch/framing MY argument in the historical overview
%% around p30 ``the narrative of the automation of work''. . .

%%4) more to define what is at stake in engineering standards/policy
%%docs; why I quibble with their definitions
%% I may be able to do this drawing on the other subsections
%%as a CONCLUSION, wrapping up the other three things
%%and what is LOST/OVERLOOKED; the ability to deal with nuance and
%%REAL ACTIVITY
%%other part of an analysis of this kind of stuff: did it for a
%%reason; what is the work that it does (reactionary thing in some
%%cases; pushes for a particular image of what this can be)
%%--visions of human; SAE history of thinking as engineers; people as
%%predictable black-boxed inputs and outputs
%%--NHTSA as reactionary, as trying to cope with what Industry says;
%%and as history of dealing with people and responsibility in
%%particularly binary ways; REAL PRESSURE to get it OUT THERE to guide
%%development
%%maybe split into different sub-headers with context like NHTSA:
%%Agency Trying to Catch Up or w/e

%%5) not a good conclusion to the chapter so far; should have a sense
%%we have gotten somewhere and learned something


The popular narratives about self-driving vehicles have not appeared
out of nowhere. But what are their roots? What are the sources from which
these stories come, the founts of technological ideology from which
they spring? Journalistic accounts of technological change are of
course impacted by a wide variety of practices and perspectives, from
the market and readership needs of news organizations to the pervasive
culture of commodity scientism.\cite{smithSelling} The
reasons for why these stories take a particular form may be innumerable
and difficult to pin down, in general. But specifically regarding the ways that
driverless cars are figured in the press as autonomous machines, there
are a number of identifiable sources for these ideological slants and
modes of rhetoric: science fiction, factory automation history,
artificial intelligence, and current engineering and policy documents. Some of
these sources themselves have more direct impacts, such as
policy documents that stand to shape the way state legislation proceeds. Each,
in its turn, impacts the popular narrative in specific and important
ways, which must be understood if we are to come to grips with the
question of why we see a particular dominant narrative:  why vehicle
automation appears, at least on the surface, in the way that it does.

\subsection{Science Fictions, Designed Dreams}

Technologies, with rare exceptions,\footnote{One could argue that
  vulcanized rubber, for example, as an accidental discovery does not
  fit this pattern.} are imagined before they are made, through design
fictions and/or science fiction. These future
visions serve a number of purposes: they inspire scientists and
engineers,\footnote{In fact I think it would be exceedingly rare to
  find an engineer who was not influenced by science fiction. My
  interest in AI has been driven by \emph{Star Trek} and \emph{2001: A
  Space Odyssey}, the latter perhaps more morbidly than the former. A
  colleague of mine cites Neal Stephenson's
  \emph{The Diamond Age} as key to shaping his interest in
  computational linguistics and human-machine interfaces.} they serve as design
studies for the possible shapes of technology, and they act as
playgrounds to investigate the cultural impacts of technologies, among
others. Though created in different contexts, with potentially
different levels of scholarly care, these two types of fiction are not
neatly delineated, and are unified in as sources of insight into what
might be possible with technology. ``Design fiction is the cousin of
science fiction,'' as Julian Bleecker puts it, and represents a hybrid
practice that attempts to negotiate between facts and wild, playful
imaginings to bring light to the multiplicity of possible
futures\cite[p. 8]{bleecker} It would be wrong to categorize science
fiction as categorically less relevant, however: science fiction
films
often involve scientific consultants with real
technical knowledge related to the technologies they are responsible for
helping bring to life on screen. These depictions become what David
Kirby calls ``diegetic prototypes'' which are used to ``demonstrate to
large public audiences a technology's need, benevolence and
viability.''\cite[p. 43]{kirbyFuture} Kirby connects prototypes---in
Suchman's terms ``performative artefacts''\cite[p. 45]{kirbyFuture}---a primary
``driver of technological innovation,'' to these diegetic prototypes,
by recognizing both their similar rhetorical roles as well as the
ability of diegetic prototypes to mobilize funding for real-life
prototypes\cite[p. 44-47]{kirbyFuture} Science fiction, then, has deep
and compelling relationships with real engineers and engineering via
its depiction of aspirational (or cautionary) futures.

%%COnsider citing the Suchman article itself in Kirby

But science fiction is also a perennial source of popular metaphors and ideas
about technological change, in part perhaps because the visions are so
compelling, but also because they are so easily available. While these images
do not issue forth from a vacuum, as we have seen---coming from a potent combination
of actual engineering and scientific developments mixed with the imagination---
science-fiction images represent easily-digestible cultural reference
points for technological stories in the popular press. From Asimov to \emph{Terminator},
these sorts of pictures are endemic to discussions of artificial
intelligence in the press, and are often mobilized specifically to
illustrate the possible forms of automated vehicles. Stories and ideas
about what autonomous cars will be are
influenced by \emph{Minority Report}\cite{fromHollywood}, \emph{KITT}\cite{wadeKITT}, and \emph{Total
  Recall}.\cite{pasdirtzSolution} Countless articles begin by describing
self-driving vehicles as a Hollywood or science-fiction
staple.\cite{scifiToReality} \emph{Minority Report} is of particular
importance in this context, not only because it is so often referenced
but because its depiction of automated vehicles was developed in
consultation with Harald Belker, an automotive designer responsible
for both numerous Hollywood collaborations as well as real-world
products.\cite{melansonMinority} But popularly referenced fictions are
not all so contemporary. \emph{The Jetsons}, though
the show did not actually foreground driverless vehicles, also get
recalled as a source of inspiration due to the role of flying cars,
which trigger similar visions of wild 
futures made possible through technology.\cite{JetsonsAge} 

%%Harald Belker, minority report

Many, indeed most, articles seem ignorant of the actual research
history that inspires and is inspired by successive generations of
science and design fictions. Some articles, especially from more
scholarly establishments, bring up 
the pioneering work done by Mercedes and Ernst
Dickmanns in Germany in the 1990s.\cite{HCRIDriverless} But few connect
autonomous vehicles today as part of a long research history going
back to the 1960s, and an even longer set of engineering dreams going
back at least to the 1920s. Such narratives would be at least as
valid, in their own way, as connections to science fiction, but I
suggest that some of the shock value of the technology would be lost
by linking it to a deep history of research and effort. Connecting it
instead to the dreams and aspirations of Hollywood cinema makes it
more novel, exciting, even magical; and the few references to past
technology projects are relegated to their symbolic value only, used
to express a sense of impatience and technological inevitability: ``isn't
it about time?'' This hype-mindset fits the business
goals of many news outlets interested primarily in page-views.

The few historically-specific 
dreams\footnote{Rarely mentioned are other contemporary research
  initiatives such as the work of Vladimir Zworykin at RCA. His
  concept, inspired by “railroad block signals,” used circuits
  embedded in the road to magnetically sense vehicle speed and
  location, nearly the opposite of GM's plan in terms of where sensing
and control occurs.\cite[p. 9]{wetmore} Zworykin's centralized planning model would send
instructions to individual cars, and a 1/40th scale demonstration
system was built for the 1960 Highway Research Board meeting in
Washington D.C. GM also built a test system in the 1950s that took
advantage of their (now defunct) ``Unicontrol'' joystick to allow
automated control of steering and acceleration/braking, but their
system located much of the sensing and control within the car
itself.\cite[p. 8]{wetmore} At the 1964 New York World's Fair, a
second Futurama exhibit by GM presented an automated highway concept
called the ``Autoline'' that works much like Zworykin's
system.\cite[p. 9]{wetmore}} that do filter through into the narratives of autonomous
technology\cite{CBSPetersen} include the 1939 World's Fair, at which auto companies
previewed a city of future. The great success of the fair was GM's
Futurama exhibit: the line for the exhibit routinely stretched to two
miles in length, and 28,000 people visited the exhibit each day. The
Futurama exhibit presented an idea of what the world would look like
in 1960.\cite[p. 371]{nyeElectrifying} The focal point of the Futurama
exhibit was a bird-eye view of a future city with multi-lane elevated
expressways filled with largely automated vehicles. GM's Firebird III,
from the 1950s, is also occasionally remembered due to its publicity campaign and
subsequent cultural presence,\cite{walshVs} despite that the vehicle actually
contained no autonomous technology of any kind.\cite[p. 7]{wetmore} It was
itself an engineering fiction. 

These fictions are powerful because in their projections into the
popular discourse they cease to answer to logic and
sense. They draw upon emotions, hopes, and aspirations. Driverless cars
are in part works of theater, objects of technological spectacle which
are not yet truly real, despite their existence as physical objects
which can be photographed and experienced.\footnote{And in this way
  they are similar to concept cars of other types, which are designed
  to embody company ideals, brand languages, and generally act as
  advertising as much as design studies for actual future vehicles.}
Such real-world contact is 
yet limited to a lucky few. Google hosts special press events to allow
select journalists
to ride in their automated vehicles. Their capabilities are touted,
advertised, but their media picture is still tightly controlled. Not subsumed
to the mundane, the quotidian,\footnote{Certain articles from people
  who have actually gone for a ride in these vehicles stress the
  boredom and mundanity that comes with operating this
  technology.\cite{rode500} But this does not represent the
  preponderance of coverage. It also should be noted that boredom
  always comes with the potential of its opposite. Operating automated
systems can involve, as Sheridan describes, ``hours or boredom
punctuated by moments of terror.''\cite[p. 339]{sheridan}} they still possess that magic that
makes science fiction connections obvious and compelling. But this
does not mean such connections are unproblematic. Far from it. By
their alignment of these vehicles to science fiction, popular
narratives emphasize images of the technology as it has already been
envisioned, and obscure the multitude of potential implementations
that can emerge from engineering practice in the moment. Self-driving
cars threaten to become natural and obvious, in a particular form,
through their associations with existing, known and culturally
assimilated media portrayals.

Close cousins to science fiction representations, the statements of
researchers themselves are also responsible for 
shaping conventional narratives of autonomous vehicle
development---through the making of their own design fictions,
technocultural dreams that motivate their research.
Since automated vehicles have the potential to reshape many areas of life, it should
be no surprise that the cross-section of researchers interested in the
technology is broad indeed. Some are vehicle engineers (e.g. John Leonard), some of whom have been
interviewed by the press or had their research papers picked up by news outlets.
Others are mathematicians and
computer scientists (e.g. Paolo Santi) working on other problems related to
autonomous vehicle systems. And yet others are designers (e.g. Carlo
Ratti of the SENSEable City Lab), urban
planners, or traffic safety experts interested in how the next
generation of vehicle systems will
affect our cities. The breadth of people involved means a breadth of
technical competencies. And many (though not all) of these contributions buy into the
implicit teleological progress narrative, whether or not they expect
driverless cars to be feasible in the market soon.

One particular strain of ideas comes from those interested in the
social benefits that would accrue if and when cars could be automated.
Daniela Rus of MIT's CSAIL speaks of ``data-driven mobility'' and the
idea of using the affordances of automated vehicles to improve traffic
patterns.\footnote{Speaking at The Road Ahead Conference, hosted by
  the MIT SENSEable City Lab, Cambridge MA, November 21, 2014} Taking
data from phones, road cameras, satellites, and other 
sources already provides the potential of forecasting congestion, from
this perspective,
provided we ``put it all in the cloud'' so that it can be collated and
queried at scale. While this approach allows incentivizing individuals to drive at
different times or use different routes, widespread use of autonomous vehicles would add
the possibility of moving vehicles around based on predicted or
current demand, and therefore potentially reduce the number of
vehicles needed to move people in a city. Researchers at MIT and Stanford, as part of the
SMART\footnote{Singapore-MIT Alliance for Research and Technology} initiative, have
performed mathematical modeling work on this topic, and found that a
significantly smaller number of cars could supply all the mobility
needs of Singapore if they were automated and could respond to demand.
Specifically, their models suggest that 300,000 vehicles could serve
all mobility needs during peak times with waits of less than 15
minutes, and even a fleet of 200,000 vehicles could reduce wait times
to about 3 minutes during off-peak hours.\cite{frazzoliSingapore} This
compares to 779,890 passenger vehicles actually owned in Singapore,
according to 2011 numbers.

Along similar
lines, Christian Zulberti of the ENEL Foundation\footnote{A non-profit
  energy and sustainable innovation research group.} envisions using
autonomous vehicles to remove traffic lights in
cities.\footnote{Speaking at The Road Ahead Conference, hosted by
  the MIT SENSEable City Lab, Cambridge MA, November 21, 2014} And Paolo
Santi of the MIT SENSEable City lab talks of replacing traffic lights
with a slot-based system, using cars that can communicate with each
other and with infrastructure to double the capacity of the
roadway.\footnote{Speaking at The Road Ahead Conference, hosted by
  the MIT SENSEable City Lab, Cambridge MA, November 21, 2014} Each vehicle would request a slot to pass through the
intersection, and would be instructed to proceed according to the
orchestrate of a central control system. This would be the coming-to-fruition of
Vladimir Zworykin's work at RCA from the 1950s. Singapore is engaging in
controlled vehicle tests to work on just such ideas, to improve car
sharing with vehicle-to-vehicle communications and predictive traffic
patterns.\footnote{Lam Wee Shan, speaking at The Road Ahead Conference, hosted by
  the MIT SENSEable City Lab, Cambridge MA, November 21, 2014} As we
might expect, these
design concepts and stories have telling connections to each other, and
to a web of other fictions, meshing well with the automated vehicle
infrastructures envisioned by science fictions such as \emph{Minority Report}.

Returning to reality, however, these concepts assume particular
communicative competencies. While 
some would seem to require fully-automated vehicles, other
visions are amenable to a variety of different types of automation.
But all assume varying levels of persistent, networked surveillance of
vehicle positions, and require vehicle-to-vehicle or
vehicle-to-infrastructure communication channels to send and receive
data and instructions. Several of these ideas also seem to present
particularly classed views of who driverless technology would serve.
An intersection that requires an electronic device to request a slot
to cross will not gracefully tolerate the poor, or really anyone who
does not own a smart car or smart phone, whatever his or her age,
race, class, or situation. Utopian visions of doubled capacity, when
described (as this was) as halving the wait-time to get through an
intersection, forget the complex dynamics of human behavior and our
tendency toward homeostasis of inconvenience: city planning has found
time and time again over the last 50 years that increasing the
capacity of roadways does not result in less congestion, only more
people driving.\cite[p. 219]{marshallFuture} One researcher I talked
to put the problem in terms of Jevon's paradox: at some point,
efficiency improvements will saturate, ``so the only true mechanism
[of reducing congestion],
at least the one that's been proven, through research, is pricing, is
through taxation.''

Nevertheless, these
sorts of envisioned futures support a get-out-of-the-way rhetoric
among their supporters. As another suggested to me in an interview:
``privacy-nuts'' and ``soccer-moms'' will be disturbed by the
technology, but we should press forward anyway. Such dismissive and
derisive categorizations, applied nonchalantly, suggest that anyone
getting in the way of progress is either a luddite or a fearmonger who
does not understand the technology. 

Another prominent design fiction regarding autonomous vehicles focuses
on personal mobility, especially for the elderly or disabled. Ryan
Chin, a notable researcher in urban mobility systems at the MIT Media
Lab, has worked on these systems as part of the Smart Cities
initiative. He suggests that in a world with an aging population, and
especially in the United States given our often lacking public
transportation infrastructure, personal mobility for a growing
population unable to drive themselves should be one of the primary
goals of future development.\footnote{Discussion with the author,
  August 20, 2014} Mobility, as an aspect of personal agency, is very important both
for one's ability to live and provide for oneself, as well as for
fostering independence and feelings of self-worth. As a side benefit,
one researcher noted, providing automated mobility solutions should
help persuade more senior citizens who can no longer drive safely to
give up their licenses voluntarily, rather than risk a serious
accident.\footnote{This is especially true for those who do not have a
  family member they can count on to assist them.}

This primarily automotive vision is not the only model of urban
mobility through autonomous systems, however, and is fraught with
certain problems. John Leonard, an MIT researcher who was involved
with the DARPA Urban Challenge in 2007, has gone on record as a critic
of replacing cars with driverless vehicles on existing infrastructure.
Not only do weather conditions and negotiations with pedestrians and
other cars present potential issues, interpreting the gestures of
police officers and dealing with other atypical road events also make
this a troubled vision. One alternative is the PRT, or Public Rapid
Transit, model, which is already being deployed in certain
geographically restricted areas. A PRT researcher I spoke to
enumerated the benefits to the approach: separate tracks with
controlled access greatly simplify issues of collision detection and
negotiation with other vehicles, and reduce risks of collisions if
they occur. Of course, controlled access requires new infrastructure,
and seems to call to mind the famous failure of the French Aramis PRT
project, so comprehensively covered by Latour in \emph{Aramis, or the
  Love of Technology}. 

What gives us confidence in these visions? Why don't they seem
outlandish, like some of the works of science-fiction with which they have
been grouped here? Some of this has to do with their manner of
presentation, lent the gravitas of ``science'' by emanating from
scientists rather than from the
illusionary powers of Hollywood. But some has to do, instead, with other historical images
that are part and parcel of
popular autonomous vehicle narratives, ones that are not connected
with vehicles at all. And among these is the assimilated cultural
understanding of the history of factory labor and the automation of
work.


\subsection{The Automation of Work and its Untold History}
%% 1.1) deep history is the mechanization/automation of work (4 p)
%% --going back to factories/IRev: replacing human competencies with
%% machine competencies and moving the people into new roles
%% --which engages old debates about the role of the human

Human technological progress since antiquity has
involved continual re-negotiations of human labor and the roles of
animals and mechanisms in the labor process. Due to a confluence
of factors---the miniaturization of computing technology, new
advances in machine learning and artificial intelligence algorithms, a
gradual increase in battery capacities, faster wireless networks---the
horizons for everyday automation are broader now than ever before. 

But though the focus is on the future, our past is deeply involved
in its presentation. News articles fret
about what will happen when no one knows how to drive manually any
more,\cite{pross} a classic fear of ``de-skilling'' that is implicated in so many
other implementations of computers. Furthermore, coexistence with
autonomous or automated systems is sometimes presented as a fundamentally new
situation, as if human beings had never before had to work and live
with and next to automated systems, presenting new benefits and
dangers, and requiring new roles for their human tenders. However,
automation already has a deep 
history in the industrial sector. Current debates and fears about de-skilling, human jobs,
and the role and value of human labor return us to questions that have
plagued factories, and labor's relationship to machinery, since the
early Industrial Revolution. But as we have already seen with the common
elision of the actual research history of self-driving vehicles, the
stories that get told about driverless cars and factory automation are
primarily those rooted in the cultural consciousness, rather than in
nuanced, factual histories.

One of the commonly referenced histories of automation is that of thee
textile mills of the early 1800s, in which a large
proportion of hand-labor was replaced by steam- or
water-powered industrial machinery, and which has entered our collective
consciousness. The
story here is a familiar one: skilled artisans made obsolete by the
lower cost and higher productive capacity of mechanical labor.\cite{pewPositive} By
analogy, new types of skilled labor (taxi and limousine drivers, or
even bus drivers) are now under threat, and their fate should be no
different than that of the workers who came before.

The automation of factory work is an
important touchstone for narratives about the automation of driving
and the creation of autonomous vehicles. But just what the
processes of standardization, mechanization, and automation (or
``automatization'') have done to the factory, and to laborers in it, is
not clearly understood among many who write about autonomous cars. Within this
forgotten history---which is substituted for by an imagined person-less
factory that does not exist in the real world---there are even lessons to be
learned by the research community. This past is relevant, perhaps
more than ever, to the future of transportation.

A search for the beginnings of industrial automation takes us to the middle of
the 18th century: Vaucanson's mechanical loom dates to 1741, and formed the basis of
 later developments in weaving by Joseph Marie Jacquard.\cite[p. 9]{dieboldImpact} 
But the first example of ``complete'' industrial automation originating in the
United States does not come until Oliver Evans' work in the 1780s on
automated grist mills.\cite[p. 5]{roesmithYankee} Through a series of elevators and descenders,
horizontal screws, spreaders and rakes, his mill moved grain from raw
agricultural commodity to finished product: sifted flour. And ideally,
all parts of the process would occur without human intervention. 

In reality, the process both increased efficiency and decreased the costs
of production, so much so that the same basic machinery is still in
use today in some smaller milling operations.\cite{wyegrist} None of his individual
inventions---which he lists as the elevator, ``conveyer,'' hopper-boy,
drill, and descender in his 1795 miller's guide---was a particularly
groundbreaking achievement, but what Evans did was place these devices
in succession so as to allow continuous production, and the
elimination of many slow human jobs that degraded the quality of the
product by tracking dirt and contaminants around inside the
mill.\cite[p. 203]{evansMillguide} 

It took some time for the high level of automation found in the Evans
mill to spread across other industries, and the mill may find its
closest cousins in the ``automatic'' factories of the 1950s and 1960s
and the roboticized factories of today, but Evans's contemporaries
were not uninterested in increasing efficiency and output. Paul
Revere, one of America's early industrialists, applied shifts in
manufacturing techniques to transition himself from an
artisan worker to manager and overseer of others over his long
metalworking career.\cite[p. 187]{martello} Like a small number of his postrevolutionary
contemporaries, he improved his circumstances by becoming a manager
and owner rather than a laborer, but manufacturing itself was a site of public
debate, pitted against the ``inherent virtue'' of agricultural pursuits.
Tench Coxe, a political economist, wrote in 1810 that ``new machines
and power sources allowed even greater productivity with less labor,
further underscoring the connection between technology and republican
virtue.''\cite[p. 217]{martello} To Coxe's romantic view, these machines  worked ``as if they
were animated beings, endowed with all the talents of their inventors,
laboring with organs that never tire, and subject to no expense of
food, or bed, or raiment, or dwelling.''\cite[p. xxv]{coxe} Though we
may have lost this romanticism, we haven't lost this perceived
animism. Automated machines, like self-driving cars, continue to
excite, impress, and cause fear due to this transformative, if
mechanistic, alive-ness.

But these romantic words did not represent the whole reality of
industrial machine labor. Human labor of
maintenance and supervision is implicit in these manufacturing
machines---even the Evans Mill---but it is rendered invisible by the rhetoric that the
machines themselves require no bed or board. At the same time, Coxe's
use of the word ``endowed'' should focus our attention on exactly which
of the ``talents'' of the inventors have been automatized, and the human
labor necessarily involved in that conferring of capabilities. 

Robotic cars are sometimes situated as
the next step for robots after the factory, their final emergence into
the real world having conquered the factory floor.\footnote{See for
  example ``Robot Vehicles'' in RobotWorx \cite{robotworx}, which describes automated cars as having the sensors
  industrial robots have had for many years.} The history of
automation that gets mobilized is one of a teleological progression
toward complete automation of all sectors of work, which does not do
justice to the historical details involved. The tendency to gloss
automation in this manner seems
to be deeply aligned with the struggle of certain groups of
middle-class laborers to keep their jobs in the face of changing
factory conditions. Among the most public and most topical of these
are the Detroit autoworkers, once a bastion of middle-class
respectability, many of whom faced unemployment with the rise of
Japanese (popularly read as: ``highly automated'') automotive
might.\footnote{It is worth mentioning here that the ``lean
  production'' techniques largely responsible for industrial
  efficiency of Japanese automotive companies are not primarily about
  automation. Though automation is involved, the essential core of
  \emph{kaizen} manufacturing is increased trust between management
  and labor, assisted by continual communications and high job
  security.\cite[p. 198--199]{nyeAmericas} These na\"{\i}vely seem
  directly opposed to automation.} There is some truth to this, though the actual story
is far more complicated and has less to do with automation and more to
do with product priorities and other labor
relations.\cite[p. 188--200]{nyeAmericas} The actual historical
circumstances are, in this case, less important than the general perception that automated
systems, such as the robotic arms used for painting and assembly, are
reducing the overall pool of available jobs.

Modern automotive manufacturing is not alone in presenting conflicting ideas
of what automation can do. Arsenal practice was the site of multiple revolutions in U.S.
manufacturing technology through the 1800s and early 1900s, notably
the development of the so-called ``American system'' of interchangeable
parts, through which a gradual increase in mechanization would seem to
continue, driven by the tight tolerances necessary for this production
method. And yet armorers and managers at Harper's Ferry resisted the
mechanization of their craft,\footnote{Blanchard's many automatic
  machines for making gunstocks were of particular
  importance,\cite[p. 56]{roesmithHarpers} but a wide variety of machinery
  was implemented in the gun-making process at Harper's Ferry. Most of
 these machines still required significant human labor. Nash's
 barrel-turning machine in part mechanized the production of barrels
 of standardized dimensions: it consisted of a lathe on a wooden
 frame, with human-operated props to hold the barrel in
 place.\cite[p. 119]{roesmithHarpers} The worker also had to continually
 measure the barrel with a caliper, and adjust the device's chisel
 appropriately.\cite[p. 121]{roesmithHarpers} This gradual implementation of
 mechanized labor was continued in further machines produced by Hall.
 His straight-cutting machine, an early version of a milling machine,
 had as its distinctive feature the ability to be tended by ``common
 hands'' without a loss of
accuracy.\cite[p. 239]{roesmithHarpers}}, and while certain competencies were
transferred from the skilled worker
to the technical apparatus, human oversight and operation was still
integral to the production of weaponry using the new technology. It was
not clear until after the fact that more mechanization was necessarily
better: Harper's Ferry remained ``competitive'' with
costs at the more highly automated Springfield Armory through the mid
1830s.\cite[p. 324]{roesmithHarpers} 

The same exchange of competencies characterized Ford's assembly line
production as well, which is cited by David Hounshell as the rise of
true mass production in America.\cite[p. 217]{hounshell} Ford's factory developed fixtures
and gauges, designed to allow for use by unskilled machine tenders. As Donald
Norman writes in \emph{Things That Make Us Smart}---and as Ed
Hutchins describes in his cognitive anthropology practice,
particularly his work
on distributed cognition
systems\cite{hutchinsCockpit}---``the world remembers things for us, just by being
there.''\cite[p. 147]{normanThings} But while the gauge simplifies the
assurance  of quality, it does not
automate it:  it simply changes the effort from a more complex judgment
of quality and measurement to a simpler one. While he instituted the
five-dollar day to attempt to solve labor problems at the factory, and
compensate laborers for becoming part of the ``production machine,''
Henry Ford also attracted a wide variety of well-educated skilled mechanics
to his automobile plants.\cite[p. 223]{hounshell} Like Evans, Blanchard, Hall, and others
before them, these mechanics applied their skills to design machines,
and simplify and standardize work processes. The individual judgment
of the assembly line laborer was displaced into standardized tools and
fixtures, built into these technologies by the labor of skilled
machinists and designers. This displacement of competences is still in
evidence in automation today, but is an often-neglected part of the
discussion of self-driving cars. The prevailing taxononies of
automation\footnote{By the NHTSA and SAE, discussed in more detail at
  the end of this chapter.} discount the displaced labors of route
mapping, programming, and system supervision. The driver, by these
standards, is only the person sitting in the seat. Those orchestrating
the course of a vehicle from outside---days or months before, or
observing in real-time from a server room---do not count where levels of
automation are concerned. The new labor generated by automation has
been made structurally invisible, as it has been in the cultural
narrative of factory automation.

Also around the turn of the century, Taylorism in factories created ``new managerial
functions'' performed by ``new classes of people with new titles and
more clearly specified responsibilities.''\cite[p. 120]{aitken} A focus on the
people---who are they? where are they? what are they doing?---shows that
one of the fundamental and enduring characteristics of Taylor's
system, the expansion of management roles and the further division of
labor, is not about mechanical automation but about new and altered
types of human work. Industrial processes in the early 1900s continued
the removal of management and strategic decision making from the
workers most physically engaged in product production, installing it
instead within formal organizational structures and the employees that
constituted them. 

This pattern of delayed recognition and contingent change repeats for
numerical control in assembly line production. Numerical control (NC),
developed in the 1940s and 1950s as an outgrowth of World War II
research into feedback systems, slowly began to produce industrial
robots that could perform factory tasks without direct human
intervention. Robots slowly began to replace assembly line jobs such
as spray painting and welding, but adoption was gradual, with only
about 6,000 robots in use in American factories by the mid
1970s.\cite[p. 159]{nyeAmericas} Industrial robots, while automating tasks,
had a way of generating large contingents of skilled human laborers
who still needed to be paid for their services. Industrial robots were
complicated, and needed a variety of skilled workers to tend them, and
to repair them when the broke down. These early experiments did not
increase profits because of the volume of highly skilled labor needed
to keep the machines operating.\cite[p. 162]{nyeAmericas} The development of NC machines
proceeded with a specific interest in eliminating skilled workers, but
the jobs that disappeared were largely unskilled or semi-skilled
laborers.\cite[p. 164]{nyeAmericas} And while Norbert Weiner, in his 1950 book \emph{The Human Use of
Human Beings}, prophesied the end of ``deadly uninteresting'' jobs, which
would be mechanized within 20 years, such changes have still not
totally come to pass.\cite[p. 161]{nyeAmericas} To compound the problem, new industries of
skilled workers---record-and-playback machine designers, and NC machine
programmers---sprang up to furnish factories with their tools. This
historical thread should focus our attention on what is added, rather
than removed, by
autonomous vehicles: more complex computer systems may make the driving
task simpler for a given level of safety, but make the system
engineering task, and the tasks of maintenance and repair, more and more complicated.

Norbert Wiener, the famous cyberneticist, was asked to contribute to an
anniversary supplement on automatic machinery for the St. Louis
Post-Dispatch in 1953. The piece that he wrote, ``The Machine as Threat
and Promise''\cite{wienerMachineThreat} hailed the coming of the
robotic factory with his usual 
caution and good sense, but confirmed that ``automatic machinery of a
new sort is assuredly here to stay,'' machines that are ``coupled to the
outer world through the mechanical equivalents of sense organs.'' The
article's photographs by Edward J. Burkhardt, displayed above the
sub-heading, ``The Only Automation Plant in the World,'' show the
machinery of the Rockford Ordinance Plant in Rockford, Illinois, and
the men who tend them. The tenders, largely stoic and inactive, stand
and observe, sit quietly at machines, or push buttons on control
panels, surrounded by the motion of the ``largely automatic process of
turning steel bars into 155 millimetre
shells.''\cite{wienerMachineThreat} Around the same time, in Ford
Motor Company's Brooks Park engine plants, near Cleveland, forty-two
automatic machines ``linked together by transfer devices that
automatically move the blocks through the complete process, perform
530 precision cutting and drilling operations.''\cite[p.
  9]{dieboldImpact} Through the 1,545 feet of assembly line, no human
touched the parts. Such is the vision of the automated factory. In
truth an operator stood by each machine, ensuring its continued
operation. But this human labor, menial as it may be, is not often
recognized. One described his experience: ``I don't do nothing but
press those two buttons . . . Sometimes I use my thumbs, sometimes I
use my wrists and sometimes I lay my whole arm across.''\cite[p.
  10]{dieboldImpact} And yet,
despite the meniality of his labor, it is still integral to the
process of production: without it, the line would grind to a halt. The worker
no longer makes choices about how to bore a part, or which tool to
wield. But these choices have been built into the industrial equipment
he oversees. Instead, he monitors the state of the line and chooses to
turn the machine on or off.

But as control is further constituted within management, the roles of
management are rendered more and more menial themselves. The Air
Force's Integrated Computer-Aided Manufacturing program (ICAM)
brings to light further complexities in the story of the automated
factory: ICAM attempted to aid shop floor automation by automating certain
management functions, ``to try to reduce the enormous indirect costs
that have resulted from the effort to reduce labor costs and remove
power and judgment from the shop floor,'' costs that have continued to
dog new rationalization strategies.\cite[p. 330]{nobleForces} ICAM, like the mythical
ouroboros, sought to offer automation as the ``solution to the problems
generated by automation,'' providing automated scheduling functions,
inventory control, and design tools to ``provide better management
control'' and ``free management from excessive routine duties to do
creative work''---the creative work that the management had attempted to
place in their own hands, in the first place, through earlier
processes of rationalization.\cite[p. 330]{nobleForces} Automation, Noble's ICAM example shows,
can be used both to routinize work---for the manual laborer---and to
eliminate the routine in favor of the creative---for managers and newly
generated classes of creative workers. This is analogous to the
current process of self-driving vehicle design: automated systems
substitute the mechanical process of controlling the vehicle inputs
with the new task of the intellectual supervision of the driving
system. This new task is not necessarily simpler or easier, though it
may be intended to be, but can be seen as representing a management,
rather than labor, role in vehicle operations. The key issue this
should bring to light is
precisely how menial the human's role in self-driving car operation
will be, which is currently an open engineering question.

%%LOSING Thread of argument

The narrative of automation progress was once the province of
blue-collar labor only, but is now moving into such white-collar work as
well, which partly mobilizes the popular concern about next-generation
automation technologies that perform more difficult and complex
informational tasks. Self-driving vehicles make sense today because of
a general climate that believes in the possibility of automating
knowledge work, and their development feeds back in to the perception
that other complex tasks will soon yield themselves to automation. Bill
Gates, speaking at the American Enterprise Institute,
suggested that a large portion of the workforce will find itself
displaced by robots in the next 20 years, including accountants and
other white-collar
jobs.\cite{gatesRobots}
Gate's suggested remedies (low to no taxes and decreasing minimum
wages) are painfully biased toward corporate profits, but his comments play directly into
contemporary fears about automation, and only support the usual
narrative that job-loss due to automation is inevitable, and workers
(and by extension, professional drivers)
should just get out of the way. To this view, the last two hundred
years of innovation in automation is unidirectional and largely
undifferentiated:  from steam power to the assembly line, from
Taylorism to roboticization, each was yet another nail in the coffin
of the human worker---to be continued in the near future with the
elimination of drivers and the labor of navigating a vehicle. But
while it is undeniable that automation had changed the
character of human labor, this perceived uniformity in automation
processes is a figment of the collective imagination. As we saw,
Taylorism, while it attempted to more deeply control and rationalize
the work processes of the individual---in a way mechanizing her---also
created new classes of worker and expanded the role of human managers
in the labor process. Articles that posit factory work as a precursor to the automated
car, without going deeper into that history, implicitly accept a
vision of teleological progress that comes to color the conclusions
and possible futures presented. In truth, automation may look very
different depending on where in the hierarchy 
a person happens to fall, but the historical lesson is that human
involvement remains, though altered in space, time, and kind. As John
Diebold pointed out in 1953, there will be ``no worker-less
factories as a result of automation''\cite[p. 63-64]{dieboldNew}
precisely because human beings will be needed to construct, to repair,
to manage, and to oversee.

So we come to one of many contradictions at the heart of
automated vehicle research. Their promise:
to provide to us a greater measure of creativity\footnote{They claim
  to do so largely by allowing people to do something other than sit
  in traffic: to read, to sleep, to eat, to work. That this idea of
  automated vehicles as a time-saving convenience feature persists
  despite the potential for these vehicles to also eliminate
  enjoyable, skilled, and rewarding parts of driving is an intriguing
  contradiction. And, at another level, this idea disregards the fact
  that the automated vehicle has shifted since the 1950s from a
  potential family space to an extension of the working environment,
  which threatens its own sort of potentially uncreative labor.} in the act of
driving, to remove some of the ``menial'' and routine tasks of manual
control in favor of strategic decision-making. In this analogy, the
driver goes from being the manual laborer to the creative manager. But
despite a focus on relieving tedium, this is not the way these systems
have primarily been envisioned. Instead, in the process of following
the dream of fully automated operation---where the human labor has been
entirely removed from the shoulders of the person in the vehicle, and
displaced to the invisible labors of mapping, programming, and
monitoring---engineers are designing systems where the ``driver''
seems present largely to ensure the operation of capital-intensive
machinery, burdened with new but perhaps even more menial tasks of
machine tending.\footnote{See for example Tom Simonite, ``Lazy Humans
Shaped Google's New Autonomous Car,''\cite{simonite}  which discusses
the human role within Google's test vehicle,
and the company's response. This is purely speculation, but due to
the way the system operated previously, it is possible at least one Google
employee fell asleep at the wheel, which was the catalyst for their
concern and change in focus.} 

Why might this be? To understand it, we must understand something
about AI history, and the ideologies intertwined with artificial
intelligence research.

%% This approach
%% presents serious risks. It may be some time before the human inside
%% the car can be entirely disengaged with the driving task,2 if that is
%% even something we want as a culture, which means an interim period of
%% operation potentially characterized by “hours of boredom punctuated by
%% moments of terror.”3 The danger of human inattention,4 which has shown
%% up in aircraft automation with sometimes disastrous results, is
%% actually pushing aircraft manufacturers to more fully involve the
%% human in the process of flying, even as cockpits become more and more
%% computerized.5 And by focusing on ever more automation, rather than
%% appropriate automation, we may also be removing some of the parts of
%% driving that are most enjoyable: by replacing the skilled craftsman
%% with the automaton and the machine tender, we risk making driving
%% sterile and dull. 

\subsection{Artificial ``Intelligence'' and Its Cultural Resonance}
%% 1.2) place to introduce the brief overview of AI history, of what goes
%% into the different approaches
%% --starting from historical visions of automata (1 p)
%% --classical symbolic approaches / physical symbol system (3 p)
%% ----which in a way we have returned to today w/ explicit mapping
%% --Rodney Brooks subsumption architecture and ``world is its own best
%% model'' (3 p)
%% --Leaning heavily on H. R. Ekiba and his approach to illuminating the
%% unstated assumptions of AI research areas (2 p)
Artificial intelligence has its own history, distinct from that of the
automation of work, that feeds into driverless car narratives. Many popular
portrayals of AI care little about the actual history of the field,
and generally pull from major moments that garnered enough popular
attention to enter the cultural knowledge-base: ELIZA, Deep Blue,
Watson, and Siri. But coverage of advances in other artificial
intelligence tasks often cross-pollinates with self-driving car
coverage, either through direct reference or indirect association.
Some appreciation for the history of the field
of AI is important for understanding these moments as they are being
used, as models of progress and evidence of the technological inevitability of
self-driving vehicles. And the technologies of the moment, employed in
cars as well as other AI applications, are critical here. The history
of AI as conveyed through news coverage about self-driving vehicles is
not a complete one, but it is one side of the truth. And even
engineers ignorant of this history may make similar mistakes of understanding.

Intelligent machines are not a new idea. Just as automation has long
been a part of human history, dreams of artificial life suffuse our
legends. The myths about Hephaestus and
his creations, notably Talos, a golden female automaton, come to us
from antiquity,\cite[Ch. 1]{mccorduck}  but continue to be cited as historical antecedents in
literature on autonomous robots and their ethical issues.\cite[p. 3]{patricklin} Automata,
or rather semblances of automata, appear in Hellenic Egypt, with
priests as puppeteers pulling their strings.\cite[Ch. 1]{mccorduck} The history of
artificial life is intertwined with that of autonomous machines: the
creation of Pygmalion's Galatea echoes the same practices and
concerns, as does the story of Mary Shelley's “modern Prometheus” (of
particular note for the purposes of this argument, Shelley's vision of
artificial life is inspired and physically mobilized by static
electricity, the infusing of a ``spark of being'' into the creature; and
electrostatics were a highly public research topic and indeed public
spectacle, complete with live demonstrations, in the 1700s and early
1800s).\cite[p. 44]{shelley} Judah Loew ben Bezalel, a Talmudic scholar, is in legend the
creator of the golem, a being animated from clay who functioned as a
spy against the Gentiles.\cite[Ch. 1]{mccorduck} Though Loew's was not the only golem
recorded in myth, the rabbi occupies a special position among the most
prominent AI researchers of the 20th century: Pamela McCorduck records
that Marvin Minsky and Joel Moses grew up with a ``family tradition
that they are descendants of Rabbi Loew,'' and Moses claims a number of
other American scientists, including John von Neumann and Norbert
Wiener, also consider themselves among the descendants.\cite[Ch. 1]{mccorduck} This is all
to say that while the technological drivers of conceptual visions are
more contemporary, ancient myth and legend continue to subtly underpin
research in autonomy and artificial intelligence.

%% Drosz and Vaucanson
As Jessica Riskin chronicles in her studies of eighteenth and
nineteenth century automata, clever inventors, interested in going
beyond mere representation, created a variety of impressive
simulations of life---that is simulation in its modern sense, meaning
experimental models that can elucidate the natural, rather than its
contemporary sense which would have meant artifice.\cite[p. 605--606]{riskinDuck}
Makers of automata strove to imitate the very materials of life,
hoping to ``make the parts of their machine work as much as possible
like the parts of living things and thereby to test the limits of
resemblance between synthetic and natural life.''\cite[p. 606]{riskinDuck}
Automata of this era ``bled,'' ``defecated,'' and ``breathed,'' though some
of these functions were themselves faked, such as in the case of
Vaucanson's Duck. Nevertheless, imitation was central to the project,
and in this way these early automata prefigured at least some of the
developments in AI and Alife. These early simulacra, though little known and
rarely referenced today, provide critical background for the attempts
that followed. 

%% Steam governors
Many of these automata, despite being surprisingly accurate
mimeses of life, did little in terms of interaction with the
environment. Meaningful interaction requires closing the loop between
sensing and acting in the manner of a
 ``teleological,'' self-governing mechanism with corrective feedback.
 Indicative of Norbert Wiener's later research into cybernetics, such
 corrective feedback mechanisms had been studied since at least the
 late 18th century, when James Watt incorporated a governor into his
 steam engine. Watt himself had pulled from earlier applications of
 governors in windmills, which had been used since at least the 17th
 century.\cite{richardhills} James Clerk Maxwell, most famous for his equations of
 electricity and magnetism published in the 1865 paper ``A Dynamical
 Theory of the Electromagnetic Field'' (among the most important
 equations in physics), published a paper in 1868 on centrifugal
 governors in steam engines in the Proceedings of Royal Society. This
 paper, ``On governors,'' became one of the central papers in early
 control theory.\cite{ottomayr} Bringing together a number of existing
 areas including control theory,
 cybernetics---from the Greek \emph{cybernetes} meaning
 ``steersman''\cite[p. 6]{wienerMainIdeas}---extended their reach to more complex
 systems: ``control and communication in the animal and machine''. As
 Norbert Wiener puts it, control, or the
 feedback mechanism, is necessary for the extension of information
 theory into communication theory. Cybernetics envisions the world in
 terms of feedback mechanisms, which can be used to explain a variety
 of phenomena in living organisms: homeostasis, balance, and motion
 disorders like locomotor ataxia and Parkinsons all fall within the
 cybernetic sphere\cite[p. 10-15]{wienerMainIdeas}. And all are envisioned
 as outcomes of systems that pass messages internally. In this way
 cybernetics is a forerunner of the discipline of
 artificial intelligence, which is interested in re-creating many of the same
 self-regulating systems within computer systems---and which claims a
 similarly broad explanatory role, whether the goal is playing chess,
 investing in the market, or driving a vehicle. This replacement of
 competencies tends toward the obsolescence of the human being, and
 again is interpreted in many stories as a teleological process, a
 perpetual advancement of technological competencies.

Integral to the history of AI as a field is that it was fundamentally
interdisciplinary from the start. Like its forebear cybernetics, it
brought together researchers from physics, mathematics, biology, and
early cognitive science. The field began in earnest with the Dartmouth
Conference in 1956, which brought together many who would continue to
be preeminent researchers over the next decades. Hosted by John
McCarthy (who originated the name
``Artificial Intelligence''), Marvin Minsky, Nathaniel Rochester, and
Claude Shannon, attendees included Trenchard More, Oliver Selfridge,
Ray Solomonoff, Allen Newell, and Herbert Simon: all were united by
``the idea that there was a rigorous and objective way of explaining
the human intellect.''\cite[Ch. 5]{mccorduck} The research areas of
the ``Dartmouth Summer Research Project'' included language learning
and use, ``neuron'' networks,\footnote{Neural networks are one of the
  intriguing long-term stories of AI research, subject of much
  controversy over the years regarding whether or not they would
  actually work. A couple of theoretical developments altered them
  from a curiosity to one of the main techniques in modern AI. This
  half-century journey was presaged by the one sentence: ``Partial
  results have been obtained by the problem needs more theoretical
  work''.\cite{dartmouthconf}} self-improving machines, and computational 
creativity.\cite{dartmouthconf} Early successes spurred romantic
predictions, and by 1960, human-level intelligence was predicted by
some to be only a decade away.\cite[p. 3]{winston} Overexpectation, however,
lead to a first AI ``winter'' from about 1965 to 1970, in which the
grand promises of AI were shown to be much further off: the current
techniques simply did not yield advances at the required rate. As Pat
Winston put it: ``Everyone searched for a kind of philosopher's stone,
a mechanism that when placed in a computer would require only data to
become truly intelligent.''\cite[p. 4]{winston} But by the 1970s
research was improving, and excitement building again.


%% DARPA SCI
The early to mid 1980s were also a time of great developments in
Artificial Intelligence, an era of ``celebrity science,'' high hopes,
big investments, and subsequent great public disappointment with the
coming of another ``AI Winter'' beginning in 1987 and
1988.\footnote{These are roughly the dates Russell and Norvig give in
  \emph{Artificial Intelligence}\cite{russellnorvig}} But despite the
warnings of Roger Schank and Marvin Minsky, that overoptimistic
expectations for AI would result in another winter like the previous
one in the 1970s, overall expectations were high, especially within
the business community, which funded companies and assimilated AI
techniques into real applications.\cite[Afterword]{mccorduck} Though
the 1980s continued divides 
within the field about approaches to artificial intelligence, the decade
actually resulted in a wide variety of successful projects based on
improvements to expert systems, machine learning, natural language
processing, and computer vision.\cite[Afterword]{mccorduck} The 1983 US Strategic Computing
initiative, led by Robert Kahn at DARPA, had AI as its third focus
area, with ``image understanding'' and interpretation---made possible by
the digitized image---as long range project goals. In its revised
10-year plan, the initiative even included an autonomous land vehicle
alongside a pilot's associate and computerized battle management
software. The project suffered serious management problems, and
was eventually canceled, precipitating the general crash in AI
funding---through which research quietly continued, waiting for another
up-tick in public interest. But the Strategic Computing project,
whatever its lofty goals, was no failure. McCorduck cites Roland and
Shiman as saying that ``AI now performs miracles unimagined when SC
began, though it can't do what SC promised,'' which speaks to the
important developments that were made in the service of DARPA's vision.\cite[Afterword]{mccorduck}


Far from the generally accepted story of continued, natural
progression (that while AI may not have been possible before, it must
certainly be possible now due to continued development and greater
computing power), artificial intelligence proceeded in fits and
starts, and there are a number of approaches to AI research,
representative of different
ideas of how machine intelligence can be achieved. It is instructive
to look specifically at how three AI paradigms have envisioned their project.
Each is an answer to the question ``how can we build systems that
can operate without humans?''

%% Classical symbol approaches (3)
%%specifically w/ reference to ideologies
The first important AI paradigm is the classical symbolic system
approach. Associated with Allen Newell and Herb Simon, the idea of the
physical-symbol system hypothesis is that ``symbols lie at the root of
intelligent action''\cite[p. 109]{newellsimon}. Therefore not only
does intelligence require symbolic manipulation, it may indeed be
coextensive with physical-symbol systems, in other words a
physical-symbol system has ``necessary and sufficient means'' for
intelligence and intelligent action.\cite[p. 111]{newellsimon} Such
objects are \emph{symbol systems} in that they contain symbols and processes
that act upon symbols. And they are \emph{physical} in that they obey
physical laws and are realizable, in reality, through engineering.
These symbol systems would arrive at answers through a technique known as
heuristic search: by looking through a tree of possibilities in an
intelligent way, they arrive at the appropriate answer.\footnote{The key
  point of heuristic search is that such answers are approximate, but
  arrived at quickly, rather than exact, but arrived at slowly or,
  perhaps, never at all.} Intelligence is applied in heuristic search
by the pruning of the tree: rather than having to apply brute force to
search the entire space, an intelligent system applying heuristic
search makes decisions at each node as to which branches are most
likely to produce a good result and searches those.\cite[p.
  124]{newellsimon} As Newell and Simon wrote what makes a problem a
problem is ``not that a large amount of search is required for its
solution, but that a large amount \emph{would} be required if a requisite
level of intelligence were not applied'': the task of intelligence is
to ``avert the ever-present threat of the explosion of
search.''\cite[p. 125]{newellsimon} 

The conceit then, of the physical-symbol system hypothesis is twofold.
First, it assumes that
human beings essentially operate in this manner: that we apply
symbolic logic and heuristic search to provide for our intelligent
actions. Second, it assumes that computers can be true physical-symbol
systems. The validity of these two assumptions is not necessary clear. John Searle
essentially rejects the computer as a physical-symbol system in his
Chinese room example. Instead, the computer (room) is seen as a cheap
imitation of such a system: a room into which strange symbols are
passed, the appropriate responses looked up in a book,
and then passed out again, all without anything in the room having
access to their meaning.\cite{chineseSearle} Though meaningless
symbols are being processed by such a contraption, his view is that no
electronic computer ``can really manipulate symbols, nor really
designate or interpret anything at all.''\cite{escapingBoden} This is
a philosophical question of whether or not computers are capable of
true intelligence, not a matter of whether or not they can
convincingly imitate intelligence (and other philosophers of AI, such
as Margaret Boden, do not take Searle's view on the
subject).\footnote{Indeed, I find the Chinese room example to be
  lacking in several respects, particularly that it rests on some
  na\"{\i}ve about what can or cannot be intelligent that seem to beg
  the question it tries to pose. What is important about the
  argument is that, right or wrong, it challenges the basis of
  computers as intelligent systems.}

The former point proves harder to dodge. While it may be true, as is
fundamental to the field of AI and which even Searle holds, that
machines can think because ``we are precisely such machines,''\cite[p.
83]{chineseSearle} and therefore it should be possible to create
intelligent machines, this does not guarantee that symbol systems are
the way to achieve intelligence. It may well be that introspection on
thought is a large part of why the logical theory seemed so
compelling:  we like to think that we behave logically. Researchers like Newell
and Simon used ``think aloud'' experiments to identify problem solving
techniques,\cite[Ch. 10]{mccorduck} which seems naturally to suggest a
logical response:  when
asked to describe how we came to some decision, basing it in logic
seems the most acceptable alternative. While we certainly may apply logic
and process symbols, there is good reason to think that isn't how we
spend most of our time. Symbolic logic takes a lot of mental capacity,
so generally, we use other sorts of shortcut processes to come to
decisions. Pollock calls these ``quick and inflexible'' or ``Q\&I''
models\cite[p. 120]{pollock} and Dennett refers to them as ``habitual methods'' or
mechanical routines\cite[p. 157]{dennett} We rely on Q\&I models to do
much of our day-to-day reasoning because it is ``very important for
humans to be able to make rough probability judgments''\cite[p.
  120]{pollock}, and accepting the output of such approximate models
is not at all unreasonable in the absence of evidence for their
inappropriateness to a situation; a logical solution may be difficult
to arrive at in some situations. The physical-symbol system hypothesis
is just that, a hypothesis, and, historically, the classical symbolic
approach did not yield results as quickly as expected. This was part
of the reason for the first AI winter, and researchers moved on to
other approaches. While logic is part of the puzzle, it seems that it
is not the entireity of it, but achieving humanlike intelligence via logic
systems was the archetypal dream of early AI.

%% Rodney Brooks (3)
One of those researchers pioneering a new way of doing AI was Rodney
Brooks. Part of a different wave of AI researchers, disillusioned with
the failures of logic-based robotic systems (like Shakey, the SRI
robot named for its tendency to shake when in motion)\cite[Ch. 10]{mccorduck} to
achieve intelligent results, he posited a new way to build intelligent
robots, defined by the subsumption architecture.\cite[p. 353]{mobilebrooks} Above and
beyond the problems that physical-symbol system based AI had in
relatively controlled domains, robots controlled with these
techniques, overwhelmed by the complexity of the real world, responded
slowly and ineptly. To rectify this, Brooks attempted to cut out
cognition altogether, focusing instead only on sensing and
action.\cite[Afterword]{mccorduck} Rather than attempt to engineer a
human-level intelligence at once, when years of research had failed to
produce anything approaching these results, why not start small?
Insects, after all, lack cognition, but respond more adroitly to the
world than Shakey and its contemporaries. Uncertainty everywhere in
the physical world makes world-modeling extremely difficult: the
model has a tendency to get out of sync, and there needs to be
some reliable, calibrating stimulus to return it to accuracy. By building systems that can
accommodate uncertainty, Brooks believed, more progress could be
made:\cite[p. 347]{mobilebrooks} instead of modeling the world, treat
the world as ``its own best model'' and focus on embodiment and action
within the environment.\cite[p. 256]{ekbia}

Rather than being built into a single integrated system, the
subsumption approach is by definition modular. More complex behaviors
are built out of simper ones: level zero competence might avoid objects,
while the next level would wander aimlessly, and the next would
attempt to wander to places it had not been before.\cite[p.
  351--352]{mobilebrooks} Each layer is separate (and can actually run 
on its own processor), and can read data from
and write data into the layer below it (hence the term subsumption: 
the higher levels subsume the lower). When a higher level fails or
cannot run, lower levels continue to operate, and basic behavior is
maintained.\cite[p. 355]{mobilebrooks} This approach has tempting
biological connections as well:
accurately or not, one can imagine the human being as a robot with a subsumption
architecture, where breathing and heartbeat are lower than balance,
which is lower than voluntary motion, which is lower than logical
thought. And temptingly, it is an approach that can handle
uncertainties, as each layer is built to be robust in the inevitable
event of inaccuracies and lost messages. Theoretically, one could
imagine building systems of great complexity (e.g. cars) using these approaches,
but this architecture, the radical relativist response to the
structural realism of the physical-symbol system, did not alone manage
to exceed robots of insect intelligence.

Brooks himself abandoned the project of building intelligence from
these humble, subsumptive blocks. Instead, his later research, for example
the Cog robot, shifts focus from ``emergence'' to ``integration,'' and
reversed some of his initial fervor to avoid representation.\cite[p.
  258]{ekbia} He skipped the middle of the evolutionary tree, straight
to humanoid forms, because the evolutionary approach was too slow: 
Brooks reported, it was ``starting to look like, if I was really
lucky, I might be remembered as the guy who built the best artificial
cat,'' a distinction he apparently did not desire.\cite[p.
  65]{brooksflesh}\footnote{As cited in \cite[p. 258]{ekbia}.}
But to do this, bootstrapped knowledge from other sources was
necessary, bringing back some of the world modeling inherent in older,
symbolic approaches. 

%% Deep learning
A number of conceptually different approaches to AI have been tried
over the past 50 years, often with similarly deep-seated
ambivalences.\footnote{Ekbia's book does an excellent job
  exploring and cataloging many of these, more than I have space for.
  The logical and neorobotic approaches appear most relevant as
  broad-strokes historical precursors for inclusion here. But the rest
of his book is worth reading for more detail on other schools of AI thought.} Ideas fade
and resurface as fashions change, and greater computational power
allows ``failed'' techniques to be tried anew. But much of this
history is presently unappreciated outside of the discipline. What the
physical-symbol system and embodied cognition 
have in common is their attempt to start from first-principles or zero
knowledge, and to build inexorably toward intelligence. The difficulty
of this road led Brooks to recombine some of the old manner of
knowledge representation into his robotic techniques. Today, multiple
strains of AI research play out the same tensions. While Tomaso Poggio
and others at the Center for Brains, Minds \& Machines attempt to
emulate human learning,\footnote{Speaking at the CAST Symposium at
  MIT, September 26, 2014, Poggio noted that their approach is
  actually stepping away from ``Big Data'' and AI approaches applied
  by Google, among others.} other researchers bootstrap their machines
with more fully-formed models. Ours is the age of
statistical AI, and that is what receives attention in the
self-driving car narrative: the new source
of bootstrapping information is data, ``Big'' and ``small.''

Today's AI buzzword seems to be ``deep
learning,'' which appears to yield radical new possibilities everywhere it is
applied---though it really just means a return of neural
networks,\footnote{These systems still have little or nothing to do
  with actual neurons; they are brain-like in only the barest
  toy-model sort of way, despite how they are often represented in the
  press.} which, armed with some improvements in weight generation,
more layers of
nodes, and more data to train with, have been able to eclipse many of
the previous techniques.

%%EDIT: this could all use some clarity

Neural networks are essentially just a web of nodes with
interconnections between them.\footnote{For a primer on neural
  networks, see \cite{neuralJordan}.} They may consist of multiple layers
(hence ``deep'' in deep learning) or may be shallow. Also known as
``multilayer perceptrons,'' such networks have an input layer and
output layer, with one or more intervening hidden layers. Each node
corresponds to a particular feature or combination of features in the
input, and therefore works to classify inputs into different
categories. Each node is also connected to all the nodes in the
following layer with some tunable weight. The process of training the
neural network involves adjusting those connection weights so as to
be more sensitive in distinguishing different types of
inputs. This tuning,
traditionally, has been done using supervised method and
backpropagation of errors: the output result is compared to an
expected classification result, and the error used to tune the weights
more appropriately. Deep learning extends this technique, decreasing
the amount of ``feature-engineering'' (a human task, identifying the
features the network should use to distinguish inputs) required to
train the system. The ``ideal'' training situation is entirely
unsupervised: the network independently ``learns'' the features of
unlabeled and unclassified input, without any human input. This ideal
prospers both due to convenience in terms of human effort (less
programmer effort required to build labeled sets of training
data\footnote{This labeling is considered ``inhumane'' work, and contributes to
a reluctance to use machine learning in automotive applications,
according to G\"{o}de Both.\cite{bothpt2}}) and
due to the deep-seated ideology that machine independence is
paramount. Unsupervised learning is often seen as more impressive and
therefore more valuable research.

The sort of ``understanding''
involved in even the most impressive current systems is limited. Image
recognition systems, for example, are not
able to answer questions about the scenes that have to do with
the material properties of the objects, or likely results of various
actions.\cite{gomesJordan} It is important to understand why this technique is not a
panacea in order to understand the possibility for alternatives to the current
driverless car vision. These statistical techniques leverage existing data
sets by training machine-learning systems; but, as we will see,
machine-learning systems have properties that make them ill-suited for
safety-critical systems, and autonomous vehicles are designed with a
mix of approaches that allows for more introspection into their
workings. Another recent slew of articles focuses on
the ``self-aware'' Mario created by researchers at the University of
T\"{u}bingen. Any pretense to worry about a ``self-aware AI . . . with
an insatiable desire for material wealth'' that knows ``how to kill''\cite{vincentMario}
is simply journalistic excess\footnote{As the
  researchers well know. This case is just a convenient example of how
such stories spiral out from the lab and acquire new meanings.}, and suggest
significantly more care must be taken in the use of such terms. Mario
is programmed with emotional states like a word-processing program is
programmed with different modes or display parameters. These states
are simply caricatures of emotions, and that plus the program's
natural-language interface makes it appear more eerily science-fictional than it
actually is.

%% ``self-aware'' mario, image recognition and other
%% claptrap (1) (incl. John von Neumann & ALife (See CMS790 paper)??)
As has happened before, such AI hype is proliferating, and these
stories may impact the way all other AI work is
perceived by the public (especially viewed in the light of
popular concern about autonomous vehicle ethics). And popular claims
about the utopic promise of deep learning, to
learn about the world ``on its own,''
abound. Google's and Stanford's recent
improvements in image recognition\cite{markoffImage} triggered a wave
of popular speculation about computer vision meeting or surpassing
that of humans. Since vision is the primary sense involved in human driving
and one of the main research areas for automated vehicles, such
advances would seem to translate automatically into the self-driving
car space. Many articles (though some note that current
state-of-the-art image recognition is still considerably less capable
than people are) still present the uncritical idea that we have solved
the image-recognition problem---or rather, that increases in computing
power mean it will necessarily soon be solved. By this narrative seemingly limitless
possibilities are open before us. As one should expect, the real
history is far more nuanced. We would do well to remember that
progress has been slow, contingent, and heterogeneous, a product of a
wide variety of concepts and techniques. But
this is the environment that autonomous cars, as a
research area of artificial intelligence, find themselves in today:
part of a new surge (bubble?) of interest in the field, driven by new
or newly extended techniques. 


\subsection{Engineering Standards and Policy Documents}

%% I may be able to do this drawing on the other subsections
%%as a CONCLUSION, wrapping up the other three things
%%and what is LOST/OVERLOOKED; the ability to deal with nuance and
%%REAL ACTIVITY
%%other part of an analysis of this kind of stuff: did it for a
%%reason; what is the work that it does (reactionary thing in some
%%cases; pushes for a particular image of what this can be)
%%--visions of human; SAE history of thinking as engineers; people as
%%predictable black-boxed inputs and outputs

%%maybe split into different sub-headers with context like NHTSA:
%%Agency Trying to Catch Up or w/e

While some of the conventional driverless car narrative comes from
poor understanding of the technology and history, some also comes
straight from contemporary sources, the engineering standards and
policy documents set up to
guide the industry's development. A number of levels-of-autonomy or
levels-of-automation taxonomies have been developed to guide
researchers and public agencies toward an appropriate understanding of
how automation research will progress. While they vary in terms of how
prescriptive or descriptive they are, these documents are easily taken
as evidence for how automated systems must or will develop in
practice.\footnote{The Society of Automotive Engineers in particular
  made an attempt to avoid prescriptive definitions of autonomy in
  their work. But even a descriptive set of levels contains an
  explicit hierarchy, which can be read as an implicit narrative of
  progress or roadmap for development.} And, when closely
interrogated, they present gaps in vision that echo the popular
narratives of automation and AI, and do not sufficiently heed the
historical complexities we examined above.

The primary formulations of levels of autonomy for self-driving cars
have been published by the National Highway Traffic Safety
Administration (NHTSA) and the Society of Automotive Engineers
(SAE).\footnote{The German Federal Highway Research Institute, BASt,
 has also produced a taxonomy that predates the SAE's work, and
 influenced it in key ways.}
These reports exhibit some resonances and contradictions in how these
organizations represent autonomous vehicles and their human drivers.
Viewed in the larger context of the discourse on levels of automation
in general, these speak to different ideas of who the ``driver'' will be
in automated systems. However, both make particular assumptions about
the way autonomy is or will be implemented that may not ultimately be
valid and certainly seem to foreclose on certain alternative ways in
which systems could be designed. These documents represent an important
vector for the traditional autonomous vehicle narrative, and are
therefore worthy of deeper scrutiny.

\subsubsection{NHTSA: Reacting to the Industry Narrative}

The NHTSA's levels of automation focus largely on the human driver and
human costs, and seem to represent an inability or unwillingness to
think beyond human-machine oppositions which 
parallels the general narrative tendencies we have already examined in
automation and AI history. 
The agency identifies three ``distinct but related streams of
technological change'': 

\begin{quote}
``(1) in vehicle crash avoidance systems that provide warnings and/or
limited automated control of safety functions; (2) V2V communications
that support various crash avoidance applications; and (3)
self-driving vehicles''\cite[p. 3]{NHTSA}
\end{quote}

Though the agency positions these technologies ``as part of a
continuum of vehicle control automation,''\cite[p. 3]{NHTSA} aligning
themselves with Thomas Sheridan, whose
work forms a fundamental part of \ref{chap:3}, this belies
their three-part dissection of the technological landscape and their
following 5-level taxonomy. They correctly recognize that today's
``crash avoidance and mitigation technologies'' are the ``building blocks
for what may one day lead to a driverless vehicle,'' but incorrectly
assume that an easy line can be drawn between driven and
driverless.\cite[p. 3]{NHTSA} In truth, vehicle automation
technologies present a spectrum of possibilities that are not clearly
delineated, but stretch from the fully manual control of early
automobiles to current amounts of automation, to potential future
technologies that are remotely monitored. Like the mythical personless
factory, the driverless vehicle can only exist by dismissing new forms
of labor. 

According to the NHTSA definition, automated
vehicles are those in which ``aspects of a safety-critical control
function (e.g., steering, throttle, or braking) occur without direct
driver input.''\cite[p. 3]{NHTSA} Therefore, this definition excludes warning
systems that nevertheless still use ``automation'' in varying degrees,
drawing a suspect line between monitoring and action. Though there is
a difference between systems that only provide information and systems
that directly affect the mechanical state of the vehicle, making that
distinction part of the definition of ``automation'' perpetuates an
inaccurate view that automation is only meaningful or important to
consider when it affects a physical mechanism. Information automation
(road condition warnings, traffic notifications, etc.), which has
potentially great implications for safety and the driver's awareness,
is written out of the NHTSA's definition. But information automation
is one of the historically dominant modes of automotive automation,
even in the eyes of the NHTSA, and has been on the research agenda for
decades.\cite[p. 11]{wetmore}

Their definition also excludes non safety-critical ``control
functions.'' The agency is likely attempting to make this distinction
so that cars with currently banal automatic technologies like
automatic transmissions do 
not count as ``automated vehicles,'' but this is the wrong footing on
which to rest a definition of automation, as it neglects both the
vital roles automation plays both in tertiary components as well as
the delicate dance of human and automated control that happens even in
current vehicles. Automated wipers and hazard
lights may well be ``safety critical'' in at least some situations.
The state of the transmission 
and drivetrain, controlled via automatic (read: automated) or manual
shifting, is fundamentally important to throttle control and the
ability to safely control the vehicle. And shifting represents one of
several areas
in which complex relations of human-requested and
automatically-provided operating criteria are already visible: both
the driver and automation may be concurrently monitoring the engine
RPMs, and the driver may request shifts that reinforce or override the
preferences of the automation (or, in the case of a shift that would
over-rev the engine, for example, are rejected). A guide for the
continued automation of automobiles could (and, I would argue, should)
make an honest attempt to reason about such preexisting examples and
build from them. But instead, they are ignored, and thus the
terms of the agency's definition of ``automation'' itself are incoherent
and self-contradictory. By writing out current systems from the field
of ``automated vehicles,'' the NHTSA has hobbled their terminology,
and its usefulness to make sense of the broad spectrum of automation
approaches that are actually being used in existing vehicles.

The agency does not view the human-machine system as a whole, focusing
on, by labeling as ``automation,'' only those processes that are
mechanical in result and are arbitrarily considered to be
``safety-critical'' as opposed to ``secondary.'' Even if one does not
wish to include 
the driver as part of the ``vehicle,'' real-world vehicle tasks, or
control functions, are more complicated than simply turning the
steering wheel, but the NHTSA's levels of autonomy only compound these
issues with simplistic distinctions that do not account for the
majority of ways these systems could be engineered. Level 0, or
``no-automation'' represents 
precisely the issues inherent in their definition of automation. Level
1 is the only automation level beyond zero that does not have the
ability to apply all types of mechanical input to the system: it is
limited to ``one or more specific control functions'' that operate
``independently,'' and only for certain periods of time.\cite[p. 4]{NHTSA} The
necessity of independence between automated ``control functions'' is
especially hard to fathom: in a modern automobile, few if any systems
are truly independent, instead coordinated via electronic management
systems.\footnote{For example, see systems like Bosch's comprehensive
  electronic energy management, EEM.} 

The report is even confused on the number of control functions, though
it ultimately means that both steering and brakes/throttle cannot be
automated at the same time in a level 1 system: 

\begin{quote}n
``there is no combination of vehicle control systems working in unison
that enables the driver to be disengaged from physically operating the
vehicle by having his or her hands off the steering wheel AND feet off
the pedals at the same time''\cite[p. 4]{NHTSA}
\end{quote}

This continues the agency's curious focus on the physical state of the
driver's body, repeated in level 2 automation to make the distinction
that now the operator can be ``disengaged from physically operating the
vehicle by having his or her hands off the steering wheel AND foot off
pedal at the same time'' [sic].\cite[p. 5]{NHTSA} This description of bodily state is
the most coherent part of the levels definitions, but makes little
practical sense for defining automation. One can drive hands-and-feet
free in a non-automated vehicle, for short periods of time, in the
right conditions. Does the car become a level 2 during this time?

%%EXPAND on the definitional issue

While this question seems fatuous, it becomes important if the
physical state of the driver's body will define system-level
automation---and, given the NHTSA's power as a regulatory body, come
to define legal aspects of automated vehicle policy, such as how
vehicles are registered. (It is also worth
noting that this clarification is
unnecessarily normative, and does not transfer to other types of
bodily input---like GM's abandoned ``Unicontrol''\cite[p. 8]{wetmore}---or controls designed
for amputees.) Though this stipulation attempts to address what the
human driver is actually doing, it is insufficiently granular to
account for the various types of mental and physical effort exerted:
from using control stalks to monitoring for vehicles to consulting a
GPS or mentally planning a route to monitoring and adjusting an
automation system via steering-wheel based controls. But the
preoccupation with the body results from the NHTSA's charter: the
human is a safety liability, something to be protected. The operations
of hands and feet represent readily visible and na\"{\i}ve distinctions
between human and automated, even if the distinctions do not turn out
to be particularly useful when faced with further technical scrutiny.
For their stated audience, primarily state lawmakers who are not
likely to be human factors engineers or well-versed in human-machine
interaction, these markers of human action are persuasive, but likely
to contribute to bad policies.

Further levels extend the functions which are automated. Levels 2-4
have automated systems capable of making all the electromechanical
inputs necessary to drive; they differ only in the extent to which
human stewardship is necessary.\cite[p. 4--5]{NHTSA} This exposes na\"{\i}ve assumptions about
how vehicles will be automated:  one whole system at a time---and
these assumptions appear implicitly, again and again, in press
accounts. How much
control is handed back when the human has to take over more vehicle
operation tasks is not clear: One primary control function? All
primary control functions? The NHTSA is trying to define an overall
automation level for a vehicle, but their definition masks system
specificities. The report is not clear on the level of automation for
a vehicle in which some control systems require continuous monitoring
and others can transition to manual control on an appropriate
timescale. And the NHTSA's taxonomy rests on the assumption that the
work of driving a vehicle will remain basically the same, some tasks
simply shuffled to the computer---system control first, monitoring of
control second---with no new cognitive loads placed on the human as a
result. This too is a na\"{\i}ve position that is not supported by current
examples of automation technology, which often result in the
generation of new types of human work (such as monitoring the
automation system itself). This labor is implicit in the NHTSA's
taxonomy, but not examined in great detail. The NHTSA suggests special
training to ``authorize the operation of self-driving
vehicles,''\cite[p. 11]{NHTSA} and
positions the operator as a subject of education and regulation while
calling upon him or her to be the ultimate decision
authority:\footnote{They mention “Several State automated vehicle laws
consider the person who activates the automated vehicle system to be
the 'driver' of the vehicle even if that person is not physically
present in the vehicle”: their only commentary on this point is to say
that they know of no current systems (level 4) capable of this
operation.\cite[p. 5]{NHTSA}} the
automated functions should always defer to driver input to the wheel
and pedals (with the sole exception of already-proven technologies
such as traction and electronic stability control).\cite[p. 13]{NHTSA}

%%--NHTSA as reactionary, as trying to cope with what Industry says;
%%and as history of dealing with people and responsibility in
%%particularly binary ways; REAL PRESSURE to get it OUT THERE to guide
%%development
The NHTSA framework overlooks a large proportion of the actual work of
driving, and is therefore a poor model for actually evaluating and
regulating automated vehicle systems. Its bias toward
full-automation, structuring the hierarchy of levels around full
self-driving vehicles as the technological peak, slants the
development narrative---in the popular attention as well as in
potential regulation and legislation---toward one particular approach
to vehicle automation while ignoring or discounting alternatives. I do
not mean to imply that the NHTSA are myopic, but their framework is
deeply influenced by their institutional culture as well as the
circumstances of its creation. Their preliminary policy document was
reactionary, an attempt to regain ground and provide some sort of guidance to an
industry already testing on public roads. The automation-first
approach, which wants to jump directly to an NHTSA level 4 system,
must be tempered for liability reasons since as the 
NHTSA is very aware (given their research interest in level 2 and 3
systems) the technology is not yet ready.\footnote{They continually
  restate the point that only few level 3, and no level 4, systems
  currently exist, and that neither of these technology levels is yet
  ready for unfettered operation.\cite[p. 10, 14]{NHTSA}} When trying to make space for
technologies that are not yet mature, keeping a human driver in a
position to recover when things go wrong, as the NHTSA does, makes sense as a normative
strategy. However, the NHTSA implicitly buys in to the prevailing
public-facing narrative in industry, that fully-autonomous vehicles
are the obvious, natural end product of the evolution of automated
systems. Their document, therefore, reinforces that narrative.

\subsubsection{SAE: The Human as Engineered Component}

Contrasting the NHTSA's model with the SAE's provides a deep look into
the priorities of the organizations. The SAE document provides a full
taxonomy of levels of automation for ``on-road motor vehicles,'' and the
presumed audience consists of engineers not policymakers.\cite{SAE} The report
focuses on the three ``highest'' automation levels (``conditional, high
and full automation''), implicitly because these are the newest areas
of research and therefore the most important. The report is careful to
distance itself from the terms ``autonomous'' or ``self-driving'' as used
in the media, preferring instead its own carefully-defined
terminology.\cite[p. 5-6]{SAE} 

The SAE report does try to square itself with NHTSA recommendations,
however approximately, and represents the hidden difference between
NHTSA's levels 2 and 3 as the monitoring of the environment by the
vehicle (in level 2 the vehicle does not monitor, and in level 3 it
does). In contrast, the NHTSA report does not make this plain, and
indeed a level 2 system can be said to ``relinquish control with no
advance warning'' which is impossible without either knowledge of the
environment or the occurrence of a bug---the system needs something on
which to base its decision to ``relinquish control'' if such a decision
can be said to be made.\cite[p. 5]{NHTSA} Rather than overloading the word ``control,''
the SAE considers the ``dynamic driving task'' to have a number of
components, including the detection and classification of objects and
events, the response to such events, planning of maneuvers, steering
and turning (including lane-holding and changing), acceleration and
deceleration, and ``enhancing conspicuity'' (referring to lighting,
signaling, gesturing, etc.).\cite[p. 6]{SAE} Like the NHTSA's taxonomy, the SAE's
document focuses primarily on four major aspects of this task:
steering, acceleration/deceleration, monitoring of the environment,
and fallback performance, but is somewhat clearer about how tasks are
defined---in particular, it is clearer about the separation of the
driving task into longitudinal and lateral components. Also like the
NHTSA, the SAE's definitions show all systems above level 1 having the
full electromechanical capability to drive the vehicle (to execute
both longitudinal and lateral driving tasks) which makes it difficult
to account for complex hybrid systems in which some tasks may be
highly automated and others not.

The primary distinction for the SAE report is whether the ``human driver'' or ``automated
driving system'' monitors the driving environment.\cite[p. 5]{SAE} The report deals
appropriately with human psychology, stating specifically that higher
levels of automation are based on the expectation that the human need
not ``and therefore will not''\footnote{Attention and task hand-over are
  known issues in aircraft automation, as prolonged inattention leaves
  pilots ill-positioned to regain control of systems when necessary
  (see for example the events leading up to the Air France 447
  crash). This will be a particular focus in \ref{chap3}} continuously
monitor the environment.\cite[p. 9]{SAE} But their 
picture is still binary, rather than considering the moment-to-moment
distribution of human 
cognitive effort. This is implicitly connected to their inclusion of
the lower levels of automation only ``as points of reference to help
bound the full range of vehicle automation''\cite[p. 2]{SAE}: they are not within
the document's focus, which favors an implicit---to the NHTSA's
explicit\footnote{The NHTSA explains this by deferring to existing
  laws: ``Generally, these laws seem to contemplate vehicle 
automation at Levels 3 and 4, as discussed above, i.e., some form of
self-driving operation. 
Accordingly, these recommendations are tailored to Levels 3 and 4
automation.''\cite[p. 10]{NHTSA}}---rhetoric of progress toward the
higher levels of autonomy. 
Not only are hybrid task monitoring systems classified as level 2
regardless of their complexity or capabilities, the SAE's taxonomy by
definition leaves out whole classes of systems where the default
execution of the dynamic driving task is up to the human but
monitoring/fallback performance are computerized, or where the dynamic
driving task is shared in a complex way, as is monitoring and fallback
performance. It considers only systems in which longitudinal and
lateral control is handed over to the system earlier in the hierarchy
than monitoring or fallback performance.

The SAE is better about
identifying new types of human work, such as the monitoring of the
automated system, generated by partial automation
strategies.\footnote{For instance, the human driver ``constantly
  supervises dynamic driving task executed by driver assistance
  system.''\cite[p. 3]{SAE}} They
are also more conscious of issues of the handover of control, and
specifically discuss delayed-release of particular tasks ``when
immediate human takeover could compromise safety,'' slowly
transitioning control of a system from fully autonomous to fully
manual though never lingering in between.\cite[p. 4]{SAE} It should be
noted that this directly contrasts with the NHTSA's driver-focused
approach, as it places fundamental decision authority in the hands of
the computer system. (When development is not necessarily oriented
toward achieving fully autonomous operation quickly---or when a
taxonomy is not designed around making space for Google's self-driving
car project and its ideological orientation---and is instead
focused on incremental improvements, such electronic overrides seem more acceptable.)

The SAE mentions the true complexities of driving at the report's end,
describing how the dynamic driving task is distinct from driving:
``Driving entails a variety of decisions and actions, which may or may
not involve the vehicle being in motion or even being in an active
lane of traffic.''\cite[p. 12]{SAE} Driving is split into Strategical, Tactical, and
Operational components, where strategical includes trip planning and
route selection, tactical includes maneuvering, while operational
involves ``split-second reactions that can be considered pre-cognitive
or innate.''\cite{Michon} The SAE is explicit about their exclusion of Strategical
effort, presumably the human's task, from the definition of the
dynamic driving task. However, this admission does expose an
inconsistency within the SAE's taxonomy: level 5 automation (and some
types of level 4 automation) definitionally require Strategical effort
(route selection is implicit within GPS navigation), which is not
separately mentioned as a system capacity in the document.

Despite their differences, these taxonomies are united in lending
credence to the teleological narrative of automation:  further
technological development implies ``higher levels'' of automation, which
imply a decreasing role for human beings. (How different these
taxonomies might appear if structured or numbered differently!)
The tendency, endemic to these taxonomies, to predicate work on
jumping to the flashy upper tiers of automation reinforces the
blindness to complex hybrid human-machine systems, and results from
preconceptions about the value of level 5 autonomy and the
intermediate stages by which it will be achieved. The SAE's taxonomy
is part of a long tradition of levels of automation formulations in
engineering that make these kinds of implicit assumptions in various
ways.\cite{ParasuramanW}\cite{PSWickens}\cite{ALFUS}\cite{SMART} Their
greater facility with the technologies involved seems likely to have
contributed to their ability to achieve a somewhat more nuanced view
of vehicle automation than the NHTSA. The
technology-first perspective that shapes these sorts of formulations
likewise comes from a deep history of engineering practice, and a
tendency to treat the user as a black-boxed entity, another signal
processor with defined inputs and outputs, subject to mathematical
modeling---a set of qualities that is highly useful for engineering
work, as it is amenable to descriptive standards and interface
specifications. Such a perspective tends to diminish the attention
paid to
the subtleties of human action and interaction, which engineering,
though it may try to minimize, cannot afford to ignore completely.

While supporting the dominant, teleological narrative of automation's
progress, both
taxonomies ignore the external labor involved in that automation:
human action displaced in space and time. Where do remotely monitored
systems fit? What about human preparatory work that allows for
automated systems to operate? These are questions with serious
implications, to which we will
return in chapters \ref{chap:3} and \ref{chap:4}. They are not
answered by either of these autonomy formulations, but should be
addressed by any document that attempts to describe, normalize, or
regulate automated vehicle operations. In a sense, these autonomy
formulations pull together the three previous strands of this
chapter: they are influenced by science and design fictions, and seek
to respond to the narratives of technological revolution as
transmitted through the popular marketing of what nevertheless remain laboratory
objects; they repeat many of the mistakes of the dominant narrative of
automation history, and neglect some of the complexities of
human-machine labor relationships evidenced by their historical
antecedents; and they represent models for the
continued development of cutting-edge AI technologies, which perpetuate
the vision of an unbroken chain of development toward
ever-more-intelligent artifices. This historical journey has attempted
to shed light on some of the unspoken assumptions behind autonomous
vehicles, assumptions that shape the popular narrative toward
particular visions of automation and away from others. Now, however,
let us turn to consider the stakes of the 
visions we have investigated. Why do these kinds of narratives and
assumptions matter? And what 
reasons might we have for investigating alternatives?

%%CONCLUDE

%%TODO: turn section 1 into ``science fictions, design fictions''
%%read actual research papers and meld in their components
%%merge back in material from chap3


%% 3) (or worked in to each of the previous) current research
%%--not historical, but actual last-20-years papers about this
%%--examples of where ideologies bleed through!!!!
