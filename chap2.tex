\chapter{The Stakes of our Stories}
\label{chap:3}

3. Stakes of stories/tech (swap 4?)
-data collection
-mapping
-ML/machine vision
-functionalism vs. Understanding
-statistics and risk
-planning, policy, cities



>traffic-light detection and problems of infrastructure??


2.5??) Worth bringing in questions of terminology, ``intelligence''
etc. and the necessary caution in ascribing them to tech; we can look
and see that the ``intelligence'' in action here is really very
different than what we usually mean when we use that term
(human-centric)
--so does knowing this reality change what we want to see? (couple of
p)

We find ourselves in an era of seemingly continual technological
change that is strangely most noticeable in the most mundane parts of
our lives---how we shop, how we communicate, how we find
partners---almost as if ``designed by a bored researcher who kept one
thumb permanently on the fast-forward button''\cite[p.
  7]{???-Neuromancer1984}. No longer does the future seem to be
defined by flying cars and jetpacks. Instead, it is defined by
information, and its collection and use. The stakes of autonomous
vehicles are thereby deeply intertwined with the
stakes of other networked information technologies. And it is in these
current models that we should start the search for why competing
narratives of self-driving car development matter.

 In May of 2014, the European
Union's Court of Justice 
ruled in the landmark Costeja decision that since Google is processing
``personal data,'' and acting as a ``data controller,'' it may be
compelled to remove links to pages containing personal information
from its search results.\cite{???} The EU ruling, in deference to European
tradition and contrary to that of the United States, places an
individual's rights to privacy above the ability of users to access
information online.\cite{???} There is growing recognition that publicly
available data can be highly sensitive and that it may be beneficial
to allow individuals certain legal rights to control their own
electronic reputations, at least in particular circumstances. Costeja
opens the floodgates---from previously limited, targeted removals
through court cases and copyright law---to the possibility of free and
open public removal of ``public'' information.\footnote{This removal,
  however, is controlled and curated by Google itself, which has not
  waited for guidance on how to proceed but has forged forward on its
  own, as a way to set the standards by which information removal can
  be justified.\cite{???-http://www.theguardian.com/technology/2015/feb/18/the-right-be-forgotten-google-search}} But much of our
information is even harder to control.

Many current data-driven business models\footnote{See for example
  Google, which has as its fundamental revenue stream proceeds from
  advertising, which is sold by virtue of it being more accurate or
  targeted than other channels can provide. Facebook's new ad network
  competes in a similar space. Many of these companies provide
  services for ``free,'' where in reality the services are paid for by
the user in the data they generate and/or the advertisements they
view.} are fundamentally united in that increases in
functionality are predicated on invasions of or encroachments on what
we used to think was private, and represent increasingly invasive data
collection and sharing at a massive scale---often this information is
used internally to improve services, but it may also be aggregated and
sold to third parties, and in either event may be stolen or leaked by
disgruntled employees or thieves. This
is particularly important as a precursor of things to
come in the autonomous vehicle space, as such vehicles will allow
large amounts of data to be collected and shared with other entities. 


\subsection{Data Gathering and Monitoring} 

Clearly, new technologies will require new information, new types of
sensing, in order to operate; but it may be that not all the
information that is collected should be shared outside the immediate
context of its use. What is sensed, and what can be appropriately
transmitted back to servers for processing and storage, is of
paramount importance: this is a question of privacy in context.\cite{???}
Following Nissenbaum, privacy must always be seen in the context of
particular users and a particular use.\cite{???} It is not that data about our
commuting routes, for example, should never be collected, but that collected data
should not be sent uncritically to any third party without our
knowledge or consent, a violation of our information norms.\cite{???} 
Automated vehicles are and will continue to be networked
technologies. This connectedness brings with it great possibilities
for coordinating traffic and improving city planning, as well as great
risks to privacy and security, whether devices are networked with each
other or simply connected to central servers. There
may be legitimate uses for certain types of sensitive information, but
while providing it to municipal governments specifically to assist in
city planning may be legitimate, selling it to advertisers to help
them design more effective billboards may not be. Privacy issues
involving motor vehicles are likely to become much more complicated as
vehicles become able to record more, and potentially “know” more,
about their passengers.


%% 2.1) data gathering and mapping
%% --this approach presupposes large amounts of data collection (maps),
%% and opens the way to more information about the passengers (2 p)
%% --see Google's patents in particular which talk about sensing things
%% like the number of passengers (4 p)

With what networks, and for what reasons, will autonomous vehicles be
connected? Current driverless car concepts depend on networked
information for vehicle guidance. While, historically, certain
guidance systems have been insulated from communications---inertial
guidance systems for intercontinental ballistic
missiles are a particular example of this,\cite{mackenzie}---and
Google's vehicles use inertial navigation devices\cite{knightfurther}
alongside other sources of position data, current navigation systems
depend on global positioning satellites. Google's approach to
driverless car development currently necessitates accurate
and expensive\footnote{An autonomous vehicle researcher at MIT
  quoted prices in the range of $70,000 to $100,000 per device for the
GPS alone, while noting that those would of course come down with
greater production volume.} differential GPS receivers.

But a number of other developments already suggest that autonomous
vehicles will be connected to more than just global positioning
networks. GM's OnStar service already connects equipped vehicles to central servers for
purposes of safety, security, and convenience. The system has the
ability to automatically alert the authorities in case of an accident
or theft. It also provides vehicle diagnostics to the owner's tablet
or smartphone, and the OnStar app also allows the owner to configure settings, lock and
unlock doors, and remotely operate the lights and horn.\cite{onstar}
While these vehicles are not (yet) autonomous, OnStar's present
capabilities are representative of features that will become more common in highly
connected and computerized vehicles, including autonomous ones.

Additionally, vehicles that can receive information from each other and from the
roadway are a top priority for the NHTSA, and have been on the
research agenda for decades.\cite[p. 11]{wetmore} These concepts would
collect and use data to streamline traffic flow and provide
information to reduce delays and accidents. But there is potential to
do far more with the available information,
and data collected by the vehicle to make possible its own functioning
could be made to serve other purposes. Information about the vehicle
and its surroundings, including the locations of cars and pedestrians,
precise GPS coordinates of the vehicle itself, and the vehicle's speed
and acceleration, not only represent important knowledge for
path-finding by the vehicle itself, but new sources of potential
revenue for the groups in position to collect them. Uber, which
through its GPS-enabled ride-hiring applications still collects only a
fraction of the data that would be available through a self-driving
vehicle, has agreed to share its ride data with municipalities for purposes of
city planning.\cite{uberJardin} Though this data is ostesibly being
shared for the public good, it also serves private ends: to curry favor with
authorities that might otherwise attempt to shut the service down. The
ride data can also be used to provide internal predictions to help
Uber increase revenue by directing drivers to the right locations at
the right times. And it would not be far-fetched, in the current
information landscape, to see such information sold to third-party advertisers.

Google has envisioned vehicles that can determine their number of
occupants, and use facial-recognition or other biometric systems to
identify them. According to one patent,\cite{predictPatent} these vehicles could prevent
unauthorized persons from putting a child in a car, prevent convicted
sex offenders from operating their vehicles within the
legally-required distances of schools and playgrounds, or prevent a
car's doors from being opened (even from the inside) by a child unless
an authorized adult is present. These are only visions, and patents
are notorious for trying to cover as many possible angles of a
technology even if they are not intended to be applied in practice.
But these suggestions represent a perspective on safety and societal
order that posits technological surveillance and enforcement as an
appropriate preventative measure against criminal behavior. Whether or not protecting
against these threats is an appropriate use of this information is a
matter for societal judgment, but such proposals, if enacted, would
require these vehicles to have unprecedented levels of very sensitive
knowledge about people and their lives: biometrics, criminal
histories, family and trust networks. 

Prevailing data ideology tells us that we can understand ourselves better through
these data, that we can use them to determine patterns we never knew were
there. Out of this ideology come publications like Uber's blog\footnote{???}, which
describes customer ``insights'' gained through their ride data, which
are ostensibly interesting to the public. ``Look here,'' they seem to
say, ``we can tell you about \emph{you}.'' But it important to
recognize that the ideologies of data collection---for corporate
profit and public use---are deeply intertwined, and strongly
influenced by the possibility of using machine learning techniques and
statistical analyses to find and exploit patterns. Automated vehicles
are part of this general culture, and without significant effort to
resist erosions of privacy and data protection stand to open our lives
to greater scrutiny in terms of the means of and reasons for our
personal mobility.

%%More on the problems of data ideology? or not the place for it?


\subsection{Maps and Mapping}

But the information that may be collected and processed by automated
vehicles is not only about human inhabitants of the environment: other
types of data collection are also implicated in current
visions of the driverless car project. In order to drive with us,
autonomous systems will have to understand,
for at least a practical sense of ``understanding,'' traffic rules and
their accompanying signs, signals, lanes, and customs. This is, at its
core, a highly complex problem of interpretation and representation
for machines. Human understanding is built
through years of experience: it is through existing as a human being
in a particular cultural context that we know to drive on roads but
not on sidewalks, and how to tell the difference. But we do not have
this luxury in training machines.

Localization has been a fundamental issue for robotics since the
beginning of the field. In order to figure out how to act, a robot
needs to know where it is; and in general, robotic environments can be
expected to change rapidly with motion, and to vary significantly from
place-to-place\cite[p. 4]{???-SLAMbook}. Motions cannot, for the most part,
be pre-planned:  they must continually be reevaluated in new and
emerging situations, as the robot moves through the environment. As a
key part of this puzzle the robot must be able to determine its own
relationship to some target location it needs to get to: this
``target-robot relation'' is an ``unavoidable''\footnote{It is
  possible to create robots that navigate without any modeling of the
environment, as Fern\'{a}ndez-Madrigal et al. point out. However, this
severely limits the range of behavior that is possible. Without
reference to the environment, errors slowly accrue, and a system that
navigates in a known space without localization will find itself
getting further and further off-track.} component of successful
navigation.\cite[p. 5]{???-SLAMbook} This relation can be expressed
in different forms---either quantitative representations such as maps,
or logical, prepositional statements---and these representations carry
their own techniques of interpretation. 

But there is more to navigation than pure localization. While
localization is the usage of known elements in the environment to
estimate a robot's position, those elements themselves must be known
in order to perform this process. Mapping is the complementary
process, the estimation of ``\emph{unknown} spatial relations that
exist between environment elements'' in order to allow for subsequent
navigation\cite[p. 5]{???-SLAMbook}. There is a somewhat tricky
precedence problem we face here:  in order to build maps with
autonomous systems, they must know where they are; in order to know
where they are, they must have maps with which to measure
against.\cite[p. 6]{???-SLAMbook}

Returning to the history of AI,
localization was part of the cause of the poor performance of the
robot Shakey: world modeling through a symbolic approach was slow,
which was rendered even more problematic by the relative lack of
computing power.\cite{???-mccorduck?}
Though one way to determine robot position in the world is through
simultaneous localization and mapping (SLAM)---a serious research area in
robotics, as it is ideal for areas that are impractical to map
beforehand, such as ones that are always changing---it is easier to localize by comparing
measurements to a known map. However, that implies that the map is
pre-made, and therefore sets limits on the rate at which the
environment can change and still allow the robot to operate. By
contrast, the subsumption architecture involved an
attempt to avoid the localization problem by pure sensory response to
the environment, but building a robot that exhibits complex and
predictable behaviors in complex environments, through this approach,
is exceedingly difficult, as evidenced by Brooks's shift to hybrid
modeling approaches. But new AI techniques do allow researchers to
take advantage of new kinds of data.\cite{???} Today, localization and
mapping are both considered ``satisfactorily solved in practical
situations''---though SLAM techniques
are still somewhat less reliable or developed---given sufficient
computational resources and environmental data.\cite[p.
  5-6]{???-SLAMbook}

%%Fernández-Madrigal, Juan-Antonio, and José Luis Blanco Claraco.
%%2013. Simultaneous Localization and Mapping for Mobile Robots :
%%Introduction and Methods. Hershey, Pa: IGI Global, 2013. eBook
%%Collection (EBSCOhost), EBSCOhost (accessed February 21, 2015).

Here, the connections of autonomous systems to information networks
again become important. The vehicles in the
DARPA Grand Challenge did not navigate ``on their own'': they used GPS
to follow a path laid out for them in advance, using their autonomy
only to avoid obstacles like rocks and ruts.\footnote{John Leonard,
  discussion with the author, December 3, 2014} And though successful
road tests have been accomplished without navigational assistance,
using only visual stimuli (such as the EUREKA PROMETHEUS project
in the 1990s)\cite{???}, modern systems are tending to use more external
stimuli, rather than less, in an attempt to increase safety. Even as
advanced as it is, Google's autonomous vehicle technology requires
hyper-detailed 3D maps in order to operate properly on public
roadways.\cite{???} These maps are generated by vehicles outfitted with
special sensor arrays, like the LIDAR Google uses for their autonomous
vehicles, which drive a route and collect data which can be used to
reconstruct the model.\cite{???}

Pre-made maps are used so the vehicle knows where stoplights, signs,
and curbs are, reducing the computational load on the machine in the
crowded visual landscape of driving, and allowing it to focus on
elements of the environment that are changing rather than those likely
to be static.\cite{???} Prior knowledge of speed limits should make the car's
behavior more reliable and predictable in all conditions, even if
speed limit signs are missing or obscured---consider how often human
drivers, when faced with an absence of signs, base their behaviors on
supposition or prior knowledge. When Google's car was certified for
testing in Nevada, Google was allowed to pre-select the route the car
would take, so that they could build the comprehensive model the
system requires beforehand.\cite{???} The system would likely not have been
capable of passing a test in which the examiner could have added
detours on the fly. And though Google claims to have driven more than
700,000 miles with their cars, those are not 700,000 unique miles. A
limited, thoroughly pre-mapped route has been driven many times to
achieve those numbers.\cite{???}

Mapping claims a unique capability to
represent the real, objectively
and diagrammatically, but also requires that world to remain largely
static, at least on the order of how long it takes to update the map
for a particular region. The necessary level of continual mapping is a massive task if the
vehicles must be usable everywhere. The United States alone contains almost
8.5 million road miles\footnote{Data as of 2008,
  http://blog.cubitplanning.com/2010/02/road-miles-by-state/\cite{???}},
and it took years for Google Streetview to acquire the level of
coverage it currently has. The utopian discourse of driverless cars
implicitly suggests that such vehicles will be available everywhere,
and are the solution to nationwide transit problems. But widespread
egalitarian access to maps-based devices depends upon a rapid,
widespread mapping initiative.

TomTom\cite{???} and Nokia\cite{???} both claim to be attempting such a mapping project,
but it will not happen immediately or all-at-once. More likely,
certain areas will be 
mapped and restricted, or separate divided public rapid transit
systems will operate on roads that can be carefully
monitored.\cite{???} While
Mountain View, California may be mapped early, rural West Virginia or
Northern Maine may not be mapped as soon or as frequently.
Inequalities may be increased if routes frequented by upper-middle
class professional commuters, most likely to own new autonomous cars,
are mapped first, while roads around low-income communities are
ignored. 

The seemingly universalizing forces of maps and computer programming
have a tendency to help hide issues of geographical and cultural
specificity, which are rendered invisible in the utopian narrative.
But though engineering practice holds that these issues are
conquerable, they should be anything but invisible. Programmed devices
must must know about speed limits, about traffic
lights, about rules of the road that were never designed for
autonomous systems. These devices must respond to human caprices and
be adapted to longstanding, ingrained laws and habits. They must
include historical knowledge, rooted in the legal and social histories
of roadways, which may differ between cities and states, and certainly
between countries across the world. Local customs and behaviors differ, and even if maps are
available, the same vehicle programming may not work for Los Angeles,
Boston, and the rural Midwest, let alone Singapore, Mumbai or Cairo.
The map, for all of its objective standardization, still represents
real places subject to cultural histories and vulnerable to
socio-economic dynamics. These social and regional issues are often
ignored in the driverless vehicle narrative, but nevertheless stand to
be critical to the manner in which these technologies could come to
enter everyday life.



\subsection{Machine Vision}
%% 2.2) machine vision
%% --pull from the Spectator paper (4 p)
%% INCL. machine learning
Interpretation of the world around us is a task that seems
particularly easy for human beings, but particularly difficult for
machines. The invention of the photocell, early a tool for workplace
monitoring and surveillance, provided a simple channel through which
electrical systems could respond to the amount of light reaching
them.\cite{???} Though the photocell can easily provide a computer system
with access to brightness information over time, perceiving detail and
depth, identifying shapes, and interpreting expression and motion are
all capabilities of human vision that require more sophisticated
technologies to reproduce. DARPA's 1983 Strategic Computing Initiative
included image interpretation as one of its main
focus areas.\cite{???} But it is only relatively recently that real-time video
processing, needed for camera-based navigation, became feasible for computer
systems small enough to fit in a standard automobile.\cite{???} And machine
vision problems, including object recognition and scene
interpretation, continue to be difficult, even with increased
processing power and new algorithms. 

As an engineering discipline, computer vision takes a decidedly
practical and reductionist view of what it means to see. The goal is
generally not to achieve creative interpretation or aesthetic
valuation, but to differentiate free space from things a robot should
not run into.\cite{???} But this so-called objective focus still encodes
certain subjective judgments about objects (including people),
behaviors, and intent. And while computer vision is having success
with object detection, there is a wide variety of human knowledge
about objects and scenes that is missing in current computer models.\cite{???}

Though vision has not always been the sensory mode that dominated
autonomous vehicle research, vision is a particularly attractive sense to
use, as it is integral to how humans drive. In an attempt to build
autonomous vehicles that can operate without infrastructural changes,
research has moved away from tracks and cables toward vision-guided
systems. New approaches were pioneered by Ernst Dickmanns at
University Bundswerhr in Munich, with the vision-guided VaMoRs van,
and continued via the EUREKA PROMETHEUS project in 1987, in which
Dickmanns and Daimler-Benz built cars guided by analog video
cameras.\cite{???} Like the earlier VITA project by Daimler that used an
analog video-camera signal processed through a framegrabber, these
cars digitized analog video at relatively low resolutions. The
features the systems searched for, including lane markings and other
cars, are geometrically distinct and visible even in small images.\cite{???}

This is only true, however, for use in fair weather. Rain, sleet, and
snow interfere with vision-guided systems, and currently prevent them
from operating safely. While the human eye is generally very good at
pattern recognition and filtering out noise, getting computers to appropriate recognize all
the necessary road objects is already something that tests
cutting-edge techniques. Precipitation no only makes roads slippery
and less safe for all drivers, it reduces visibility---which decreases
the distances at which objects can be detected, and therefore also the
time the system has to react---as well as potentially decreasing image
contrast and presenting interference to the image---through drops or
streaks on the glass through which images are taken.\cite{???-rainACAS} These issues also
affect people, though our brains can filter out raindrops on the
windshield rather than interpreting them as obstacles, but human
drivers would choose to drive more slowly. One emerging research area
in automated vehicles is raindrop detection for automated driver
assistance systems, in order to help such systems compensate for
reduced visibility, or alter their behavior to be more conservative in
these situations. However, ``developing algorithms that work perfectly
under all weather conditions appears to be unrealistic,'' so such a
modular and cautious approach may well be necessary in order to build
robust systems.\cite{???-rainACAS} While commercial use of vision-guided self-driving vehicles on
sunny days may indeed be possible in the near future, use in
less-than-ideal conditions is likely to be limited for some time,
while human oversight compensates for algorithmic deficiencies. 

Vision-guided systems, now using digital video cameras and
off-the-shelf consumer hardware, have the benefit of being inexpensive
and insensitive to interference from other nearly devices (unlike
sonar, for example, which becomes problematic in crowded
situations\footnote{John Leonard, discussion with the author, December
3, 2014.}). Some commercial systems, such as that developed for Mercedes-Benz's
self-driving S-class, which is slowly finding its way into consumer
vehicles, are primarily guided based on such visual sensors.\cite{???} To
these sensors, recent research has added roof-mounted LIDAR arrays.
LIDAR, short for Light Detection and Ranging, is a distance
sensor, which is applied in vehicles to scan the environment with a
rotating array of laser beams to create a detailed 360-degree
representation of objects and their distances. This technology
solves some of the difficulties of image interpretation by default, as
it can provide highly-sensitive information about free space and
obstacles. Shape-detection algorithms can then be used (in addition to
vision-based data) to classify obstacles as different types of
objects: pedestrians, bicyclists, cars, and trucks.\cite{???}

--Göde Both and reluctance to use Machine Learning (1 p)
---brittle, unpredictable, difficult to ``tune''

--Sensors issues and inability to distinguish crushed newspaper from
rock (1 p)
---requires a lot of other information, more than simple physical
volume
---object identification work in machine vision is slowly progressing,
but then we hit the above problems of VV\&T for such models (2 p)

Pedestrian detection algorithms search for person-like shapes, where
“person-like” is determined by, for example, training a classifier
using thousands of images previously labeled (by people) as being images of humans, so
the system can learn the features that correlate with a person being
in a particular region of an image. These detected categories allow the system to make
statistical predictions about likely types of behavior: according to
one of Google's patent applications, bicyclists are likely to be more
erratic than trucks, and should be treated
accordingly.\cite{predictPatent} These sorts of predictions are
something that human drivers do consistently, and are therefore also
likely important to how autonomous vehicles may drive.\footnote{The
  DARPA Urban Challenge crash, the first crash between two autonomous
  cars, provides an important lesson on the vagaries of object
  detection: the classification threshold between moving and
  stationary, set too high, allowed one vehicle to interpret the other
  as stationary, leaving no room for unexpected behavior.\cite{???}} 

One notable researcher I spoke to drives around searching
for situations he believes will cause trouble for current vehicles,
trying to photograph them. These include many situations with police
directing traffic, especially when combined with sun glare, or
occlusions of the sight lines---such as by a mail relay box---that
would make predictions of oncoming 
objects difficult. His take-away from these situations is that there
is a significant body of edge-cases that make full autonomy
impractical for the forseeable future. Instead, humans will be
required to account for these sorts of situations. 

<Include quotes from the interview>

But because autonomous cars see---putatively “as we see”---their sight can
be leveraged as visual evidence of their operation. Computer vision systems that identify
pedestrians can be shown to do so, via the detection boxes that act as
diagnostic tools for researchers and direct representations of
internal system information. The new technologies of vehicle
automation thereby produce through 
their operation new forms of evidence, which can be presented through
electronic information media. We can point to these images and identify
that the vehicle is operating as it should. The box inscribed around
the pedestrian shows this plainly. The 3D environment scan from the
LIDAR system presents the same opportunities for “transparent” visual
proof. Three-dimensional shapes, in standing in stark relief against
the background, bear witness to the sensory operation of the vehicle.
These shapes too are demarcated by boxes, which represent their
computational transformation from information into an object or
artifact of interest. Because the visual detection technologies used
by autonomous vehicles are compatible with the visual technologies of
media representation, new types of seeing are opened to us.

A coincidence of sensing and representation in the evocative and
powerfully persuasive medium of visual representation stands to shift
the way we perceive driverless systems in their operation, providing
us a different manner of insight and introspection, but also
potentially a different level of obfuscation, than ever before. When
considering how these vehicles are presented to us—and the fervor with
which some researchers demand that we accept them\cite{???}---it is important to
remember the many black boxes of information processing behind the
naturalized image of the sensor readout. The rhetoric of the
self-evident visual image, as it operates in the autonomous vehicle
space, can be made more visible by considering contemporary medical
imaging. As researchers have noted about the prevalence of brain
images from fMRI studies in the popular press, these depictions have
strong rhetorical impact on discourse about neuroscience. Colorful
pictures of the brain, as the inheritors of Enlightenment notions of
visual evidence par excellence, have a way of convincing the viewer of
the validity of reseachers' claims about physical brain locations and
their effects,\cite{???} especially since those pictures are presented as the
direct, transparent products of sensing techniques. The elision of
human and machine vision which makes these images so confusing is as
misleading in vehicle navigation as it is in neuroscience. Significant
statistical processing is necessary to make sense of data in either
realm, processing that is generally beyond the public's gaze\cite{???} but the
end result leaves the viewer with a false sense that something real
has been sensed, revealed, and affirmed by the image.


%% 2.2) functionalism over understanding
%% --for better or worse these devices are not humanlike in their
%% understanding
%% ----AI winters & the rise of commercial ML AI with much smaller goals
%% (see Wired articles, etc) (3 p)
%% --the ideology that drives them is an engineering mindset: ``just make
%% it work'' (2 p)
%% --pulling the quote from my USC talk: also interesting to note
%% regarding 1.2 that it seems to expect a humanoid robotic chauffeur in
%% a normal car! (1 p)
%% -and of course interviews with people (Ryan Chin; Walker Smith etc.
%% where they matter to this type of vehicle)
\subsection{Functionalism and Utilitarianism} 
But for better or worse, self-driving cars will not be human-like in
understanding, even while they can detect and identify pedestrians.
A wide range of software companies and startups have entered the AI
industry, but these companies are not primarily focused on
general-purpose AI. Though certain ventures still hold out the dream
of doing so, several AI winters have shown that the creation of
general intelligence is very difficult, and is by no means around the
corner. Those working in the field are well aware of
this.\cite{???-articlerebuttingmusk} So much current work is
fundamentally utilitarian, building systems with clear goals, metrics
for success, and market segments.

Though computer science and philosophies of AI have been using
``intelligence,'' ``knowledge,'' and ``understanding,'' among other
words, to talk about computers since the beginning of the field, these
uses should not be taken at face value. “Intelligence” is slippery,
and its definition is not constant over time. It is difficult to
define intelligence in ourselves\cite{???} and yet another thing to define it
in relation to other entities. Weaving was once considered to be a
peculiarly human capability, a sign of an advanced, intelligent
mind.\cite{???} But after Vaucanson's loom allowed mechanical devices to weave
seemingly on their own, this capacity was no longer seen as uniquely
human, and was no longer a marker of intelligence. The same process
occurred with chess in the 1990s. When IBM's Deep Blue beat Gary
Kasparov, chess ceased to be the standard by which intelligence could
be judged, precisely because it had been achieved. Real intelligence
had to lie elsewhere: for example, in the game Go, mastery of which
has continued to elude machines.\cite{???}

Nevertheless, machines manage to do things that seem “intelligent.” So
though these terms are heuristics for understanding the observed
behaviors of machines, they slip slowly over time from self-conscious
scare-quoted use into casually accepted statements. While automatic
translation may seem ``intelligent,'' or a system that can define \emph{\'{e}toile}
as ``star'' may seem to possess ``knowledge,'' this intelligence or
knowledge is perhaps very different than our own. A deep
epistemological question presents itself: how do we know, and how do
machines ``know''? Many AI systems operate via statistical pattern
recognition, so we may ask whether we believe human intelligence is
also merely pattern recognition: does a system that can associate star
with its definition really know what a star is? Is mere linguistic
association sufficient for knowledge?

H. R. Ekbia\cite{???} and others remind us that we should be skeptical of the
applications of these terms to computational processes. As we have
seen, Searle's thought experiment of the “Chinese room”
argues that symbol processing and pattern recognition alone is not
intelligence, though from the outside the results may appear to be
intelligent. Despite the fault's of his argument, his caution
about ascribing overly ambitious human ideas to computational
processes is warranted. Even Pamela McCorduck, a colleague of several
notable AI researchers and a believer in the field in general, hedges
on how intelligent some of the programs she discusses in \emph{Machines Who
Think} actually are. Ornstein, Smith, and Suchman, in their 1984
article ``Strategic Computing,'' warn of the difference between domain
capabilities and ``common sense,'' and suggest that ``unwarranted
optimism'' and a particular funding climate (issues also present today)
push researchers to mask the shortcomings of AI with ``semantic
shifts.''\cite{???} We alter the definitions of ``knowledge'' and ``understanding''
to fit what our machines can do, and these claims, taken literally,
``give rise to unrealistic confidence in the power of the technology.''\cite{???}
The two-way process of linguistic and technological change---that
intelligence gets applied to describe whatever researchers manage to
achieve, while real ``intelligence'' retreats away from each
computational advance---leaves these terms poorly defined.

However, the utilitarian model of AI makes good sense for a number of reasons.
First, much can be achieved with current technologies. Rather than
focusing on a long-term project, which would carry much greater risks
and rewards which are further off, achieving short term goals is an
attractive prospect. It can not only attract money but can be
profitable sooner. Though short term commercial viability is not
necessarily applicable for this vision of the self-driving vehicle, it
is possible to have working prototypes on the road, generating
interest and publicity even in controlled conditions. Taking
journalists for test drives drums up interest, even if the technology
is not ready for full-scale deployment. Make no mistake: the current
vehicles are capable of recognizing pedestrians, but any claim that
they ``know'' or ``understand'' is a tenuous misuse of words which
could no longer credibly mean what they generally do. 

Second, humanlike characteristics may not be helpful for building
specific applications. One would likely not want one's self-driving car
to be preoccupied or emotional.\cite{???-wiredFutureofAI} It may be that, for utilitarian
purposes like driving, many of the characteristics of the human are
detrimental, their elimination helpful and intentional. Much of the
discussion around why autonomous vehicles are necessary centers on
just such qualities: distractability, sleepiness, lapses in
concentration.\cite{???} We would not wish to emulate such
characteristics in robotic systems. However, these are human
capabilities, but also only caricatures of the human. People possess a
variety of other capabilities which might be helpful to certain AI
systems. As AI researcher Doug Lenat wrote in 1997:
\begin{quote}
Before we let robotic chauffeurs drive around our streets, I'd want the
  automated driver to have a general common sense about the value of a
cat versus a child versus a car bumper, about children chasing balls
into the streets, about young dogs being more likely to dart in front
of cars than old dogs (which, in turn, are more likely to bolt than
elm trees are), about death being a very undesirable thing.\cite[p.
  122]{ekbia}\end{quote} 

This is a difficult knowledge and perception problem. But even more,
it is an issue of selfhood, embodiment, even sentience. While cats,
children and bumpers can be identified as objects, and children
chasing balls into the streets can be identified as patterns, a
computer programmed to respond to these stimuli may respond correctly
without ``knowing'' anything. While a machine can be programmed to avoid
running into people, can it have any understanding of death? Can it be
programmed to ``feel guilt''? Does it need to?

Current approaches, however, assume this kind of deep understanding is
unnecessary, both for the technical creation of such vehicles as well
as their public acceptance. And yet the ideology of artificial
intelligence, the focus of the field itself, is bound up in the idea
of ``intelligent'' machines that can be said to ``know.'' It is an
interesting read on the changing 
times to notice that Lenat's statement seems to suggest humanoid
robotic drivers operating regular cars. As well as moving toward
functionalist systems, the industry has moved toward embedded systems
within devices, systems that make no pretenses to be humanoid, but
instead revel in appliance-hood. Whether this shift in the form of AI
systems makes customers more or less nervous about computer-driven
vehicles is an empirical question\footnote{CAN I FIND RESEARCH ON
  THIS}. But it certainly suggests a desire to make the systems more
invisible---and actually has important implications for human-computer
interaction, as we will see in the next section. Though it may seem
obvious, it is critical to remember that the devices we discuss here may
have the properties Lenat mentions only in the way that the University
of T\"{u}bingen's AI Mario may be
``self-aware,'' possessing programmed constraints that cause it to
avoid people, and perhaps expect children to behave erratically.
Nonetheless, despite lacking the facilities for actual ethics, these
devices possess an implicit ethics: the
behaviors of these devices will the instantiate moral and
ethical judgments of their human creators, based on
human-authored heuristics and statistical predictions. This will be
very important for how we understand our relationships to these
complicated technological systems.



%% 2.3) what standard of safety? 
%% --better than an average person? or better than the best people? (1 p)
%% --human problems with using projected statistics to define policy:
%% does it make people feel better to know a system is statistically
%% safer when they are uncomfortable with it? see cars/planes for example
%% (3 p)
%% -->perspective of caution? or  ``losing lives every day'' that
%% could be saved?
%% ----how much risk is legitimate?? (2 p)
%% --airlines as a place where we see the different dimensions of
%% statistical safety vs. passenger's feelings of safety (3 p)
%% ---drawing from PARC/CAST documents
\subsection{Safety and Statistical Risk}

But regardless of understanding, what drives the self-driving car
narrative is safety; specifically, the poor safety record of human
drivers and the potential for machines to do much better, free from
human frailties of distraction and fatigue. How bad are human
drivers, really? Conventional stories of human drivers paint us as
plainly terrible, prone to road rage and drowsyness and generally
doing anything except paying attention\footnote{Numerous popular
  articles take this position\cite{???}}. However, the statistics tell
a slightly different story. Official numbers show that the number of
motor vehicle accidents has remained in the range of 10--11 million
per year for most of the late 2000s. The death rate seems to have
decreased overall in this time, settling somewhere below 1.5 deaths
per 100 million vehicle miles, presumably due to a combination of
better safety features (especially since 1990) and other
factors.\cite{???} The total number of vehicle-related deaths is much
lower, at a still significant 35,000 deaths per year. But this alone
does not tell the story. At around 1.5 deaths per 100 million vehicle
miles, or about 1 death per 67 million miles, humans seem relatively
competent in a statistical sense. The average American, who might
drive 1 million miles\cite{???} is unlikely to be
involved in a fatal crash in his or her lifetime. Looking at non-fatal
accidents as well, humans get involved in about one accident per
286,000 vehicle miles. Part of why the autonomous vehicle problem is
such a difficult one is that these numbers are relatively high.

Theoretically, computers can do better. But especially careful human
drivers can also clearly beat the human average. But how safe do
autonomous vehicles need to be in order to be allowed on our roads?
Safer than the average human? or safer than the very best drivers?
Such questions have real impact when it comes to how devices are
designed and when they become commercially viable. The autonomous
vehicle enterprise seems to call for using such projected statistics
to define policy. One common narrative is that undue caution in the
rollout of autonomous vehicles will directly ``cost'' lives, since
people are killed by human drivers every day.\cite{???-blog} However,
people are also accustomed to the current automobile death rate, and
any autonomous vehicle crashes are likely to attract deep
scrutiny\footnote{As Jim Womack has pointed out, there is no good side
to change as a regulator. Regulators are not congratulated when things
go right, only criticized when things go wrong. So some measure of
tentativeness is almost certainly justified to the regulatory mind.
(Discussion with the author, December 3, 2014)} as
to whether a human could have prevented the accident.\cite{???}

-if human oversight to an otherwise autonomous system is required,
there's a whole issue of supervision (dealt with more thoroughly in
next section)
-but also risk homeostasis!

These are questions of policy, but also questions of human acceptance.
This ideology posits lowering accident rates above all else, leaving
no space for human squeamishness about technology and responsibility. 
The statistical argument suggests that the death rate is all that
matters, but humans are notoriously bad at understanding and
responding to statistics. Does it make us feel better---more
comfortable, more likely to get into autonomous taxis and spend our
money on autonomous cars---to know that they are statistically safer
than the average driver? 

Michigan paper about ``may not be safer''
%''Of course, the researchers are trying to correct what they regard as
%excessive technological optimism. Still, is it entirely fair of them
%to compare robocars only to the best drivers? Most accidents are
%caused by the worst ones, and it is beginning to become clear that
%those are the people that a robot could outperform with one clanky
%arm tied behind its back.'' (Phillip E. Ross, ``Has Robocar Safety
%Been Hyped?'' 20 Jan 2015: http://spectrum.ieee.org/cars-that-think/transportation/safety/has-robocar-safety-been-hyped)
UMTRI-2015-2.pdf: road safety w/ self-driving vehicles, things being
considered
-p6

---airlines/Mil worried about reliability: need better VV\&T, models
for testing (3 p)

Airplanes are one type of vehicle for which these different dimensions of
safety---statistical safety compared with perceptions or feelings of
safety---have already become visible. Despite the comparative statistical safety of flying,
people tend to be more afraid of getting on an airliner than getting in their
cars.\cite{???} While this may have to do with a number of factors,
including that aircraft do not remain on the ground during operation,
it also represents a situation in which passengers give over their
agency to pilots performing a job they do not understand and could not
take over in an emergency.\cite{???-canIFindAnythingOnThis} SIMILAR
ISSUES WITH TRAINS?\cite{??} The
PARC/CAST working group had to account for these issues in their recent
recommendations about airplane safety. They judged that if air traffic
were to continue to increase with XXXX rates of crashes, by XXXX it
would reach one fatal crash per day, which would be intolerable to
airline customers, even though the overall accident rate would be no
larger.\cite{???-PARCCAST} Though aircraft would be as safe as they
had ever been, people, on seeing the sheer number and scale of
accidents, would be unlikely to choose to fly. While the issues facing
aircraft and trust are not precisely the same as those for cars, this
example shows that actual safety rates are only
one component of interest when considering how consumers react to
modes of transportation. Perceived safety---due to accident scale,
publicity, trust, or other factors---may be very different. But
while research into how to get human beings to trust robotic drivers
is being done\cite{???}, the voices pushing for autonomous cars sooner
rather than later would suggest that the statistics are all that
matters (and indeed, would tend to fabricate those statistics out of
mere predictions). 


\subsection{Planning, Policy, Cities}

Besides being presented as steps toward road safety, driverless cars
also become part of the rhetoric of personal mobility, ``public''
transportation, and urban planning. Potential or imagined
benefits of these vehicles include empowerment for the blind or
elderly (as we discussed in chapter \ref{chap:1}), a reduction in
traffic congestion, elimination of parking problems, and the
persistent access to a dense network of hireable point-to-point
transport vehicles (essentially, driverless taxis). There is
  also an environmental case being made for these vehicles, as they
  will drive predictably and can therefore be tuned to be very
  fuel-efficient. The social, environmental, and urban planning
implications are at least worth considering in passing before moving
on to consider alternate models for how these technologies could be
developed. 

In my discussions with a fellow researcher who has been studying the
development of self-driving vehicles, it became clear that the
developers see themselves as people trying to change society. They
tend to buy into utopian visions of big cities freed of cars, with no
parked cars on the streets and only driverless cabs. This desire to
change the way cities operate is admirable: our cities have a
difficult hundred-year history of changing to cope with the
automobile, and many of these changes have not been for the better
when looked at through a broad lens. The prevalence of automobiles has
literally re-shaped city centers,\cite{???-kemp} widened
streets,\cite{???-kemp} and generally made many cities less safe for
pedestrians and bicyclists. Many of the streets in the most pedestrian
friendly zones of older cities would no longer be legal to build under
current traffic codes---minimum lane widths have increased
substantially in the past XX years.\cite{???-kemp} In some of the
United States's most pedestrian-unfriendly cities, major intersections
in the downtown area are more than XX feet across. These changes in
regulations and practices have contributed to more sterile urban
centers with reduced potential for vibrant civic life. Urban planners have
in recent years begun to take the automotive threat seriously, pushing
for reduced lane width requirements and designing urban areas that
limit vehicle traffic on purpose.\cite{???-kemp} If self-driving
vehicles have a high probability of effecting a positive change on the
cityscape, as some proponents claim, they could be an important
addition to these developments.

Congestion and other environmental factors, such as air pollution, are
other social reasons used to support automated vehicle development.
With carefully controlled, automated driving, the fuel consumption of each
individual car could be reduced, just as so-called ``hypermilers''
today use altered---and very conservative---driving techniques in
order to increase their fuel efficiency.\cite{???} As discussed in
chapter \ref{chap:1}, researchers envision using V2V communications to
share road information between vehicles, reduce gaps between cars, and
thereby increase throughput and efficiency of the road system. But
these proposals involve numerous potential pitfalls. While coordinated
fleets of vehicles could increase the throughput of roads by 2 to X
times, significantly greater increases would be necessary to match the
throughputs of buses or subway trains, which can be 100 times
greater.\cite{???-kemp} Much depends on actual usage---subject to
homeostasis of inconvenience and the Jevons paradox. If a factor of 10
increase in highway throughput were possible, but caused a factor of
10 increase in overall miles driven, congestion would not be
ameliorated, and significantly more environmental impact might result. Any
large-scale impacts of automated vehicles are dependent on the
architecture of the overall transportation system. And therefore it is
the transportation system, not automated vehicles alone, that must be remodeled.

Fleets of fully automated vehicles could reasonably be expected to increase
efficiency and decrease reluctance to take trips---making them
less-inconvenient by allowing the driver to perform other tasks---in
which case vehicle usage would be expected to increase. This result is actually
implicit in the visions of those who would support fleets of
driverless taxis to move people around cities:  these concepts are
explicitly oriented toward providing for needs that are presently
under-served, and so presenting automated vehicles as a solution to
city transit problems implies greater usage of such vehicles to meet
those needs. So as increases in the use of cars to commute have
decreased the quality of urban spaces, what is to stop cities of
automated vehicles from
being even more unfriendly to
people? This question was in fact asked at the MIT SENSEable Cities
conference in 2014.\footnote{It received little in the way of reply from the
panel. Nhai Cao suggested that cities will not be built around new
vehicle infrastructure, and that his focus is on building new
capacities into vehicles, which avoid the question. Paolo Santi was
unconcerned with vehicle-to-pedestrian sensing and interaction, but
instead with the very limited domain of mathematical optimization,
a viewpoint that seeks to ignore the potential consequences of such
optimization.} Positive changes to city infrastructure will not happen
automatically. Complex
changes to complex systems require significant modeling work,
experiments, or even trial and error to get right. Old models and
habits need to be broken---consider for example the rules (about road
widths, for instance) enshrined
both in the official urban planning regulations as well as their
surrounding culture, rules which are often taken almost as natural
law\cite{???-kemp}---and new ones built to replace them. 

However, we should be aware that these visions, however contingent,
are not universal. Looking more closely, my informant described to me, the visions
of driverless car developers
often have a strong male bias. They see businessmen
taking driverless cabs to work, and students getting drunk and, unable
to drive themselves home, using automated vehicles to ferry themselves
back to their apartments. These visions may be greatly influenced by
the developers themselves---primarily male engineers with masculinist
preconeptions---either thoughtlessly or as a marketing strategy. But
regardless of the source, they suggest designed solutions may tend to
be predisposed to certain types of uses, and less amenable to others
that fall too far outside this masculine vision. Other uses are still
possible, of course---Uber is already being used by parents to ferry
their kids to school, even though it was almost certainly not designed
for that
purpose\cite{???-http://healthland.time.com/2013/11/14/for-more-parents-its-uber-to-the-rescue/--http://www.nytimes.com/2013/09/26/fashion/moms-van-is-called-uber.html?_r=0}---but
inherent gender bias in design is not a problem that should be ignored
when making large-scale changes to infrastructure, as it can deeply
affect the ways and frequencies with which people choose to use new
technologies. Indeed, a recent UK study suggests men may be more
amenable to autonomous vehicle technologies, and it is worth
considering the role that gender-biased technological visions may have
in that
effect\cite{???-http://www.nytimes.com/2013/09/26/fashion/moms-van-is-called-uber.html?_r=0}.
Thinking about the variety in types, uses, and users of road vehicles---from
subcompacts to vans to pickup trucks; from solo commuting to carrying kids to
hauling construction equipment or moving furniture; from the wealthy
to the poor, the urban to the rural---makes clear that cars are
multipurpose vehicles, with culturally-specific uses. When the
expected user is the commuting, upper-middle-class, working father or
the privileged college boy (and the opposers of the technology are
branded by some, as we saw, as ``soccer moms''), we risk developing
vehicles that preferentially serve certain dominant uses and not
others. When I asked one informant whether the developers have an idea
of what driverless cars would mean for people who have children, he
replied:  ``they don't think about it.'' While certainly not shared by
all developers in this space, it is not a vision we can afford.



