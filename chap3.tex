\chapter{Hybrid Controls, Hybrid Possibilities}
\label{chap:4}

Technological Realities (27 p)

%% 4. What is the alternative to the teleological progression implicit
%% in the for- and against- stories?
%% (start with story of planes [the backing off from full autonomy] or Mars rovers or something
%% -HSC
%% -Autonomy research from other areas
%% -envision some alternatives
%% -some stakes (data) are still applicable, but others may be
%% ameliorated

Most automated vehicle narratives---and all those we have investigated
so far---rest on two primary, interlocking assumptions. First, the nature of the
ideal human-machine interaction for vehicle control is assumed to be
known. Second, an inevitable progression toward not only greater
autonomy but complete autonomy is assumed as the
starting point of these arguments. Rarely if ever does the question of
how much autonomy or supervision to provide to the automated system
enter the discussion as an engineering parameter over which designers
have control, and which should be responsive to larger goals. Instead,
advanced driver-assistance technologies and fully-self-driving
operation with no need for human supervision are recognized as
technologically connected, but perceived as fundamentally dichotomous
approaches. Fully-self-driving operation is considered---often via a
speculative or ideological basis---either good or not-good compared to
current vehicles with driver-assistance technologies; it is not generally
perceived as the upper bound on a spectrum of automation
approaches.\footnote{And as we will see in this chapter, even
  so-called ``full'' autonomy would not, in practice, be so simply
  disconnected from human oversight.} And through all this,
fully-automated operation is assumed to be the ultimate end goal, in a
realm of complete technological possibility: the ideal human-machine
interaction is, in a sense, no human-machine interaction. As I have
outlined, this perspective comes from particular roots (automation
history, artificial intelligence, science fiction), but is not the
only way to envision automated systems. There is a deep history of
work in human supervisory control (HSC) that has great implications
for the real-world design of automated systems, and which tells a
potentially very different story about what automated vehicle
operation will look like from a ``driver's'' point of view.

\subsection{Human Supervisory Control}

—while Hutchins' cockpit
remembers its speeds through a combination of human activity and
physical cognitive aids,\cite{???} the NHTSA's “vehicle” may sometimes “not
perform a control function.”\cite{???}

ref back to NHTSA/SAE; starting from P. 9 of the DM paper: The documentation of the Google car's Nevada driving test
exposes fractures in the traditional perspectives on vehicle
automation.\cite{???} 

As a way to INTRODUCE HSC, actually

NRC report on aviation (see e.g. 14-15)

Defense Science board report (DSB)
NASA, and the Defense Science Board in their report The Role of
Autonomy in DoD Systems, describe this proliferation of attempts at
autonomy taxonomies as developing out of Sheridan's work.i The DSB
identifies that these levels formulations are “often incorrectly
interpreted as implying that autonomy is simply a delegation of a
complete task to a computer, that a vehicle operates at a single level
of autonomy and that these levels are discrete and represent scaffolds
of increasing difficulty,”ii all interpretations made by both the
NHTSA and SAE taxonomies and ones I have been attempting to critique.
The DSB highlights two main negative consequences of the popularity of
levels of autonomy: that it “deflects focus from the fact that all
autonomous systems are joint human-machine cognitive systems”1 and
that it “reinforces fears about unbounded autonomy” while obscuring
the fact that no systems are fully autonomous.iii Humans are always
involved somewhere along the line, in their programming, production,
and use, though it makes sense that the military, focused as it is on
human command hierarchies, would find it especially important to make
this apparent. 

EVEN ``FULL AUTONOMY'' is not likely to be so simply full; got to have
a stop/abort button! if so, that implies some human oversight, which
means you have to start questioning how much, when, and how is it
regulated or supported?

\subsection{Lessons from Autonomy Research}

Apollo/Mars rover

Underwater exploration

Aircraft (see Digital Apollo ch 2)

\subsection{Whither Alternate Narratives?}

note especially the contradiction within X's characterization of human
drivers and their future: ``humans are bad drivers and we should all
have our licenses taken away'' compared with ``car nuts should welcome
this because it will free the roads up for them'' which doesn't
actually make sense!
--but there's perhaps a middle ground here in the hybrid narrative

-question of whether people will be allowed to drive
--self-contradictory comments: Daniela Rus saying
-that people will still be able to drive normally
-these questions are deeply embedded in the idea of progress: does
-greater safety imply taking licenses away? a question that really
-only makes sense with a particular vision of autonomy (perhaps a
-better question is what sort of licensing/training is necessary)


1) bring in the telerobotics/supervisory control literature
-why supervisory control? and where is it used? (5 p)
-examine the issue of deskilling vs. the ``irony of automation'' well
known in Human Factors, in which increased automation actually
increases human load (2 p)
-but SC allows for particular combinations of human skills and machine
competencies (1 p)
--used all over industry, aviation, undersea (2 p)


3) situate the moonshot approach (which may actually be easier in some
senses but less socially acceptable) and the mixed approach in a way
that does not support a teleology of autonomous vehicle development
(think Sheridan's graph of telerobotics, not the SAE's 5 stages) (4 p)
--in historical context of previous systems that are wholly or
partially autonomous (4 p)





