\chapter{Conclusion: Driving the Future}
\label{chap:4}

%%Resisting Teleology / Conclusion (14 p)

Our journey through ideologies of automation and driverless vehicle
development has taken us from an explication of the dominant narrative
of the ``self-driving'' vehicle, through an examination of what this
might mean for our society, to an investigation of an alternative
narrative and the real histories that support that narrative. What
should be clear from this thesis, but which must be made clearer in the
public discourse about increasingly automated technologies, is that a
movement from human systems, through hybrid systems, to fully
autonomous systems autonomous is not inevitable. It is not a
requirement of technological progress, or a fundamental fact about the
future, but one narrative among many which must be conditional on our
acceptance as well as on technological, and in many cases
infrastructural, progress. A forward march of
technology does not alone make full autonomy acceptable or viable,
but presents a convenient cover story for the economic objectives of
organizations involved in automating the car.

\section{Reshaping the Road: A Last Lesson in History}

So far, I have treated the current status
quo as a foregone conclusion: that cars would have separate spaces on
the roadway, and generally interact with pedestrians in a controlled
fashion.\footnote{This is not, however, to minimize the human
  interaction component between drivers and pedestrians at crosswalks
  and lights. Such interactions are a critical part of navigating city
  streets, and some interesting research work has been done building
  machines that take them seriously. Of particular note is Nicholas
  Pennycooke's thesis on AEVITA \cite{aevita}. Negotiating street
  space with unpredictable and difficult-to-read human beings is a
  major stumbling block for automated vehicles.} However, there was a
time when city streets were not primarily the venue of the automobile,
but were mixed-use areas where children played, vendors sold goods,
and adults walked, talked, biked, and gathered socially. The street as
a social space predates the concept of the street as a throughway for
motorized transportation specifically, and its changes over the past
hundred or so years are greatly responsible for the inhumanity of the
modern urban landscape, an inhumanity that current urban designers are
interested in reversing. 

Early automobiles and streetcars shared the roads with other social
uses. And this space sharing caused problems for the drivers and
manufacturers of fast moving, dangerous vehicles, which all too
frequently inflicted bodily harm on those people with which they
shared the environment. The regimentation of public space into
crosswalks, where pedestrians are legally protected, and other parts
of the roadway from which pedestrians are supposed to be excluded, is
a direct outcome of an early 20th century campaign to reduce
pedestrian deaths. ``In the early days of the automobile, it was
drivers' job to avoid you, not your job to avoid them,'' describes
Peter Norton, the author of \emph{Fighting Traffic}
\cite{voxNorton}.
But accidents nevertheless occurred, and the victims were primarily
children and the elderly\cite{voxNorton}; and the deaths of children,
specifically, came to have a new social meaning that made them
particularly abhorrent.
After Mary Miner's death in 1903, the driver was almost beaten by a
mob \cite[p. 22]{zelizer}. Accidental deaths of children were an
alarming problem, with a significant public response:  mobs attacked
the killers, acts of public mourning memorialized the lost, and a
national safety campaign began to attempt to reduce these
deaths \cite[p. 23]{zelizer}. Public outrage cast automobiles as
``frivolous playthings'' or ``pleasure cars''\cite{voxNorton}, magnified
by a transformation in the sentimental worth of
children. 

This contest for public space involved a potentially radical change in
the uses and meanings of the street. As Zelizer notes, the city street
was formerly a playground for children, in part out of the necessity
to find some space for play amid crowded tenements \cite[p.
  33]{zelizer}. But children did not surrender their street games
easily, and their ``eviction'' from the streets came about via safety
campaigns and ``Americanization programs''---which encouraged
immigrant children to use playgrounds, instead of streets, as their
play spaces---catalyzed by the automotive threat\cite[p.
  35]{zelizer}. But the deaths of children at the hands of
automobiles were not solely placed on the shoulders of drivers. As the
death rate became a national crisis, the
early press ``pinned most of the blame on parents'': modern life, it
was said, ``cannot be retarded to enable heedless children to get out
of the way'' \cite[p. 37]{zelizer}. Street games were turned into
criminal offenses by around 1914, and the police arrested many
children, but fatalities kept increasing nonetheless\cite[p.
  38]{zelizer}. Families were called upon to take a greater role
in protecting children from the perils of the street; mothers were
charged with keeping their children out of ``what had been their play
areas'' in order to keep the roads clear for automobiles, and safety
crusaders tended to blame mothers for the deaths of their own
children \cite[p. 73]{lochlannjain}. The homogenization of the road
for ``transit'' \cite[p. 73]{lochlannjain} involved not only
family pressures but a concerted legal and public relations campaign. Automakers
and dealers, concerned by public pressure for speed governors on
automobiles, pushed for stricter pedestrian controls across the country, and
auto industry groups exerted significant pressure on the creation of
the 1928 Model Municipal Traffic Ordinance in order to build a law
that was friendly to automobiles \cite{voxNorton}. To attempt to
compensate for laws that were rarely followed and enforced,
auto-friendly groups worked to change the public dialogue. Articles
ghostwritten by the National Automobile Chamber of Commerce shifted
the blame for traffic accidents to pedestrians; the AAA sponsored
safety campaigns in schools; and police and citizens were called upon
to shame transgressors in order to set new public standards---even the
name for the infraction, ``jay-walking,'' was intended to create
public opprobrium for the supposed ``hicks'' who did not know how to
behave in cities, and to shift blame to them \cite{voxNorton}. This
change in the way streets were utilized entailed a large societal
shift motivated by a new technology, but it would be wrong to say it
was caused by the automobile. Instead, automobility was an enabling
force, which provided auto companies and their supporters the impetus
to shift public standards in a particular direction, and to shape the
street to their own advantage.\footnote{Cars were not, however, the
  only technological device responsible for 
the beginning of the street as we know it. Instead, the bicycle marks the
beginning of the ``good roads'' movement, and the push for ubiquitous
road
paving\cite{voxCycle}.
Bicycles and the social groups that championed their use--aided by
asphalt manufacturers and other special interests who saw money to be
made---created the 
very roads that bicycles then had to compete with cars for space on
\cite{voxCycle}. Many of the primary riders who had succeeded in lobbying for
the 1916 Federal Aid Road Act, however, switched over to pioneer the
automobile as its popularity rose in the early 20th century.} 

This historical
example provides some insight into the process by which new
transportation technologies become entwined with new social standards
and legal principles. Technological epistemologies are deeply involved
in this process: What is a road for? What is a vehicle's
proper role? We know that a road is intended for driving precisely
because we have been taught according to a social code that was
designed to foster automobility. What is the new epistemology needed
to make sense of devices like 
automated vehicles in their every-day existence? We are so far not
used to encountering such devices
except in weak forms such as cruise control and automated
transmissions. How should we regard them?
Automobiles were long subject to disputes over their nature: were they
fundamentally safe vehicles misused by people, or fundamentally
dangerous technologies that required careful licensing and use to
make safe? In one such battle over cars as ``dangerous
instrumentalities,'' a court held that ``Until human agency
intervenes, they are usually 
harmless'' \cite[p. 70]{lochlannjain}. Such legal statements
explicitly involve human agency, but machine agency presents the
possibility that such claims could be obsolesced. Are our intuitions
affected when and if automated vehicles can be said to ``operate
themselves'' for some periods of time, nonwithstanding the centrality
of human supervision to operations over the long term?
And what new re-shapings of public space will happen as part of the 
popularization of these technologies? Will these vehicles increase the
segregation of the road space, and require new lanes that are even
more insulated from pedestrians? Or will faster reaction times and
always-attentive automated safety features foster tighter, mixed-use
environments?\footnote{And additionally, as the concept of replacing traffic
lights with a slots system, as described by Paolo Santi, should have
us asking, which types and classes of users will the new environments
and standards benefit? Will environments improve for those with access
to technology, while being degraded for those without?}

\section{New Epistemologies}

How we ask and answer such questions depends on our understanding (or
not) of our own hybridity with technology. This hybridity deserves
to be more broadly appreciated within the public sphere. 
In fact, I hold that fostering its appreciation is of paramount
importance, one of the great challenges for the public understanding
of technology in the near future. Without an understanding of our
currently hybrid nature, we risk having to choose between blind ludditism
and equally blind technophilia. We come to face questions of our own
obsolescence, and are left with no way out because our way of thinking
about the world no longer corresponds to the world we see and live in
on a day-to-day basis. Either humans should drive, or machines should
drive. The idea that humans drive through machines, or machines drive
via humans, or that human and machine drive in combination, are
practically incomprehensible. They seem like failures---and they are
failures for an ideology of complete technological dominance---when
indeed they may be the roots of our greatest successes. But once we
recognize that we \emph{already} drive through machines, and that they
even already may drive through us---consider blind-spot
warning lights, which are an automated system designed to affect the
human and produce a response, but have no individual capacity to drive
the vehicle---multiple, multifaceted futures of automated vehicle
development open to us. We are not building robotic
chauffeurs, but rather designing ourselves, in some fashion, into more
hybrid, more cyborg, entities.\footnote{To return to science fiction, Phillip K. Dick said in
a 1972 speech: ``Someday a human being, named perhaps Fred White, may shoot a robot
named Pete Something-or-Other, which has come out of a General
Electrics factory, and to his surprise see it weep and bleed. And the
dying robot may shoot back and, to its surprise, see a wisp of gray
smoke arise from the electric pump that it supposed was Mr. White's
beating heart. It would be rather a great moment of truth for both of
them'' \cite{androidHuman}.
While ``Pete Something-or-Other'' does not yet exist, ``Fred White''
is already here. Fully comprehending this is a critical task for the
maintenance of cogent, productive public conversations---and
policymaking---about automated vehicles.}

%%TODO (DONE) insert cyborg ref briefly
%While they may permeate Hollywood movies, most people would probably
%say that they are not yet here. 

The cyborg is publicly understood as an artifact of science
fiction. But I would argue that we are
all cyborgs, to a greater or lesser extent, in our interactions with
everyday technologies and devices---not only those people augmenting
their bodies with implanted electrodes, or making use of prosthetics
to replace lost limbs, but everyone who interacts with a computer,
carries a cellular phone, or drives a car. This idea has received
serious attention and consideration in philosophical circles, and
deserves to be revisited here as we consider \emph{why} the hybridity
of vehicle operation is not widely recognized, and what can be done to
increase popular appreciation of this operation and the important
questions it reveals about how we design the future. Our world is
becoming a ``cyborg planet,'' to an extent many have not yet
realized \cite[p. 64]{ekbia}.

The idea of the ``cyborg'' was introduced by Manfred Clynes and Nathan
Kline in 1960 \cite{clyneskline}, as a descriptor for the alteration
of human beings to 
cope with the conditions of outer space: they would be self-regulating
\emph{cybernetic organisms} \cite[p. 66]{ekbia}. While the creation of
such cyborg astronauts was never attempted outside of the imagination
of science fiction writers, astronauts were indeed fashioned into
cyborgs by their existence within suits and spacecraft with which they
had to interface for their survival, and the cyborg idea has become a
powerful cultural force.\footnote{As Donna Haraway, one of the most recognized
philosophers of cyborg culture (and cyborg feminism), describes:
``Contemporary science 
fiction is full of cyborgs---creatures simultaneously
animal and machine, who populate worlds ambiguously natural and
crafted'' \cite[p. 117]{haraway}.} Meanwhile, cyborg technologies
abound in real life, from the extreme to the mundane: implants to
achieve increased sensory range and experience, or to trigger orgasm
\cite[p. 64]{ekbia}; implants to monitor vital signs; telerobotic
arms; bots and chatbots; implants to provide neural control of
vehicles \cite[p. 65]{ekbia}. 

%% ``Modern medicine is also full of
%% cyborgs, of couplings between organism
%% and machine''\cite[p. 117]{???-haraway}. Meanwhile, the cyborg has
%% infiltrated our methods of production and destruction: ``Modern
%% production seems like a dream of cyborg colonization work, a dream
%% that makes the nightmare of Taylorism seem idyllic. And modern war is
%% a cyborg orgy, coded by C3I,
%% command-control-communication-intelligence, an \$84 billion item in 1984's US
%% defence budget''\cite[p. 118]{???-haraway}. 
%% Haraway's view is not altogether pessimistic, as she sees in the cyborg
%% the potential site of a new epistemology that does not recognize or
%% repeat Western binaries and cultural subjugation\cite[p.
%%   118-121]{???-haraway}. But while one can hardly mention cyborgs without
%% mentioning Haraway, hers is not the vision I find most relevant for
%% understanding automated vehicles. Instead, I would like to consider

But, more fundamentally, philosopher Andy
Clark contends that humans are ``(disguised) \emph{natural-born}
cyborgs'' \cite[p. 66]{ekbia}. This idea is particularly compelling
because it need make no distinction between the analog and the
digital, the material and the virtual. It is not an artifact of the
present moment, but a fundamental component of human experience. To
Clark, our ``ability to enter into deep and complex relationships with
nonbiological constructs, props, and aids'' is what best explains our
distinctive intelligence \cite[p. 66-67]{ekbia}. This therefore holds
not just for cars, or information and computer technologies, but for
all kinds of technology. Our existence as a technological species is
not new, and human technological augmentation goes back into
prehistory. Our engagement with technological tools and
artifacts---whether the tool is a smartphone, a loom, a wheel, or
fire---is what makes us, fundamentally, cyborg beings.\footnote{Though Haraway holds that ``By the late 20th
century, our time, a mythic time, we are all chimeras,
theorized, and fabricated hybrids of machine and organism; in short,
we are cyborgs'' \cite[p. 118]{haraway}, I stand with Clark that we
have long been so. It is only recently however, in part due to the pressure
that AI places on human-machine dualisms, that this state of being has
come to be recognized.}

This concept is particularly powerful and valuable because it
challenges hundreds of years of assumptions about human beings and
human achievement---even some that are deeply ingrained in the human
factors engineering work I lean on in chapter \ref{chap:3}. We are
possessed by the idea that our technologies change, but that the human
being remains fundamentally the same.\footnote{As Richard Horner put
  it to the test pilots assembled at the SETP banquet in 1957: ``the
  one link in the manned system which we have that improves the least
  in successive generations, is the man himself''\cite[p.
    19]{DM}.} However, this assumption rests on a long held 
dichotomy of human and machine, and the idea that the object of
interest is the purely biological human. If prosthetics and artificial
organs teach us anything, however, it should be that these boundaries
are by no means clear. AI is however heir to a world of such sharp
boundaries: mind and body, subject
and object, nature and culture, science and politics \cite[p.
  327]{ekbia}. Science, engineering, and broader culture ``embody'' and
``regenerate'' these divisions \cite[p. 327]{ekbia}, but they are
fundamentally only true or useful analytical frameworks, so we must
ask whether they continue to serve us well, or whether they should,
despite their attractive simplicity, be retired.\footnotemark Cognitive
anthropology starts to break down these 
divides, with the inspection of a human-machine cognitive system as a
whole, but there is more to be done. Ekbia asks, what happens if we
abandon the outmoded question of whether machines can reach our level
of intelligence or capability, and instead ask how  ``humans and machines
[are] mutually constituted through discursive practices?'' \cite[p.
  328]{ekbia}. 

\footnotetext{Ekbia, considering the source of ideologies of AI, sees its roots in
the teachings of Democritus---carried forward by Hobbes
and Descartes---and the separation of the atomist world and our
representations of it \cite[p. 331]{ekbia}. These dualisms are deeply
engrained in our 
thought patterns, but fail us when thinking about advanced
technologies and their impacts because they favor unrealistic---and
indeed, unreal---totalisms: all human or all machine, fully manual driving or fully
autonomous driving.}

%% TODO: FIX THIS FOOTNOTE, make it clearer how it fits

The problem facing AI, according to Lucy Suchman\footnote{Note that
  Ekbia cites this statement as well
  \cite[p. 331-332]{ekbia}.}, ``is less that we attribute agency to
computational artifacts than that our language for talking about
agency, whether for persons or artifacts, presupposes a field of
discrete, self-standing entities'' \cite[p. 263]{SuchmanPlans}.
Instead, we should be asking how does intelligent behavior emerge in
the interactions of 
humans and machines, refusing to fix \emph{a priori} the category of
the human. Automated vehicles are a product of AI, and are vulnerable
to the same critique. 

New epistemologies, involving perhaps a broader recognition of our
cyborg nature,  may be
necessary at multiple levels. At the level of the individual, what is
the role or status of the human, and that of the machine? How do we
classify, and make sense of, users and devices, and their
relationships of supervision and co-operation? At the level of the
system, what new understandings of the role and purpose of the road
itself are needed if we want to make use of automated technologies to
make cities more humane? At the legal level, what is the status of a
vehicle acting autonomously on a certain time scale? And how can
responsibility be apportioned between supervisors and the
supervised?\footnote{It is important to note that ``responsibility''
  is not binary, nor 
should it be an all-or-nothing prospect. Legal scholars note that
torts may already be distributed across human and nonhuman actors
(operator, owner, seller, manufacturer, distributors) in legal
rulings, but distribution of torts has an ethical
and ideological stance \cite{suemycar} \cite{proximityLiability}. The distribution of
torts to different actors in the system may vary from situation to
situation, given the capacities of 
the vehicle and the driver \cite[p. 267]{suemycar}. However,
the current liability framework does have problems, including the
potential to scapegoat the human being, and the expense and difficulty
of pursuing litigation.}
The question of what we can actually ask the human to do, and hold them to task
for, is a critical question both for automation system design and the
legal handling of cases involving such automation.
%% Sidenote: important to note that issues of litigation for full autonomy are
%% not even part of the debate yet, we just aren't at the stage where it
%% is worth discussing

%% There are, however, problems with the using
%%   the current liability framework to deal with blame and
%%   responsibility in highly-automated systems. It is expensive for the
%% litigant to get expert witnesses to testify as to the apportionment of
%% responsibility between human and machine, and the human tends to be
%% scapegoated all too often in industrial accidents involving human
%% supervisors interacting with automation.

And questions of the appropriate role of the human being involve not
only the supervisor, within the vehicle or in a remote data center,
but other users in the environment. If streets must be re-made in
order to make certain technological configurations viable, is that
re-making something the public is willing to accept? And who will
benefit from it? As Dieter Zetsche, chairman of Daimler AG describes,
``anyone who focuses solely on the technology has not yet grasped how 
autonomous driving will change our
society'' \cite{slashgearDavies}.
But as we have found in the past, changes that favor the users or
manufacturers of automated vehicles may not favor other users of city
spaces, who may find their freedoms foreclosed upon. The history of
the re-making of the city and street is part of why I hold that
vehicle automation is not an 
independent factor to be maximized, but a variable that is firmly
intertwined with the design of the whole transport system.
As I have described, these vehicles sit in a much broader network of
social relationships: the city and the street have changed before, and
will change again, to accomodate new technologies, assuming sufficient
social and economic pressure to catalyze that change.\footnote{Technologies do
not alone bring about those changes, but their presence, availability,
and market viability provide incentives for groups to encourage broad
social and infrastructural changes.} The automated vehicle represents
another possible nexus for change, but how the city will be re-shaped
is an open question. 


\section{The Shape of Automation}

And as I find myself repeating continually, because it is such a vital
recognition, complete autonomy is ultimately a foreign concept,
something no current automated vehicle plans point toward. Until
vehicles construct themselves, monitor themselves, pay for themselves,
and are intended only to drive themselves around---a strange world
indeed---human oversight is inescapable. Vehicles serve human needs,
are constructed and operated by humans or organizations made of
humans, and are ultimately paid for by humans. While certain types of
labor may be eliminated, and certain laborers marginalized, a
system-level view of automation continues to uncover vast amounts of
human labor---perhaps at the periphery of the car as an individual
object, but unavoidably implicated in the day-to-day reality of
vehicle operations. At the most radical, and most teleological, we are
facing not a system of autonomous robots but fleets of telerobotic
vehicles with closed-loop control systems providing limited autonomy,
that are supervised by remote operators within the datacenters of
multinational IT corporations.\footnote{I have encountered few
  companies who seem to be honest about this supervisory arrangement,
  but the founder and CEO of the mini-cab app company Kabbee envisions
just such a thing: ``There’s no reason why a taxi driver couldn't have
something like three screens in front of him . . . and sit in a studio
directing three or four or five cars through the roads of London where
they are driverless cars with a human controlling the GPS''
\cite{forbesDawson}.
Whether the appropriate number is 5 or 5000 cars, this vision seems
plausible, and bears similarities to current Predator UAV operations.
It also sounds quite a bit like GM's `Autoline' concept from 1964,
mentioned in the introduction.}

%%TODO (DONE): 
%%Kabbee gets the supervised idea!

But even this, though it presents certain advantages, is by no means
our obvious future. Such a networked system worsens issues of privacy
and data security. Longer time periods of unsupervised operation, and
more limited involvement of the people within the vehicle, require
automation technologies with greater reliability and situational
capability, in order to reduce the risk of catastrophe for
operators---whether that catastrophe is measured by personal death or
system failure leading to financial ruin. Even Tesla Motors, bullish
about its forthcoming ``autopilot'' technology, admits the limitations
of current automated systems: automated driving will not be available
in residential neighborhoods because they do not believe it is safe
enough\cite{slashgearDaviesT}.
More capable systems, able to operate without failure in a greater
proportion of real-world situations, may require human involvement and
supervision, at the very least until significant open problems in
artificial intelligence are solved. Human beings are not solely
sources of failure to be engineered out of systems, but are also
successful operators and risk-mitigators, who are capable of
performing complex and difficult tasks. And it would be wrong to
categorize human involvement as purely a temporary requirement, until
computers are sufficiently advanced:  it
may be that whatever the ultimate capabilities of machines, we may
find it socially unacceptable to surrender certain areas of operation
completely to computers. The method and timescale of automated
operation may greatly impact 
public acceptance, to the point that certain types of human
involvement may be required to produce marketable
technologies.\footnote{Other barriers to public acceptance that are
  amenable to alternative operational modes include travel sickness. A
  recent University of Michigan study suggests car sickness could be a
  problem for automated vehicle systems, as well as significantly reducing their
  convenience factor
  \cite{SivakSchoettleSick}.
  Certain levels of human involvement would reduce the perceived productivity
  gains of automated systems, but could ameliorate travel sickness issues.} Though
this may be distasteful to some technologists invested in furthering
technological solutions to social problems, it is not fundamentally
a failure. It is a societal choice to which engineering solutions
should be pliable.

Many examples of hybrid systems exist, and joint-cognitive-systems
design presents an alternative way of looking at problems, and valuing
human and machine contributions to their solution, that opens the way
for other futures. And as we have seen, these approaches and
perspectives are not those of ``mere'' luddites or humanists on the
margins of engineering practice, but of an important segment of
engineers themselves who are vital to the design and construction of
successful real-world systems. The hybrid human-machine system is a
very difficult engineering problem---we are not necessarily making
things easier on ourselves by choosing such a solution compared to a
more fully automated one, something even the Department of Defense,
hardly a bunch of technophobes, finds it important to recognize---but
it is also a valuable approach for 
systems that are tasked with keeping us safe, whether in space, in the
air, or on the ground. In applying this approach, however, it is
important to keep in mind the extent to which we are re-making
ourselves into managers or into machine tenders:  Are we maintaining a sense of
creative agency? Or becoming wheels in the machinery of capital? And
this is especially true as we will use our 
vehicles every day, and cannot afford to alienate ourselves from them.
A future in which our transportation system is indifferent to us is
not a productive future to be lauded, but a destructive one to be
avoided. 

This discussion has tried to frame the largely invisible histories involved in
notions of autonomy and automation, the ideologies flowing into the
dreams of driverless cars and attendant approaches to system design.
When we use factory automation, artificial intelligence, ``NASA
engineering,'' or autopilot to frame ideas about self-driving
vehicles, we carry forward certain ideas about these technologies that
narrow and constrain our vision, irrespective of actual historical
developments. We risk 
thinking about autopilots as a small step away from being full vehicle
operators, rather than as tools used by vehicle operators to support
their needs. We risk thinking about factory automation as a
teleological process toward the elimination of labor, rather than a
deeply contingent process that changes the forms of certain kinds of
labor into other forms, or shifts that labor in time and space. We
risk thinking about NASA as an organization responsible for
engineering highly automated, redundant systems, rather than an
organization full of people whose jobs include constant monitoring,
supervision, and interactions with the same automated systems. We may
consider new automation through the lens of the artificial, of
building systems to replace people, or through a hybrid lens, building
systems to support humans in their tasks. Both ways of considering
automated systems can often be applied to the same technological
artifact, but result in very different ways of thinking.\footnote{A
speech-to-text system can be seen as either a technology to transcribe 
the human voice into text instead of a person, or a tool to assist a
human with transcription. But the choice of perspective will likely do
much to change how such a technology is designed. I would hypothesize that
the focus on what computerized personal assistants can do, for
example, as opposed to the process of human and machine jointly
carrying out a task and accomplishing something together, does much to
explain the repeated failure of personal assistant technology to gain
users.}  Throughout, I have emphasized the contingency of current
automated vehicle plans on specific ideas about the appropriate and
necessary role of technology, and stressed the presence of other ways
to regard vehicle automation technology that could bring about
different futures. There is no reason that commonly accepted ideas
about complete vehicle automation are necessarily right---and that
partial, or function-by-function automation, for example, is simply a
stop-gap measure. In contrast to the simplistic depictions provided by
most media representations---of pro-and-con, for-and-against, but all
focused around a particular view of the object of study, not asking
what automated vehicles will truly be, but only what will this assumed
object do---which form the visible picture of this technology today
for most people not involved in its engineering, I have described a
range of alternative narratives that complicate our ideas of what
automated vehicles can and will be.

\section{Automation and Social Goals}

Ultimately, from a design and policy perspective, my point is that we
cannot achieve positive social effects by na\"{\i}vely adding autonomy to
existing vehicles. Autonomy and automation are not natural goods to be
fostered wherever they can be, but technological tools and strategies
for achieving particular goals. The manner and extent to which we
build our vehicles to be autonomous stands to produce very different
social impacts, to the point where going from the idea of the
``self-driving vehicle'' to social and cultural impacts is
fundamentally backward, since the vehicle itself is not fixed and
small details may matter a great deal in real-world use. Instead,
social changes have to be at the center of design and implementation.
What are the goals a vehicle is designed to achieve, and which goals
are more important than others? Increasing
statistical safety by a factor of 100? Providing mobility for the
elderly or disabled? Reducing the environmental impact of vehicles and
their emissions? Increasing throughput of the roadway? Reducing
traffic delays for commuters? Equalizing the 
disparities in mobility between the wealthy and the homeless? It is
fantastical thinking to believe that the just-add-autonomy approach
will automatically achieve all these goals. Each presents a
system-wide design problem, involving cars, people, and
infrastructures, that puts different demands on possible solutions.
And some contradict the motives of organizations responsible for
providing the solutions:  while automobile companies can promulgate
ideas about how automated vehicles can provide greater mobility, help
the environment, and reduce traffic, they are unlikely to economically
back concepts that are against their interests---anything that reduces
the number of vehicles on the road,\footnote{Thanks to Joe Dumit for eloquently
  making this observation during a recent visit I made to UC Davis.}
or the overall cost of those 
vehicles, without providing a new revenue stream to compensate,
represents a deeply suspect investment. 

Problematically, the automated car---like the
``smart city'' which has already been critiqued in this
way \cite{greenfieldSmart}---presents the opportunity for successful technology
companies to wrest greater control over everyday life, to worm their
way more deeply into our existence and thereby make themselves
indispensable. Automation can be a tool to enable one group of
people---technologists running multinational organizations---at the
expense of the rest of us.
But it also does not have to be employed toward those ideological
ends; given sufficient willpower, it can be made to serve others.
As I held in chapter \ref{chap:2}, changes to the city
should not be arbitrary, at the whims of a certain set of
producers and organizations, but part of a large-scale system design
strategy to address the needs of all transportation users.

%% The pro-side: millions of deaths if we don't do something now, so we
%% have to accept these
%% The con-side: (regulator) current deaths not on my hands, but if one
%% little girl is killed by a robot I've lost my job

But public rhetorics of driverless vehicles have an unfortunate
tendency to avoid these complex questions. One popular and troubling
argument revolves around responsibility for the rollout of
self-driving systems. On the pro-side, commentators stress the many
thousands who will die if self-driving systems are not implemented
soon, using that as a lever to argue for the moral imperative of
speeding up their legalization and acceptance \cite{baileyReason}
\cite{howardRobots}. On the con-side, in 
this interpretation, stand the risk-averse regulators: current deaths
are obviously not on their hands, but if one child is killed by a
``robot car,'' they face public censure. But though this cartoon-like
view of reality does have a media public face, it does not do justice
to the complexity of the situation. The statistics about driverless
cars and risk, though partly a function of mathematical modeling, are
also, fundamentally, matters of faith. No one has the precise answer.
While we can point to the 90\% of accidents that involve human error,
computers will fix some of these types of error but may also cause
other problems, and increase failure rates unrelated to human error.
The safety record of ``current'' vehicles is also not fixed; even if
we were to accept the popularly figured distinction between
incremental autonomy and ``complete'' autonomy approaches, the safety
of increasingly autonomous vehicles is a moving target against which
the achievements of more radical approaches would need to be compared.
Complex changes to complex, high-stakes systems produce unpredictable
results. So how we implement automated vehicle technology is as much
about narratives, the stories we believe and tell about technology, as
much as it is about mathematics, and modeling the world. 

Our choice should not be to either accept this driverless vision or take
responsibility for the deaths of thousands. That viewpoint is abusive, coercive,
and deeply wrong, and the future is too important to be left up to
knee-jerk techno-utopianism and blind ideology. This is not a question
of whether fully automated cars can come to exist, even as they are
now envisioned. I am not saying that the science-fiction dreams of
driverless vehicles are possible or impossible, and I believe in the
potential of computer technologies to achieve groundbreaking results.
But many worlds that look lovely in science fiction represent places
we may not actually wish to live, and these portrayals can afford to
avoid issues of reliability and human interaction that we cannot avoid
in the real world. There are other choices to be made as we work toward building a
more automated future. Our choices should be between options, between
visions, choices of how we integrate humans and computers to make our
driving safer, our cities more livable, our lives better. The Google model which has
captured so much press attention is one among innumerable imagined or
not-yet-imagined possibilities. Automation is not a
take-it-or-leave-it phenomenon, and the choice to accept one
particular model of vehicle automation or accept tens-of-thousands of
prospective road fatalities is a false choice. There is more on heaven
and earth than is dreamt of in this philosophy, and it is time we ask
of autonomy not the na\"{\i}ve questions of whether it will keep us
safe and improve our cities, but the deep, engaged, and difficult
questions of how it can be leveraged to achieve such aims. The real
question we need to ask is what form technologies of vehicle automation 
should take, and what benefits and acceptable sacrifices adhere to
that choice. This question is a truly multidisciplinary venture,
involving engineering, law, policy, design, and ethics. When we
automate, do we choose to do so with the philosophy of ``do no harm,''
or ``save more lives''?\footnote{These are deep and subtle questions,
  but proclaiming them meaningless from an engineering perspective is
  to miss the importance of ideas to guide technological development,
  and the social importance of developed technologies. I am grateful
  to Evan Donahue in particular for a discussion of how the
  implications of the Hippocratic oath differ from those of a
  philosophy specifically oriented around saving the greatest number.
  These two basic premises, extrapolated out to their logical
  conclusions, may diverge rather than converge, in ways that remind
  us of the dystopic potential of quantification and optimization,
  which can lead to solutions that are fundamentally inhumane. It
  would be foolish 
  to assume that medical systems, themselves a collection of
  technologies and people, are not affected by these kinds of distinctions.} There may be hidden consequences to these
philosophies---who is saved? and how? and who bears the cost, or is
counted out in order to save the greater number?---that come to deeply
affect how systems engineered from these alter the world.
%% (Evan, on Hippocratic oath: why is it ``do no harm'' not ``save more
%% lives''?
%% there may be hidden consequences to a philosophy of saving more lives)

\section{Lingering Questions}

The purpose of this thesis has been to sweep away some lazy thinking
about automated systems, and to try to re-orient a more nuanced dialog
around different sets of issues. As we think about the future of
vehicle automation---whether as
designers, lawmakers, interested technologists or concerned
citizens---what are the questions we should be asking? What should we
grapple with instead of accepting common framings of the issues
involved? To conclude, let me summarize the main open questions around
which a more productive dialogue about automation could be based.

First, what are the social goals around which automated technology
should be designed and implemented? The relative importance of safety,
convenience, mobility, social equality, and other factors must be
matters of public debate, as they are absolutely central to the
project of automation.\footnote{To the list
of major questions facing us as a result of this technology, given the
interest in full-system design, we might
wish to
add: how do we make transportation technology and urban planning sensitive to social
justice and responsive to a broad base of citizens, and inoculate it
against takeover by corporate entities that have only their own best interests
in mind? But this question is larger than the autonomous vehicle arena.}

Second, for any particular design, what are the appropriate roles of
human and machine in the human-machine system that automated vehicles
will necessarily be? These roles will not be a pure function of
technological capabilities, but will involve numerous other factors,
and will alter the skills that human operators will be expected to
acquire, and the types of licensing and control that are therefore
necessary. 

Third, as part of this question, how do humans interact with and
respond to AI systems that cannot simply be said to
``think'', ``know'', or ``understand'' in the same ways that we do (at
least not yet) but which nevertheless hold our lives in their hands?
And how can human decision making in the design of such systems be
reasonably and successfully audited?
These concerns may be ameliorated by human involvement and
supervision in operations, which means we must consider what types of supervision,
and on what time scales, are socially or legally valuable, and
therefore should be built into that technology. 

Fourth, how should we value different automation approaches, or
estimate their risks, when the technologies involved require complex
changes to complex systems?  This
involves balancing the statistical benefits of different automation
approaches, and coming to conclusions about how to reasonably
estimate risks, test and certify systems, and set engineering
priorities based on this information.

Fifth, relatedly, what is the appropriate role of statistics and risk
projections in governing policy on automated technologies? How safe is
safe enough, for whom, and how is this
regulated? Assuming we can come to reasonable predictions about costs
and benefits, we must close the loop between this information and our
broader social goals. We need to decide how to weigh uncertainties in
our evaluation of which goals matter and which are achievable in the
near term or long term.

%% 2) wrap up with the big questions we are faced with, that we have to
%% grapple with instead of accepting teleology/common media framings: (1
%% p)
%% --1) what is the appropriate role for the human in the human/machine
%% system? (1 p) (and what skills do they need to acquire, what licensing
%% is necessary?)
%% --2) what is the appropriate role of statistics and risk in governing
%% policy on the issue? can you opt-out? how do we balance projected
%% statistical benefits of disparate approaches? (0.5 p)
%% --3) how safe is safe enough? for whom? and how is this regulated? (1
%% p)
%% -----safe for drivers? for pedestrians?
%% -----what types of pedestrians?
%% --4) how do we feel about AI systems that cannot really be said to
%% ``think'', ``know'', or ``understand'' but which nevertheless ``hold
%% our lives in their hands'' (0.5 p) 
%% ----and how is this changed by the promise of continued human
%% supervision?
%% ----what types of supervision, on what time scales, are
%% socially/legally valuable, valuable enough to be build into our technology?
%% ----This may well imply we need the human involved, for that very
%% reason
%% ----and we should KEEP the human involved as a matter of design
%% principle (2 p)

These considerations may well imply the need to maintain significant
human involvement in order to mitigate risk, achieve public
acceptance, and address the human goals that drive technological
development. Rather than ``to automate or not to automate,'' we should ask
``how and why do we automate?'' But even in the most automated
technologies, their 
autonomy is largely an artifact of the lens through which we engage
with them---these systems involve delicate dances of human and machine
components, dispersed through time and space, and only pushed to the
margins of a point of view that takes the technological object itself,
not its sociopolitical and cognitive contexts, as the object of study.
Recognizing that continued human involvement will occur as a matter of
principle is 
the most important first step we can take toward rebalancing the
narrative of automation toward something more productive, which takes
seriously the technological hybridity of our past, present and future.
And it paves the way for a political critique of automated vehicles
that asks, knowing 
that humans remain involved, who they are, where they are, and how
the system is being designed to serve their needs or impede their
agency.

%% TODO make sure there isn't a hanging word!
