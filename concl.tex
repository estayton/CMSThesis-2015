\chapter{Conclusion}

Resisting Teleology / Conclusion (14 p)

1) what should be clear from the above, but must be made clear in
public discourse, is that human->hybrid->autonomous is not inevitable,
it is not a requirement, it is conditional on our acceptance AS WELL
as on technological progress (3 p)
--the hybrid system is a very difficult engineering problem, but this
is valuable for systems that are tasked with keeping us safe (see
Apollo etc.); especially as we will use them every day and we cannot
afford to alienate ourselves from them (4 p)
-This discussion has tried to frame the invisible history, the
ideologies flowing into these systems, the contingency of the plans
--and contrast with the simplistic depictions provided to most via
media
---which form the visible picture as of today, for MOST people (1 p)
>>> possibly split up <<<

2) wrap up with the big questions we are faced with, that we have to
grapple with instead of accepting teleology/common media framings: (1
p)
--1) what is the appropriate role for the human in the human/machine
system? (1 p)
--2) what is the appropriate role of statistics and risk in governing
policy on the issue? can you opt-out? (0.5 p)
--3) how safe is safe enough? for whom? and how is this regulated? (1
p)
--4) how do we feel about AI systems that cannot really be said to
``think'', ``know'', or ``understand'' but which nevertheless ``hold
our lives in their hands'' (0.5 p)
----This may well imply we need the human involved, for that very
reason
----and we should KEEP the human involved as a matter of design
principle (2 p)

