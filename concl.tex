\chapter{Conclusion: Driving the Future}
\label{chap:4}

%%Resisting Teleology / Conclusion (14 p)

Our journey through ideologies of automation and driverless vehicle
development has taken us from an explication of the dominant narrative
of the ``self-driving'' vehicle, through an examination of what this
might mean for our society, to an investigation of an alternative
narrative and the real histories that support that narrative. What
should be clear from this thesis, but which must be made clearer in the
public discourse about increasingly-automated technologies, is that a
movement from human systems, through hybrid systems, to fully
autonomous systems autonomous is not inevitable. It is not a
requirement of technological progress, or a fundamental fact about the
future, but one narrative among many which must be conditional on our
acceptance as well as on technological progress. A forward march of
technology does not alone make full autonomy acceptable or viable,
but presents a convenient cover story for the economic objectives of
organizations involved in automating the car.\footnote{For more about
  how struggles about cities and transportation technologies have
  panned out in the past, see appendix \ref{chap:5}.}

And as I find myself repeating continually, because it is such a vital
recognition, complete autonomy is ultimately a foreign concept,
something no current automated vehicle plans point toward. Until
vehicles construct themselves, monitor themselves, pay for themselves,
and are intended only to drive themselves around---a strange world
indeed---human oversight is inescapable. Vehicles serve human needs,
are constructed and operated by humans or organizations made of
humans, and are ultimately paid for by humans. While certain types of
labor may be eliminated, and certain laborers marginalized, a
system-level view of automation continues to uncover vast amounts of
human labor---perhaps at the periphery of the car as an individual
object, but unavoidably implicated in the day-to-day reality of
vehicle operations. At the most radical, and most teleological, we are
facing not a system of autonomous robots but fleets of telerobotic
vehicles with closed-loop control systems providing limited autonomy,
that are supervised by remote operators within the datacenters of
multinational IT corporations. 

But even this, though it presents certain advantages, is by no means
our obvious future. Such a networked system worsens issues of privacy
and data security. Longer time periods of unsupervised operation, and
more limited involvement of the people within the vehicle, require
automation technologies with greater reliability and situational
capability, in order to reduce the risk of catastrophe for
operators---whether that catastrophe is measured by personal death or
system failure leading to financial ruin. Even Tesla Motors, bullish
about its forthcoming ``autopilot'' technology, admits the limitations
of current automated systems: automated driving will not be available
in residential neighborhoods because they do not believe it is safe
enough\cite{???-http://www.slashgear.com/tesla-model-s-autopilot-update-due-in-3-4-months-19374458/}.
More capable systems, able to operate without failure in a greater
proportion of real-world situations, may require human involvement and
supervision, at the very least until significant open problems in
artificial intelligence are solved. Human beings are not solely
sources of failure to be engineered out of systems, but are also
successful operators and risk-mitigators, who are capable of
performing complex and difficult tasks. And it would be wrong to
categorize human involvement as purely a temporary requirement, until
computers are sufficiently advanced:  it
may be that whatever the ultimate capabilities of machines, we may
find it socially unacceptable to surrender certain areas of operation
completely to computers. The method and timescale of automated
operation may greatly impact 
public acceptance, to the point that certain types of human
involvement may be required to produce marketable technologies. Though
this may be distasteful to some technologists invested in furthering
technological solutions to social problems, it is not fundamentally
a failure. It is a societal choice to which engineering solutions
should be pliable.

Many examples of hybrid systems exist, and joint-cognitive systems
design presents an alternative way of looking at problems, and valuing
human and machine contributions to their solution, that opens the way
for other futures. And as we have seen, these approaches and
perspectives are not those of ``mere'' luddites or humanists on the
margins of engineering practice, but of an important segment of
engineers themselves who are vital to the design and construction of
successful real-world systems. The hybrid human-machine system is a
very difficult engineering problem---we are not necessarily making
things easier on ourselves by choosing such a solution compared to a
more fully automated one, something even the Department of Defense,
hardly a bunch of technophobes, finds it important to recognize---but
it is also a valuable approach for 
systems that are tasked with keeping us safe, whether in space, in the
air, or on the ground. In applying this approach, however, it is
important to keep in mind the extent to which we are re-making
ourselves into managers or into machine tenders:  Are we maintaining a sense of
creative agency? Or becoming wheels in the machinery of capital? And
this is especially true as we will use our 
vehicles every day, and cannot afford to alienate ourselves from them.
A future in which our transportation system is indifferent to us is
not a productive future to be lauded, but a destructive one to be
avoided. 

This discussion has tried to frame the largely invisible histories involved in
notions of autonomy and automation, the ideologies flowing into the
dreams of driverless cars and attendant approaches to system design.
When we use factory automation, artificial intelligence, ``NASA
engineering,'' or autopilot to frame ideas about self-driving
vehicles, we carry forward certain ideas about these technologies that
frame our vision, irrespective of actual historical developments. We risk
thinking about autopilots as a small step away from being full vehicle
operators, rather than as tools used by vehicle operators to support
their needs. We risk thinking about factory automation as a
teleological process toward the elimination of labor, rather than a
deeply contingent process that changes the forms of certain kinds of
labor into other forms, or shifts that labor in time and space. We
risk thinking about NASA as an organization responsible for
engineering highly automated, redundant systems, rather than an
organization full of people whose jobs include constant monitoring,
supervision, and interactions with the same automated systems. We may
consider new automation through the lens of the artificial, of
building systems to replace people, or through a hybrid lens, building
systems to support humans in their tasks. Both ways of considering
automated systems can often be applied to the same technological
artifact, but result in very different ways of thinking.\footnote{A
speech-to-text system can be seen as either a technology to transcribe 
the human voice into text instead of a person, or a tool to assist a
human with transcription. But the choice of perspective will likely do
much to change how such a technology is designed. I would hypothesize that
the focus on what computerized personal assistants can do, for
example, as opposed to the process of human and machine jointly
carrying out a task and accomplishing something together, does much to
explain the repeated failure of personal assistant technology to gain
users.}  Throughout, I have emphasized the contingency of current
automated vehicle plans on specific ideas about the appropriate and
necessary role of technology, and stressed the presence of other ways
to regard vehicle automation technology that could bring about
different futures. There is no reason that commonly accepted ideas
about complete vehicle automation are necessarily right---and that
partial, or function-by-function automation, for example, is simply a
stop-gap measure. In contrast to the simplistic depictions provided by
most media representations---of pro-and-con, for-and-against, but all
focused around a particular view of the object of study, not asking
what automated vehicles will truly be, but only what will this assumed
object do---which form the visible picture of this technology today
for most people not involved in its engineering, I have described a
range of alternative narratives that complicate our ideas of what
automated vehicles can and will be.

Ultimately, from a design and policy perspective, my point is that we
cannot achieve positive social effects by na\"{\i}vely adding autonomy to
existing vehicles. Autonomy and automation are not natural goods to be
fostered wherever they can be, but technological tools and strategies
for achieving particular goals. The manner and extent to which we
build our vehicles to be autonomous stands to produce very different
social impacts, to the point where going from the idea of the
``self-driving vehicle'' to social and cultural impacts is
fundamentally backward, since the vehicle itself is not fixed and
small details may matter a great deal in real-world use. Instead,
social changes have to be at the center of design and implementation.
What are the goals a vehicle is designed to achieve, and which goals
are more important than others? Increasing
statistical safety by a factor of 100? Providing mobility for the
elderly or disabled? Reducing the environmental impact of vehicles and
their emissions? Increasing throughput of the roadway? Reducing
traffic delays for commuters? Equalizing the 
disparities in mobility between the wealthy and the homeless? It is
fantastical thinking to believe that the just-add-autonomy approach
will automatically achieve all these goals. Each presents a
system-wide design problem, involving cars, people, and
infrastructures, that puts different demands on possible solutions.
And some contradict the motives of organizations responsible for
providing the solutions:  while automobile companies can promulgate
ideas about how automated vehicles can provide greater mobility, help
the environment, and reduce traffic, they are unlikely to economically
back concepts that are against their interests---anything that reduces
the number of vehicles on the road,\footnote{Thanks to Joe Dumit for eloquently
  making this observation during a recent visit I made to UC Davis.}
or the overall cost of those 
vehicles, without providing a new revenue stream to compensate,
represents a deeply suspect investment. 

%% The pro-side: millions of deaths if we don't do something now, so we
%% have to accept these
%% The con-side: (regulator) current deaths not on my hands, but if one
%% little girl is killed by a robot I've lost my job

But public rhetorics of driverless vehicles have an unfortunate
tendency to avoid these complex questions. One popular and troubling
argument revolves around responsibility for the rollout of
self-driving systems. On the pro-side, commentators stress the many
thousands who will die if self-driving systems are not implemented
soon, using that as lever to argue for the moral imperative of
speeding up their legalization and acceptance.\cite{???} On the con-side, in
this interpretation, stand the risk-averse regulators: current deaths
are obviously not on their hands, but if one child is killed by a
``robot car'' they face public censure. But though this cartoon-like
view of reality does have a media public face, it does not do justice
to the complexity of the situation. The statistics about driverless
cars and risk, though partly a function of mathematical modelling, are
also, fundamentally, matters of faith. No one has the precise answer.
While we can point to the 90\% of accidents that involve human error,
computers will fix some of these types of error but may also cause
other problems, and increase failure rates unrelated to human error.
The safety record of ``current'' vehicles is also not fixed; even if
we were to accept the popularly figured distinction between
incremental autonomy and ``complete'' autonomy approaches, the safety
of increasingly autonomous vehicles is a moving target against which
the achievements of more radical approaches would need to be compared.
Complex changes to complex, high-stakes systems produce unpredictable
results. So how we implement automated vehicle technology is as much
about narratives, the stories we believe and tell about technology, as
much as it is about mathematics, and modelling the world. 

Our choice should not be to either accept this driverless vision or take
responsibility for the deaths of thousands. That viewpoint is abusive, coercive,
and deeply wrong, and the future is too important to be left up to
knee-jerk technoutopianism and blind ideology. This is not a question
of whether fully automated cars can come to exist, even as they are
now envisioned. I am not saying that the science-fiction dreams of
driverless vehicles are possible or impossible, and I believe in the
potential of computer technologies to achieve groundbreaking results.
But many worlds that look lovely in science fiction represent places
we may not actually wish to live, and these portrayals can afford to
avoid issues of reliability and human interaction that we cannot avoid
in the real world. There are other choices to be made as we work toward building a
more automated future. Our choices should be between options, between
visions, choices of how we integrate humans and computers to make our
driving safer, our cities more livable, our lives better. The Google model which has
captured so much press attention is one among innumerable imagined or
not-yet-imagined possibilities. Automation is not a
take-it-or-leave-it phenomenon, and the choice to accept one
particular model of vehicle automation or accept tens-of-thousands of
prospective road fatalities is a false choice. There is more on heaven
and earth than is dreamt of in this philosophy, and it is time we ask
of autonomy not the na\"{\i}ve questions of whether it will keep us
safe and improve our cities, but the deep, engaged, and difficult
questions of how it can be leveraged to achieve such aims. The real
question we need to ask is what form technologies of vehicle automation 
should take, and what benefits and acceptable sacrifices adhere to
that choice. This question is a truly multidisciplinary venture,
involving engineering, law, policy, design, and ethics. When we
automate, do we choose to do so with the philosophy of ``do no harm,''
or ``save more lives''?\footnote{These are deep and subtle questions,
  but proclaiming them meaningless from an engineering perspective is
  to miss the importance of ideas to guide technological development,
  and the social importance of developed technologies. I am grateful
  to Evan Donahue in particular for a discussion of how the
  implications of the Hippocratic oath differ from those of a
  philosophy specifically oriented around saving the greatest number.
  These two basic premises, extrapolated out to their logical
  conclusions, may diverge rather than converge, in ways that remind
  us of the dystopic potential of quantification and optimization,
  which can lead to solutions that are fundamentally inhumane. It would be foolish
  to assume that medical systems, themselves a collection of
  technologies and people, are not affected by this kinds of distinctions.} There may be hidden consequences to these
philosophies---who is saved? and how? and who bears the cost, or is
counted out in order to save the greater number?---that come to deeply
affect how systems engineered from these alter the world.
%% (Evan, on Hippocratic oath: why is it ``do no harm'' not ``save more
%% lives''?
%% there may be hidden consequences to a philosophy of saving more lives)

The purpose of this thesis has been to sweep away some lazy thinking
about automated systems, and to try to re-orient a more nuanced dialog
around different sets of issues. As we think about the future of
vehicle automation---whether as
designers, lawmakers, interested technologists or concerned
citizens---what are the questions we should be asking? What should we
grapple with instead of accepting common framings of the issues
involved? To conclude, let me summarize the main open questions around
which a more productive dialogue about automation could be based.

First, what are the social goals around which automated technology
should be designed and implemented? The relative importance of safety,
convenience, mobility, social equality, and other factors must be
matters of public debate, as they are absolutely central to the
project of automation.

Second, for any particular design, what are the appropriate roles of
human and machine in the human-machine system that automated vehicles
will necessarily be? These roles will not be a pure function of
technological capabilities, but will involve numerous other factors,
and will alter the skills that human operators will be expected to
acquire, and the types of licensing and control that are therefore
necessary. 

Third, as part of this question, how do humans interact with and
respond to AI systems that cannot simply be said to
``think'', ``know'', or ``understand'' in the same ways that we do (at
least not yet) but which nevertheless hold our lives in their hands?
These concerns may be ameliorated by human involvement and
supervision. Which means we must consider what types of supervision,
and on what time scales, are socially or legally valuable, and
therefore should be built into that technology. 

Fourth, how should we value different automation approaches, or
estimate their risks, when the technologies involved require complex
changes to complex systems?  This
involves balancing the statistical benefits of different automation
approaches, and coming to conclusions about how to reasonably
estimate risks, test and certify systems, and set engineering
priorities based on this information.

Fifth, relatedly, what is the appropriate role of statistics and risk
projections in governing policy on automated technologies? How safe is
safe enough, for whom, and how is this
regulated? Assuming we can come to reasonable predictions about costs
and benefits, we must close the loop between this information and our
broader social goals. We need to decide how to weigh uncertainties in
our evaluation of which goals matter and which are achievable in the
near term or long term.

%% 2) wrap up with the big questions we are faced with, that we have to
%% grapple with instead of accepting teleology/common media framings: (1
%% p)
%% --1) what is the appropriate role for the human in the human/machine
%% system? (1 p) (and what skills do they need to acquire, what licensing
%% is necessary?)
%% --2) what is the appropriate role of statistics and risk in governing
%% policy on the issue? can you opt-out? how do we balance projected
%% statistical benefits of disparate approaches? (0.5 p)
%% --3) how safe is safe enough? for whom? and how is this regulated? (1
%% p)
%% -----safe for drivers? for pedestrians?
%% -----what types of pedestrians?
%% --4) how do we feel about AI systems that cannot really be said to
%% ``think'', ``know'', or ``understand'' but which nevertheless ``hold
%% our lives in their hands'' (0.5 p) 
%% ----and how is this changed by the promise of continued human
%% supervision?
%% ----what types of supervision, on what time scales, are
%% socially/legally valuable, valuable enough to be build into our technology?
%% ----This may well imply we need the human involved, for that very
%% reason
%% ----and we should KEEP the human involved as a matter of design
%% principle (2 p)

These considerations may well imply we need to maintain significant
human involvement in order to mitigate risk, achieve public
acceptance, and address the human goals that drive technological
development. Rather than ``to automate or not to automate,'' we ask
``how and why do we automate?'' But even in the most automated technologies, their
autonomy is largely an artifact of the lens through which we engage
with them---these systems involve delicate dances of human and machine
components, dispersed through time and space, and only pushed to the
margins of a point of view that takes the technological object itself,
not its sociopolitical and cognitive contexts, as the object of study.
Recognizing that continued human involvement will occur as a matter of principle is
the most important first step we can take toward rebalancing the
narrative of automation toward something more productive, which takes
seriously the technological hybridity of our past, present and future.
And it paves the way for a political critique that asks, knowing
that humans remain involved, who they are, where they are, and how
the system is being designed to serve their needs or impede their agency.

