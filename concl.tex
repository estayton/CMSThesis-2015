\chapter{Conclusion: Driving the Future}

%%Resisting Teleology / Conclusion (14 p)

Our journey through ideologies of automation and driverless vehicle
development has taken us from an explication of the dominant narrative
of the ``self-driving'' vehicle, through an examination of what this
might mean for our society, to an investigation of an alternative
narrative and the real histories that support that narrative. What
should be clear from this thesis, but which must be made clearer in the
public discourse about increasingly-automated technologies, is that a
movement from human systems, through hybrid systems, to fully
autonomous systems autonomous is not inevitable. It is not a
requirement of technological progress, or a fundamental fact about the
future, but one narrative among many which must be conditional on our
acceptance as well as on technological progress. A forward march of
technology does not alone make full autonomy acceptable or viable,
but presents a convenient cover story for the economic objectives of
organizations involved in automating the car.\footnote{For more about
  how struggles about cities and transportation technologies have
  panned out in the past, see appendix \ref{chap:5}.}

And as I find myself repeating continually, because it is such a vital
recognition, complete autonomy is ultimately a foreign concept,
something no current automated vehicle plans point toward. Until
vehicles construct themselves, monitor themselves, pay for themselves,
and are intended only to drive themselves around---a strange world
indeed---human oversight is inescapable. Vehicles serve human needs,
are constructed and operated by humans or organizations made of
humans, and are ultimately paid for by humans. While certain types of
labor may be eliminated, and certain laborers marginalized, a
system-level view of automation continues to uncover vast amounts of
human labor---perhaps at the periphery of the car as an individual
object, but unavoidably implicated in the day-to-day reality of
vehicle operations. At the most radical, and most teleological, we are
facing not a system of autonomous robots but fleets of telerobotic
vehicles with closed-loop control systems providing limited autonomy,
that are supervised by remote operators within the datacenters of
multinational IT corporations. 

But even this, though it presents certain advantages, is by no means
our obvious future. Such a networked system worsens issues of privacy
and data security. Longer time periods of unsupervised operation, and
more limited involvement of the people within the vehicle, require
automation technologies with greater reliability and situational
capability, in order to reduce the risk of catastrophe for
operators---whether that catastrophe is measured by personal death or
system failure leading to financial ruin. Even Tesla Motors, bullish
about its forthcoming ``autopilot'' technology, admits the limitations
of current automated systems: automated driving will not be available
in residential neighborhoods because they do not believe it is safe
enough\cite{???-http://www.slashgear.com/tesla-model-s-autopilot-update-due-in-3-4-months-19374458/}.
More capable systems, able to operate without failure in a greater
proportion of real-world situations, may require human involvement and
supervision, at the very least until significant open problems in
artificial intelligence are solved. Human beings are not solely
sources of failure to be engineered out of systems, but are also
successful operators and risk-mitigators, who are capable of
performing complex and difficult tasks. And it would be wrong to
categorize human involvement as purely a temporary requirement, until
computers are sufficiently advanced:  it
may be that whatever the ultimate capabilities of machines, we may
find it socially unacceptable to surrender certain areas of operation
completely to computers. The method and timescale of automated
operation may greatly impact 
public acceptance, to the point that certain types of human
involvement may be required to produce marketable technologies. Though
this may be distasteful to some technologists invested in furthering
technological solutions to social problems, it is not fundamentally
a failure. It is a societal choice to which engineering solutions
should be pliable.

Many examples of hybrid systems exist, and joint-cognitive systems
design presents an alternative way of looking at problems, and valuing
human and machine contributions to their solution, that opens the way
for other futures. And as we have seen, these approaches and
perspectives are not those of ``mere'' luddites or humanists on the
margins of engineering practice, but of an important segment of
engineers themselves who are vital to the design and construction of
successful real-world systems. The hybrid human-machine system is a
very difficult engineering problem---we are not necessarily making
things easier on ourselves by choosing such a solution compared to a
more fully automated one, something even the Department of Defense,
hardly a bunch of technophobes, finds it important to recognize---but
it is also a valuable approach for 
systems that are tasked with keeping us safe, whether in space, in the
air, or on the ground. And this is especially true as we will use our
vehicles every day, and cannot afford to alienate ourselves from them.
A future in which our transportation system is indifferent to us is
not a productive future to be lauded, but a destructive one to be
avoided. 

This discussion has tried to frame the largely invisible histories involved in
notions of autonomy and automation, the ideologies flowing into the
dreams of driverless cars and attendant approaches to system design.
When we use factory automation, artificial intelligence, ``NASA
engineering,'' or autopilot to frame ideas about self-driving
vehicles, we carry forward certain ideas about these technologies that
frame our vision, irrespective of actual historical developments. We risk
thinking about autopilots as a small step away from being full vehicle
operators, rather than as tools used by vehicle operators to support
their needs. We risk thinking about factory automation as a
teleological process toward the elimination of labor, rather than a
deeply contingent process that changes the forms of certain kinds of
labor into other forms, or shifts that labor in time and space. We
risk thinking about NASA as an organization responsible for
engineering highly automated, redundant systems, rather than an
organization full of people whose jobs include constant monitoring,
supervision, and interactions with the same automated systems. We may
consider new automation through the lens of the artificial, of
building systems to replace people, or through a hybrid lens, building
systems to support humans in their tasks. Both ways of considering
automated systems can often be applied to the same technological
artifact, but result in very different ways of thinking.\footnote{A
speech-to-text system can be seen as either a technology to transcribe 
the human voice into text instead of a person, or a tool to assist a
human with transcription. But the choice of perspective will likely do
much to change how such a technology is designed. I would hypothesize that
the focus on what computerized personal assistants can do, for
example, as opposed to the process of human and machine jointly
carrying out a task and accomplishing something together, does much to
explain the repeated failure of personal assistant technology to gain
users.}  Throughout, I have emphasized the contingency of current
automated vehicle plans on specific ideas about the appropriate and
necessary role of technology, and stressed the presence of other ways
to regard vehicle automation technology that could bring about
different futures. There is no reason that commonly accepted ideas
about complete vehicle automation are necessarily right---and that
partial, or function-by-function automation, for example, is simply a
stop-gap measure. In contrast to the simplistic depictions provided by
most media representations---of pro-and-con, for-and-against, but all
focused around a particular view of the object of study, not asking
what automated vehicles will truly be, but only what will this assumed
object do---which form the visible picture of this technology today
for most people not involved in its engineering, I have described a
range of alternative narratives that complicate our ideas of what
automated vehicles can and will be.

Ultimately, from a design and policy perspective, my point is that we
cannot achieve positive social effects by na\"{\i}vely adding autonomy to
existing vehicles. Autonomy and automation are not natural goods to be
fostered wherever they can be, but technological tools and strategies
for achieving particular goals. The manner and extent to which we
build our vehicles to be autonomous stands to produce very different
social impacts, to the point where going from the idea of the
``self-driving vehicle'' to social and cultural impacts is
fundamentally backward, since the vehicle itself is not fixed and
small details may matter a great deal in real-world use. Instead,
social changes have to be at the center of design and implementation.
What are the goals a vehicle is designed to achieve, and which goals
are more important than others? Increasing
statistical safety by a factor of 100? Providing mobility for the
elderly or disabled? Reducing the environmental impact of vehicles and
their emissions? Increasing throughput of the roadway? Reducing
traffic delays for commuters? Equalizing the 
disparities in mobility between the wealthy and the homeless? It is
fantastical thinking to believe that the just-add-autonomy approach
will automatically achieve all these goals. Each presents a
system-wide design problem, involving cars, people, and
infrastructures, that puts different demands on possible solutions.
And some contradict the motives of organizations responsible for
providing the solutions:  while automobile companies can promulgate
ideas about how automated vehicles can provide greater mobility, help
the environment, and reduce traffic, they are unlikely to economically
back concepts that are against their interests---anything that reduces
the number of vehicles on the road,\footnote{Thanks to Joe Dumit for eloquently
  making this observation during a recent visit I made to UC Davis.}
or the overall cost of those 
vehicles, without providing a new revenue stream to compensate,
represents a deeply suspect investment. 

%% The pro-side: millions of deaths if we don't do something now, so we
%% have to accept these
%% The con-side: (regulator) current deaths not on my hands, but if one
%% little girl is killed by a robot I've lost my job

But public rhetorics of driverless vehicles have an unfortunate
tendency to avoid these complex questions. One popular and troubling
argument revolves around responsibility for the rollout of
self-driving systems. On the pro-side, commentators stress the many
thousands who will die if self-driving systems are not implemented
soon, using that as lever to argue for the moral imperative of
speeding up their legalization and acceptance.\cite{???} On the con-side, in
this interpretation, stand the risk-averse regulators: current deaths
are obviously not on their hands, but if one child is killed by a
``robot car'' they face public censure. But though this cartoon-like
view of reality does have a media public face, it does not do justice
to the complexity of the situation. The statistics about driverless
cars and risk, though partly a function of mathematical modelling, are
also, fundamentally, matters of faith. No one has the precise answer.
While we can point to the 90\% of accidents that involve human error,
computers will fix some of these types of error but may also cause
other problems, and increase failure rates unrelated to human error.
The safety record of ``current'' vehicles is also not fixed; even if
we were to accept the popularly figured distinction between
incremental autonomy and ``complete'' autonomy approaches, the safety
of increasingly autonomous vehicles is a moving target against which
the achievements of more radical approaches would need to be compared.
Complex changes to complex, high-stakes systems produce unpredictable
results. So how we implement automated vehicle technology is as much
about narratives, the stories we believe and tell about technology, as
much as it is about mathematics, and modelling the world. 

Our choice should not be to either accept this driverless vision or take
responsibility for the deaths of thousands. That viewpoint is abusive, coercive,
and deeply wrong, and the future is too important to be left up to
knee-jerk technoutopianism and blind ideology. This is not a question
of whether fully automated cars can come to exist, even as they are
now envisioned. I am not saying that the science-fiction dreams of
driverless vehicles are possible or impossible, and I believe in the
potential of computer technologies to achieve groundbreaking results.
But many worlds that look lovely in science fiction represent places
we may not actually wish to live, and these portrayals can afford to
avoid issues of reliability and human interaction that we cannot avoid
in the real world. There are other choices to be made as we work toward building a
more automated future. 
...run together..
The choice should be between options, between visions, choices of how
we integrate computers to make our driving safer. The google model,
this model, the other model, or innumerable newly imagined
possibilities. NOT a take it or leave it; not the choice of the google
car or a big fuck you to all the prospective road fatalities. That is
no choice. There is more on heaven and earth than is dreamt of in this
philosophy. The real question we need to ask is what form the tech
should take, and what benefits and acceptable sacrifices adhere to
that choice.

(Evan, on Hippocratic oath: why is it ``do no harm'' not ``save more
lives''?
there may be hidden consequences to a philosophy of saving more lives)


EDIT THE BELOW

2) wrap up with the big questions we are faced with, that we have to
grapple with instead of accepting teleology/common media framings: (1
p)
--1) what is the appropriate role for the human in the human/machine
system? (1 p) (and what skills do they need to acquire, what licensing
is necessary?)
--2) what is the appropriate role of statistics and risk in governing
policy on the issue? can you opt-out? how do we balance projected
statistical benefits of disparate approaches? (0.5 p)
--3) how safe is safe enough? for whom? and how is this regulated? (1
p)
-----safe for drivers? for pedestrians?
-----what types of pedestrians?
--4) how do we feel about AI systems that cannot really be said to
``think'', ``know'', or ``understand'' but which nevertheless ``hold
our lives in their hands'' (0.5 p) 
----and how is this changed by the promise of continued human
supervision?
----what types of supervision, on what time scales, are
socially/legally valuable, valuable enough to be build into our technology?
----This may well imply we need the human involved, for that very
reason
----and we should KEEP the human involved as a matter of design
principle (2 p)

